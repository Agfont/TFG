{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook, para cada estancia en UCI guardada en MIMIC-III, extraemos los datos de diferentes variables que componen OASIS (Oxford acute severity of illness score) relacionados con esa estancia y a partir de estos datos calculamos la puntuación OASIS de esa estancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Fu-sdl9qh_1c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import scipy.stats as stats\n",
    "import pylab\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "bCKcyWu-tJa1",
    "outputId": "67d3751c-4d03-4d92-ecc4-fd18ae222ed6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 8)\n",
      "unique SUBJECT_ID: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>DOB</th>\n",
       "      <th>DOD</th>\n",
       "      <th>DOD_HOSP</th>\n",
       "      <th>DOD_SSN</th>\n",
       "      <th>EXPIRE_FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9467</td>\n",
       "      <td>10006</td>\n",
       "      <td>F</td>\n",
       "      <td>2094-03-05 00:00:00</td>\n",
       "      <td>2165-08-12 00:00:00</td>\n",
       "      <td>2165-08-12 00:00:00</td>\n",
       "      <td>2165-08-12 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9472</td>\n",
       "      <td>10011</td>\n",
       "      <td>F</td>\n",
       "      <td>2090-06-05 00:00:00</td>\n",
       "      <td>2126-08-28 00:00:00</td>\n",
       "      <td>2126-08-28 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9474</td>\n",
       "      <td>10013</td>\n",
       "      <td>F</td>\n",
       "      <td>2038-09-03 00:00:00</td>\n",
       "      <td>2125-10-07 00:00:00</td>\n",
       "      <td>2125-10-07 00:00:00</td>\n",
       "      <td>2125-10-07 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9478</td>\n",
       "      <td>10017</td>\n",
       "      <td>F</td>\n",
       "      <td>2075-09-21 00:00:00</td>\n",
       "      <td>2152-09-12 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2152-09-12 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9479</td>\n",
       "      <td>10019</td>\n",
       "      <td>M</td>\n",
       "      <td>2114-06-20 00:00:00</td>\n",
       "      <td>2163-05-15 00:00:00</td>\n",
       "      <td>2163-05-15 00:00:00</td>\n",
       "      <td>2163-05-15 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID  SUBJECT_ID GENDER                  DOB                  DOD  \\\n",
       "0    9467       10006      F  2094-03-05 00:00:00  2165-08-12 00:00:00   \n",
       "1    9472       10011      F  2090-06-05 00:00:00  2126-08-28 00:00:00   \n",
       "2    9474       10013      F  2038-09-03 00:00:00  2125-10-07 00:00:00   \n",
       "3    9478       10017      F  2075-09-21 00:00:00  2152-09-12 00:00:00   \n",
       "4    9479       10019      M  2114-06-20 00:00:00  2163-05-15 00:00:00   \n",
       "\n",
       "              DOD_HOSP              DOD_SSN  EXPIRE_FLAG  \n",
       "0  2165-08-12 00:00:00  2165-08-12 00:00:00            1  \n",
       "1  2126-08-28 00:00:00                  NaN            1  \n",
       "2  2125-10-07 00:00:00  2125-10-07 00:00:00            1  \n",
       "3                  NaN  2152-09-12 00:00:00            1  \n",
       "4  2163-05-15 00:00:00  2163-05-15 00:00:00            1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients=pd.read_csv('/data/demo/PATIENTS.csv')\n",
    "print(patients.shape)\n",
    "print('unique SUBJECT_ID:', patients.SUBJECT_ID.nunique())\n",
    "patients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "id": "-X5qj5bStJrA",
    "outputId": "957ce16d-8857-4065-f0c9-ff2d5023a952"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129, 19)\n",
      "unique SUBJECT_ID: 100\n",
      "unique HADM_ID   : 129\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ADMITTIME</th>\n",
       "      <th>DISCHTIME</th>\n",
       "      <th>DEATHTIME</th>\n",
       "      <th>ADMISSION_TYPE</th>\n",
       "      <th>ADMISSION_LOCATION</th>\n",
       "      <th>DISCHARGE_LOCATION</th>\n",
       "      <th>INSURANCE</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>RELIGION</th>\n",
       "      <th>MARITAL_STATUS</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>EDREGTIME</th>\n",
       "      <th>EDOUTTIME</th>\n",
       "      <th>DIAGNOSIS</th>\n",
       "      <th>HOSPITAL_EXPIRE_FLAG</th>\n",
       "      <th>HAS_CHARTEVENTS_DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12258</td>\n",
       "      <td>10006</td>\n",
       "      <td>142345</td>\n",
       "      <td>2164-10-23 21:09:00</td>\n",
       "      <td>2164-11-01 17:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>SEPARATED</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>2164-10-23 16:43:00</td>\n",
       "      <td>2164-10-23 23:00:00</td>\n",
       "      <td>SEPSIS</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12263</td>\n",
       "      <td>10011</td>\n",
       "      <td>105331</td>\n",
       "      <td>2126-08-14 22:32:00</td>\n",
       "      <td>2126-08-28 18:59:00</td>\n",
       "      <td>2126-08-28 18:59:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>DEAD/EXPIRED</td>\n",
       "      <td>Private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>UNKNOWN/NOT SPECIFIED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HEPATITIS B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12265</td>\n",
       "      <td>10013</td>\n",
       "      <td>165520</td>\n",
       "      <td>2125-10-04 23:36:00</td>\n",
       "      <td>2125-10-07 15:13:00</td>\n",
       "      <td>2125-10-07 15:13:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>DEAD/EXPIRED</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN/NOT SPECIFIED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEPSIS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12269</td>\n",
       "      <td>10017</td>\n",
       "      <td>199207</td>\n",
       "      <td>2149-05-26 17:19:00</td>\n",
       "      <td>2149-06-03 18:42:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>SNF</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>DIVORCED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2149-05-26 12:08:00</td>\n",
       "      <td>2149-05-26 19:45:00</td>\n",
       "      <td>HUMERAL FRACTURE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12270</td>\n",
       "      <td>10019</td>\n",
       "      <td>177759</td>\n",
       "      <td>2163-05-14 20:43:00</td>\n",
       "      <td>2163-05-15 12:00:00</td>\n",
       "      <td>2163-05-15 12:00:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>DEAD/EXPIRED</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CATHOLIC</td>\n",
       "      <td>DIVORCED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALCOHOLIC HEPATITIS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID  SUBJECT_ID  HADM_ID            ADMITTIME            DISCHTIME  \\\n",
       "0   12258       10006   142345  2164-10-23 21:09:00  2164-11-01 17:15:00   \n",
       "1   12263       10011   105331  2126-08-14 22:32:00  2126-08-28 18:59:00   \n",
       "2   12265       10013   165520  2125-10-04 23:36:00  2125-10-07 15:13:00   \n",
       "3   12269       10017   199207  2149-05-26 17:19:00  2149-06-03 18:42:00   \n",
       "4   12270       10019   177759  2163-05-14 20:43:00  2163-05-15 12:00:00   \n",
       "\n",
       "             DEATHTIME ADMISSION_TYPE         ADMISSION_LOCATION  \\\n",
       "0                  NaN      EMERGENCY       EMERGENCY ROOM ADMIT   \n",
       "1  2126-08-28 18:59:00      EMERGENCY  TRANSFER FROM HOSP/EXTRAM   \n",
       "2  2125-10-07 15:13:00      EMERGENCY  TRANSFER FROM HOSP/EXTRAM   \n",
       "3                  NaN      EMERGENCY       EMERGENCY ROOM ADMIT   \n",
       "4  2163-05-15 12:00:00      EMERGENCY  TRANSFER FROM HOSP/EXTRAM   \n",
       "\n",
       "  DISCHARGE_LOCATION INSURANCE LANGUAGE  RELIGION MARITAL_STATUS  \\\n",
       "0   HOME HEALTH CARE  Medicare      NaN  CATHOLIC      SEPARATED   \n",
       "1       DEAD/EXPIRED   Private      NaN  CATHOLIC         SINGLE   \n",
       "2       DEAD/EXPIRED  Medicare      NaN  CATHOLIC            NaN   \n",
       "3                SNF  Medicare      NaN  CATHOLIC       DIVORCED   \n",
       "4       DEAD/EXPIRED  Medicare      NaN  CATHOLIC       DIVORCED   \n",
       "\n",
       "                ETHNICITY            EDREGTIME            EDOUTTIME  \\\n",
       "0  BLACK/AFRICAN AMERICAN  2164-10-23 16:43:00  2164-10-23 23:00:00   \n",
       "1   UNKNOWN/NOT SPECIFIED                  NaN                  NaN   \n",
       "2   UNKNOWN/NOT SPECIFIED                  NaN                  NaN   \n",
       "3                   WHITE  2149-05-26 12:08:00  2149-05-26 19:45:00   \n",
       "4                   WHITE                  NaN                  NaN   \n",
       "\n",
       "             DIAGNOSIS  HOSPITAL_EXPIRE_FLAG  HAS_CHARTEVENTS_DATA  \n",
       "0               SEPSIS                     0                     1  \n",
       "1          HEPATITIS B                     1                     1  \n",
       "2               SEPSIS                     1                     1  \n",
       "3     HUMERAL FRACTURE                     0                     1  \n",
       "4  ALCOHOLIC HEPATITIS                     1                     1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions=pd.read_csv('/data/demo/ADMISSIONS.csv')\n",
    "print(admissions.shape)\n",
    "print('unique SUBJECT_ID:', admissions.SUBJECT_ID.nunique())\n",
    "print('unique HADM_ID   :', admissions.HADM_ID.nunique())\n",
    "admissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ICa4vBLgOQ4r"
   },
   "outputs": [],
   "source": [
    "admissions=admissions.drop(['ROW_ID', 'DEATHTIME', 'ADMISSION_LOCATION', 'DISCHARGE_LOCATION', 'LANGUAGE', \n",
    "                        'RELIGION', 'MARITAL_STATUS', 'EDREGTIME', 'EDOUTTIME'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "id": "lHsOxvsLOREb",
    "outputId": "358309a5-a4dd-4b10-cb59-69c1a0451e88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129, 17)\n",
      "unique SUBJECT_ID: 100\n",
      "unique HADM_ID   : 129\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>DOB</th>\n",
       "      <th>DOD</th>\n",
       "      <th>DOD_HOSP</th>\n",
       "      <th>DOD_SSN</th>\n",
       "      <th>EXPIRE_FLAG</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ADMITTIME</th>\n",
       "      <th>DISCHTIME</th>\n",
       "      <th>ADMISSION_TYPE</th>\n",
       "      <th>INSURANCE</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>DIAGNOSIS</th>\n",
       "      <th>HOSPITAL_EXPIRE_FLAG</th>\n",
       "      <th>HAS_CHARTEVENTS_DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9467</td>\n",
       "      <td>10006</td>\n",
       "      <td>F</td>\n",
       "      <td>2094-03-05 00:00:00</td>\n",
       "      <td>2165-08-12 00:00:00</td>\n",
       "      <td>2165-08-12 00:00:00</td>\n",
       "      <td>2165-08-12 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>142345</td>\n",
       "      <td>2164-10-23 21:09:00</td>\n",
       "      <td>2164-11-01 17:15:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>SEPSIS</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9472</td>\n",
       "      <td>10011</td>\n",
       "      <td>F</td>\n",
       "      <td>2090-06-05 00:00:00</td>\n",
       "      <td>2126-08-28 00:00:00</td>\n",
       "      <td>2126-08-28 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>105331</td>\n",
       "      <td>2126-08-14 22:32:00</td>\n",
       "      <td>2126-08-28 18:59:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>Private</td>\n",
       "      <td>UNKNOWN/NOT SPECIFIED</td>\n",
       "      <td>HEPATITIS B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9474</td>\n",
       "      <td>10013</td>\n",
       "      <td>F</td>\n",
       "      <td>2038-09-03 00:00:00</td>\n",
       "      <td>2125-10-07 00:00:00</td>\n",
       "      <td>2125-10-07 00:00:00</td>\n",
       "      <td>2125-10-07 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>165520</td>\n",
       "      <td>2125-10-04 23:36:00</td>\n",
       "      <td>2125-10-07 15:13:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>UNKNOWN/NOT SPECIFIED</td>\n",
       "      <td>SEPSIS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9478</td>\n",
       "      <td>10017</td>\n",
       "      <td>F</td>\n",
       "      <td>2075-09-21 00:00:00</td>\n",
       "      <td>2152-09-12 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2152-09-12 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>199207</td>\n",
       "      <td>2149-05-26 17:19:00</td>\n",
       "      <td>2149-06-03 18:42:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>HUMERAL FRACTURE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9479</td>\n",
       "      <td>10019</td>\n",
       "      <td>M</td>\n",
       "      <td>2114-06-20 00:00:00</td>\n",
       "      <td>2163-05-15 00:00:00</td>\n",
       "      <td>2163-05-15 00:00:00</td>\n",
       "      <td>2163-05-15 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>177759</td>\n",
       "      <td>2163-05-14 20:43:00</td>\n",
       "      <td>2163-05-15 12:00:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>ALCOHOLIC HEPATITIS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID  SUBJECT_ID GENDER                  DOB                  DOD  \\\n",
       "0    9467       10006      F  2094-03-05 00:00:00  2165-08-12 00:00:00   \n",
       "1    9472       10011      F  2090-06-05 00:00:00  2126-08-28 00:00:00   \n",
       "2    9474       10013      F  2038-09-03 00:00:00  2125-10-07 00:00:00   \n",
       "3    9478       10017      F  2075-09-21 00:00:00  2152-09-12 00:00:00   \n",
       "4    9479       10019      M  2114-06-20 00:00:00  2163-05-15 00:00:00   \n",
       "\n",
       "              DOD_HOSP              DOD_SSN  EXPIRE_FLAG  HADM_ID  \\\n",
       "0  2165-08-12 00:00:00  2165-08-12 00:00:00            1   142345   \n",
       "1  2126-08-28 00:00:00                  NaN            1   105331   \n",
       "2  2125-10-07 00:00:00  2125-10-07 00:00:00            1   165520   \n",
       "3                  NaN  2152-09-12 00:00:00            1   199207   \n",
       "4  2163-05-15 00:00:00  2163-05-15 00:00:00            1   177759   \n",
       "\n",
       "             ADMITTIME            DISCHTIME ADMISSION_TYPE INSURANCE  \\\n",
       "0  2164-10-23 21:09:00  2164-11-01 17:15:00      EMERGENCY  Medicare   \n",
       "1  2126-08-14 22:32:00  2126-08-28 18:59:00      EMERGENCY   Private   \n",
       "2  2125-10-04 23:36:00  2125-10-07 15:13:00      EMERGENCY  Medicare   \n",
       "3  2149-05-26 17:19:00  2149-06-03 18:42:00      EMERGENCY  Medicare   \n",
       "4  2163-05-14 20:43:00  2163-05-15 12:00:00      EMERGENCY  Medicare   \n",
       "\n",
       "                ETHNICITY            DIAGNOSIS  HOSPITAL_EXPIRE_FLAG  \\\n",
       "0  BLACK/AFRICAN AMERICAN               SEPSIS                     0   \n",
       "1   UNKNOWN/NOT SPECIFIED          HEPATITIS B                     1   \n",
       "2   UNKNOWN/NOT SPECIFIED               SEPSIS                     1   \n",
       "3                   WHITE     HUMERAL FRACTURE                     0   \n",
       "4                   WHITE  ALCOHOLIC HEPATITIS                     1   \n",
       "\n",
       "   HAS_CHARTEVENTS_DATA  \n",
       "0                     1  \n",
       "1                     1  \n",
       "2                     1  \n",
       "3                     1  \n",
       "4                     1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions=pd.merge(patients, admissions, on=['SUBJECT_ID'])\n",
    "print(admissions.shape)\n",
    "print('unique SUBJECT_ID:', admissions.SUBJECT_ID.nunique())\n",
    "print('unique HADM_ID   :', admissions.HADM_ID.nunique())\n",
    "admissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "YdhYxmqSORGT",
    "outputId": "2ca11f6e-656c-4027-d6ac-61915616c74c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136, 12)\n",
      "unique SUBJECT_ID: 100\n",
      "unique HADM_ID   : 129\n",
      "unique ICUSTAY_ID: 136\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ICUSTAY_ID</th>\n",
       "      <th>DBSOURCE</th>\n",
       "      <th>FIRST_CAREUNIT</th>\n",
       "      <th>LAST_CAREUNIT</th>\n",
       "      <th>FIRST_WARDID</th>\n",
       "      <th>LAST_WARDID</th>\n",
       "      <th>INTIME</th>\n",
       "      <th>OUTTIME</th>\n",
       "      <th>LOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12742</td>\n",
       "      <td>10006</td>\n",
       "      <td>142345</td>\n",
       "      <td>206504</td>\n",
       "      <td>carevue</td>\n",
       "      <td>MICU</td>\n",
       "      <td>MICU</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>2164-10-23 21:10:15</td>\n",
       "      <td>2164-10-25 12:21:07</td>\n",
       "      <td>1.6325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12747</td>\n",
       "      <td>10011</td>\n",
       "      <td>105331</td>\n",
       "      <td>232110</td>\n",
       "      <td>carevue</td>\n",
       "      <td>MICU</td>\n",
       "      <td>MICU</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2126-08-14 22:34:00</td>\n",
       "      <td>2126-08-28 18:59:00</td>\n",
       "      <td>13.8507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12749</td>\n",
       "      <td>10013</td>\n",
       "      <td>165520</td>\n",
       "      <td>264446</td>\n",
       "      <td>carevue</td>\n",
       "      <td>MICU</td>\n",
       "      <td>MICU</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2125-10-04 23:38:00</td>\n",
       "      <td>2125-10-07 15:13:52</td>\n",
       "      <td>2.6499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12754</td>\n",
       "      <td>10017</td>\n",
       "      <td>199207</td>\n",
       "      <td>204881</td>\n",
       "      <td>carevue</td>\n",
       "      <td>CCU</td>\n",
       "      <td>CCU</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2149-05-29 18:52:29</td>\n",
       "      <td>2149-05-31 22:19:17</td>\n",
       "      <td>2.1436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12755</td>\n",
       "      <td>10019</td>\n",
       "      <td>177759</td>\n",
       "      <td>228977</td>\n",
       "      <td>carevue</td>\n",
       "      <td>MICU</td>\n",
       "      <td>MICU</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2163-05-14 20:43:56</td>\n",
       "      <td>2163-05-16 03:47:04</td>\n",
       "      <td>1.2938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID  SUBJECT_ID  HADM_ID  ICUSTAY_ID DBSOURCE FIRST_CAREUNIT  \\\n",
       "0   12742       10006   142345      206504  carevue           MICU   \n",
       "1   12747       10011   105331      232110  carevue           MICU   \n",
       "2   12749       10013   165520      264446  carevue           MICU   \n",
       "3   12754       10017   199207      204881  carevue            CCU   \n",
       "4   12755       10019   177759      228977  carevue           MICU   \n",
       "\n",
       "  LAST_CAREUNIT  FIRST_WARDID  LAST_WARDID               INTIME  \\\n",
       "0          MICU            52           52  2164-10-23 21:10:15   \n",
       "1          MICU            15           15  2126-08-14 22:34:00   \n",
       "2          MICU            15           15  2125-10-04 23:38:00   \n",
       "3           CCU             7            7  2149-05-29 18:52:29   \n",
       "4          MICU            15           15  2163-05-14 20:43:56   \n",
       "\n",
       "               OUTTIME      LOS  \n",
       "0  2164-10-25 12:21:07   1.6325  \n",
       "1  2126-08-28 18:59:00  13.8507  \n",
       "2  2125-10-07 15:13:52   2.6499  \n",
       "3  2149-05-31 22:19:17   2.1436  \n",
       "4  2163-05-16 03:47:04   1.2938  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icustays=pd.read_csv('/data/demo/ICUSTAYS.csv')\n",
    "print(icustays.shape)\n",
    "print('unique SUBJECT_ID:', icustays.SUBJECT_ID.nunique())\n",
    "print('unique HADM_ID   :', icustays.HADM_ID.nunique())\n",
    "print('unique ICUSTAY_ID:', icustays.ICUSTAY_ID.nunique())\n",
    "icustays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ukB8GPoCORJ5"
   },
   "outputs": [],
   "source": [
    "icustays=icustays.drop(['ROW_ID', 'LAST_CAREUNIT', 'LAST_WARDID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "vErMIvkaORLt",
    "outputId": "29efb52e-d645-4188-ad06-a9e32dd76983",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136, 24)\n",
      "unique SUBJECT_ID: 100\n",
      "unique HADM_ID   : 129\n",
      "unique ICUSTAY_ID: 136\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>DOB</th>\n",
       "      <th>DOD</th>\n",
       "      <th>DOD_HOSP</th>\n",
       "      <th>DOD_SSN</th>\n",
       "      <th>EXPIRE_FLAG</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ADMITTIME</th>\n",
       "      <th>...</th>\n",
       "      <th>DIAGNOSIS</th>\n",
       "      <th>HOSPITAL_EXPIRE_FLAG</th>\n",
       "      <th>HAS_CHARTEVENTS_DATA</th>\n",
       "      <th>ICUSTAY_ID</th>\n",
       "      <th>DBSOURCE</th>\n",
       "      <th>FIRST_CAREUNIT</th>\n",
       "      <th>FIRST_WARDID</th>\n",
       "      <th>INTIME</th>\n",
       "      <th>OUTTIME</th>\n",
       "      <th>LOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9467</td>\n",
       "      <td>10006</td>\n",
       "      <td>F</td>\n",
       "      <td>2094-03-05 00:00:00</td>\n",
       "      <td>2165-08-12 00:00:00</td>\n",
       "      <td>2165-08-12 00:00:00</td>\n",
       "      <td>2165-08-12 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>142345</td>\n",
       "      <td>2164-10-23 21:09:00</td>\n",
       "      <td>...</td>\n",
       "      <td>SEPSIS</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>206504</td>\n",
       "      <td>carevue</td>\n",
       "      <td>MICU</td>\n",
       "      <td>52</td>\n",
       "      <td>2164-10-23 21:10:15</td>\n",
       "      <td>2164-10-25 12:21:07</td>\n",
       "      <td>1.6325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9472</td>\n",
       "      <td>10011</td>\n",
       "      <td>F</td>\n",
       "      <td>2090-06-05 00:00:00</td>\n",
       "      <td>2126-08-28 00:00:00</td>\n",
       "      <td>2126-08-28 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>105331</td>\n",
       "      <td>2126-08-14 22:32:00</td>\n",
       "      <td>...</td>\n",
       "      <td>HEPATITIS B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>232110</td>\n",
       "      <td>carevue</td>\n",
       "      <td>MICU</td>\n",
       "      <td>15</td>\n",
       "      <td>2126-08-14 22:34:00</td>\n",
       "      <td>2126-08-28 18:59:00</td>\n",
       "      <td>13.8507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9474</td>\n",
       "      <td>10013</td>\n",
       "      <td>F</td>\n",
       "      <td>2038-09-03 00:00:00</td>\n",
       "      <td>2125-10-07 00:00:00</td>\n",
       "      <td>2125-10-07 00:00:00</td>\n",
       "      <td>2125-10-07 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>165520</td>\n",
       "      <td>2125-10-04 23:36:00</td>\n",
       "      <td>...</td>\n",
       "      <td>SEPSIS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>264446</td>\n",
       "      <td>carevue</td>\n",
       "      <td>MICU</td>\n",
       "      <td>15</td>\n",
       "      <td>2125-10-04 23:38:00</td>\n",
       "      <td>2125-10-07 15:13:52</td>\n",
       "      <td>2.6499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9478</td>\n",
       "      <td>10017</td>\n",
       "      <td>F</td>\n",
       "      <td>2075-09-21 00:00:00</td>\n",
       "      <td>2152-09-12 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2152-09-12 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>199207</td>\n",
       "      <td>2149-05-26 17:19:00</td>\n",
       "      <td>...</td>\n",
       "      <td>HUMERAL FRACTURE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>204881</td>\n",
       "      <td>carevue</td>\n",
       "      <td>CCU</td>\n",
       "      <td>7</td>\n",
       "      <td>2149-05-29 18:52:29</td>\n",
       "      <td>2149-05-31 22:19:17</td>\n",
       "      <td>2.1436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9479</td>\n",
       "      <td>10019</td>\n",
       "      <td>M</td>\n",
       "      <td>2114-06-20 00:00:00</td>\n",
       "      <td>2163-05-15 00:00:00</td>\n",
       "      <td>2163-05-15 00:00:00</td>\n",
       "      <td>2163-05-15 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>177759</td>\n",
       "      <td>2163-05-14 20:43:00</td>\n",
       "      <td>...</td>\n",
       "      <td>ALCOHOLIC HEPATITIS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>228977</td>\n",
       "      <td>carevue</td>\n",
       "      <td>MICU</td>\n",
       "      <td>15</td>\n",
       "      <td>2163-05-14 20:43:56</td>\n",
       "      <td>2163-05-16 03:47:04</td>\n",
       "      <td>1.2938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_ID  SUBJECT_ID GENDER                  DOB                  DOD  \\\n",
       "0    9467       10006      F  2094-03-05 00:00:00  2165-08-12 00:00:00   \n",
       "1    9472       10011      F  2090-06-05 00:00:00  2126-08-28 00:00:00   \n",
       "2    9474       10013      F  2038-09-03 00:00:00  2125-10-07 00:00:00   \n",
       "3    9478       10017      F  2075-09-21 00:00:00  2152-09-12 00:00:00   \n",
       "4    9479       10019      M  2114-06-20 00:00:00  2163-05-15 00:00:00   \n",
       "\n",
       "              DOD_HOSP              DOD_SSN  EXPIRE_FLAG  HADM_ID  \\\n",
       "0  2165-08-12 00:00:00  2165-08-12 00:00:00            1   142345   \n",
       "1  2126-08-28 00:00:00                  NaN            1   105331   \n",
       "2  2125-10-07 00:00:00  2125-10-07 00:00:00            1   165520   \n",
       "3                  NaN  2152-09-12 00:00:00            1   199207   \n",
       "4  2163-05-15 00:00:00  2163-05-15 00:00:00            1   177759   \n",
       "\n",
       "             ADMITTIME  ...            DIAGNOSIS HOSPITAL_EXPIRE_FLAG  \\\n",
       "0  2164-10-23 21:09:00  ...               SEPSIS                    0   \n",
       "1  2126-08-14 22:32:00  ...          HEPATITIS B                    1   \n",
       "2  2125-10-04 23:36:00  ...               SEPSIS                    1   \n",
       "3  2149-05-26 17:19:00  ...     HUMERAL FRACTURE                    0   \n",
       "4  2163-05-14 20:43:00  ...  ALCOHOLIC HEPATITIS                    1   \n",
       "\n",
       "  HAS_CHARTEVENTS_DATA ICUSTAY_ID DBSOURCE  FIRST_CAREUNIT  FIRST_WARDID  \\\n",
       "0                    1     206504  carevue            MICU            52   \n",
       "1                    1     232110  carevue            MICU            15   \n",
       "2                    1     264446  carevue            MICU            15   \n",
       "3                    1     204881  carevue             CCU             7   \n",
       "4                    1     228977  carevue            MICU            15   \n",
       "\n",
       "                INTIME              OUTTIME      LOS  \n",
       "0  2164-10-23 21:10:15  2164-10-25 12:21:07   1.6325  \n",
       "1  2126-08-14 22:34:00  2126-08-28 18:59:00  13.8507  \n",
       "2  2125-10-04 23:38:00  2125-10-07 15:13:52   2.6499  \n",
       "3  2149-05-29 18:52:29  2149-05-31 22:19:17   2.1436  \n",
       "4  2163-05-14 20:43:56  2163-05-16 03:47:04   1.2938  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions=pd.merge(admissions, icustays, on=['SUBJECT_ID', 'HADM_ID'])\n",
    "print(admissions.shape)\n",
    "print('unique SUBJECT_ID:', admissions.SUBJECT_ID.nunique())\n",
    "print('unique HADM_ID   :', admissions.HADM_ID.nunique())\n",
    "print('unique ICUSTAY_ID:', admissions.ICUSTAY_ID.nunique())\n",
    "admissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "oZhI9QmxOqsL"
   },
   "outputs": [],
   "source": [
    "#we compute the age at the time the patient is admitted to the ICU from date of birth dob, then we drop dob.\n",
    "admissions['DOB'] = pd.to_datetime(admissions['DOB']).dt.date\n",
    "admissions['INTIME_TMP'] = pd.to_datetime(admissions['INTIME']).dt.date\n",
    "admissions['AGE'] = admissions.apply(lambda e: (e['INTIME_TMP'] - e['DOB']).days/365, axis=1)\n",
    "admissions=admissions.drop(['DOB'], axis=1)\n",
    "admissions=admissions.drop(['INTIME_TMP'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "pAQXoQO8hrgo"
   },
   "outputs": [],
   "source": [
    "admissions=admissions.drop(['INSURANCE','ETHNICITY'], axis=1)\n",
    "admissions=admissions.drop(['DOD', 'DOD_HOSP', 'DOD_SSN', 'EXPIRE_FLAG','DISCHTIME','DIAGNOSIS','HOSPITAL_EXPIRE_FLAG','HAS_CHARTEVENTS_DATA','FIRST_CAREUNIT','FIRST_WARDID','OUTTIME'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "YdPZOUpn-Lc7"
   },
   "outputs": [],
   "source": [
    "#we compute the  Pre-ICU length of stay in hours. \n",
    "prelos_tmp= pd.to_datetime(admissions['INTIME'])-pd.to_datetime(admissions['ADMITTIME'])\n",
    "admissions['PRELOS']=np.round(prelos_tmp.dt.total_seconds()/3600, 1)\n",
    "admissions['PRELOS']=np.where(admissions['PRELOS']<0,0,admissions['PRELOS']) #hours, (la fila 128 sale negativo, error de introducir admittime y intime, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mzvII0GmBF1M",
    "outputId": "0a6a9edc-b67f-4a9d-f7d6-74b007b8834a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "older89=len(admissions[(admissions['AGE']>=300)])\n",
    "older89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "REXBTie4eD9w",
    "outputId": "b474180d-7dcb-4427-c63b-2ec8dcccf62c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136, 12)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions['AGE']=admissions['AGE'].apply(lambda x: np.random.triangular(89.01, 89.01, 100) if x >= 300 else x)\n",
    "admissions.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "T7sz48Q9wKsl"
   },
   "outputs": [],
   "source": [
    "#prueba_merged=pd.merge(admissions.iloc[0].to_frame().T,df_temp,how='left',on=['subject_id', 'hadm_id','icustay_id'])\n",
    "#prueba_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "2xvdf07tx_9W"
   },
   "outputs": [],
   "source": [
    "#para hacer prueba de prints, coger un solo icustay_id:\n",
    "#admissions = admissions.loc[admissions['ICUSTAY_ID'] == 264446]  #icustay_id que tiene datos en los 10 variables.\n",
    "#admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions=admissions.drop(['ROW_ID','GENDER','DBSOURCE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ADMITTIME</th>\n",
       "      <th>ADMISSION_TYPE</th>\n",
       "      <th>ICUSTAY_ID</th>\n",
       "      <th>INTIME</th>\n",
       "      <th>LOS</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PRELOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10006</td>\n",
       "      <td>142345</td>\n",
       "      <td>2164-10-23 21:09:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>206504</td>\n",
       "      <td>2164-10-23 21:10:15</td>\n",
       "      <td>1.6325</td>\n",
       "      <td>70.682192</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10011</td>\n",
       "      <td>105331</td>\n",
       "      <td>2126-08-14 22:32:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>232110</td>\n",
       "      <td>2126-08-14 22:34:00</td>\n",
       "      <td>13.8507</td>\n",
       "      <td>36.213699</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10013</td>\n",
       "      <td>165520</td>\n",
       "      <td>2125-10-04 23:36:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>264446</td>\n",
       "      <td>2125-10-04 23:38:00</td>\n",
       "      <td>2.6499</td>\n",
       "      <td>87.142466</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10017</td>\n",
       "      <td>199207</td>\n",
       "      <td>2149-05-26 17:19:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>204881</td>\n",
       "      <td>2149-05-29 18:52:29</td>\n",
       "      <td>2.1436</td>\n",
       "      <td>73.734247</td>\n",
       "      <td>73.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10019</td>\n",
       "      <td>177759</td>\n",
       "      <td>2163-05-14 20:43:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>228977</td>\n",
       "      <td>2163-05-14 20:43:56</td>\n",
       "      <td>1.2938</td>\n",
       "      <td>48.931507</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>44083</td>\n",
       "      <td>198330</td>\n",
       "      <td>2112-05-28 15:45:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>286428</td>\n",
       "      <td>2112-05-29 02:01:33</td>\n",
       "      <td>3.6174</td>\n",
       "      <td>54.569863</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>44154</td>\n",
       "      <td>174245</td>\n",
       "      <td>2178-05-14 20:29:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>217724</td>\n",
       "      <td>2178-05-14 20:29:55</td>\n",
       "      <td>0.6259</td>\n",
       "      <td>98.035910</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>44212</td>\n",
       "      <td>163189</td>\n",
       "      <td>2123-11-24 14:14:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>239396</td>\n",
       "      <td>2123-11-24 14:14:29</td>\n",
       "      <td>31.1235</td>\n",
       "      <td>45.468493</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>44222</td>\n",
       "      <td>192189</td>\n",
       "      <td>2180-07-19 06:55:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>238186</td>\n",
       "      <td>2180-07-19 06:56:38</td>\n",
       "      <td>1.3279</td>\n",
       "      <td>73.112329</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>44228</td>\n",
       "      <td>103379</td>\n",
       "      <td>2170-12-15 03:14:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>217992</td>\n",
       "      <td>2170-12-15 04:41:39</td>\n",
       "      <td>4.6191</td>\n",
       "      <td>58.186301</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SUBJECT_ID  HADM_ID            ADMITTIME ADMISSION_TYPE  ICUSTAY_ID  \\\n",
       "0         10006   142345  2164-10-23 21:09:00      EMERGENCY      206504   \n",
       "1         10011   105331  2126-08-14 22:32:00      EMERGENCY      232110   \n",
       "2         10013   165520  2125-10-04 23:36:00      EMERGENCY      264446   \n",
       "3         10017   199207  2149-05-26 17:19:00      EMERGENCY      204881   \n",
       "4         10019   177759  2163-05-14 20:43:00      EMERGENCY      228977   \n",
       "..          ...      ...                  ...            ...         ...   \n",
       "131       44083   198330  2112-05-28 15:45:00      EMERGENCY      286428   \n",
       "132       44154   174245  2178-05-14 20:29:00      EMERGENCY      217724   \n",
       "133       44212   163189  2123-11-24 14:14:00      EMERGENCY      239396   \n",
       "134       44222   192189  2180-07-19 06:55:00      EMERGENCY      238186   \n",
       "135       44228   103379  2170-12-15 03:14:00      EMERGENCY      217992   \n",
       "\n",
       "                  INTIME      LOS        AGE  PRELOS  \n",
       "0    2164-10-23 21:10:15   1.6325  70.682192     0.0  \n",
       "1    2126-08-14 22:34:00  13.8507  36.213699     0.0  \n",
       "2    2125-10-04 23:38:00   2.6499  87.142466     0.0  \n",
       "3    2149-05-29 18:52:29   2.1436  73.734247    73.6  \n",
       "4    2163-05-14 20:43:56   1.2938  48.931507     0.0  \n",
       "..                   ...      ...        ...     ...  \n",
       "131  2112-05-29 02:01:33   3.6174  54.569863    10.3  \n",
       "132  2178-05-14 20:29:55   0.6259  98.035910     0.0  \n",
       "133  2123-11-24 14:14:29  31.1235  45.468493     0.0  \n",
       "134  2180-07-19 06:56:38   1.3279  73.112329     0.0  \n",
       "135  2170-12-15 04:41:39   4.6191  58.186301     1.5  \n",
       "\n",
       "[136 rows x 9 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'eficienteV3_3_demo/data/root/'\n",
    "try:\n",
    "    os.makedirs(output_path)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions.to_csv(os.path.join(output_path, 'all_stays.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_up_stays(stays, output_path):\n",
    "    nb_stays = stays.shape[0]\n",
    "    stays_ids = stays.ICUSTAY_ID.unique()\n",
    "    for icustay_id in tqdm(stays_ids, total=nb_stays, desc='Breaking up stays'):\n",
    "        dn = os.path.join(output_path, str(icustay_id))\n",
    "        try:\n",
    "            os.makedirs(dn)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        stays[stays.ICUSTAY_ID == icustay_id].to_csv(os.path.join(dn, 'stays.csv'),\n",
    "                                                                              index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_events_table_by_row(mimic3_path, table):\n",
    "    nb_rows = {'chartevents': 330712484,  'outputevents': 4349219, 'procedureevents_mv': 258067,}\n",
    "    reader = csv.DictReader(open(os.path.join(mimic3_path, table.upper() + '.csv'), 'r'))\n",
    "    for i, row in enumerate(reader):\n",
    "        if 'ICUSTAY_ID' not in row:\n",
    "            row['ICUSTAY_ID'] = ''\n",
    "        yield row, i, nb_rows[table.lower()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_events_table_and_break_up_by_stays(mimic3_path, table, output_path,\n",
    "                                              items_to_keep=None, stays_to_keep=None):\n",
    "    \n",
    "    if(table == 'PROCEDUREEVENTS_MV'):\n",
    "        obs_header = ['SUBJECT_ID', 'HADM_ID', 'ICUSTAY_ID', 'STARTTIME', 'ITEMID']\n",
    "    \n",
    "    elif(table == 'OUTPUTEVENTS'):\n",
    "        obs_header = ['SUBJECT_ID', 'HADM_ID', 'ICUSTAY_ID', 'CHARTTIME', 'ITEMID', 'VALUE','VALUEUOM','ISERROR']\n",
    "    \n",
    "    else:\n",
    "        obs_header = ['SUBJECT_ID', 'HADM_ID', 'ICUSTAY_ID', 'CHARTTIME', 'ITEMID', 'VALUE', 'VALUENUM','VALUEUOM','ERROR']\n",
    "\n",
    "    \n",
    "    if items_to_keep is not None:\n",
    "        items_to_keep = set([str(s) for s in items_to_keep])\n",
    "\n",
    "    if stays_to_keep is not None:\n",
    "        stays_to_keep = set([str(s) for s in stays_to_keep])\n",
    "        \n",
    "    class DataStats(object):\n",
    "        def __init__(self):\n",
    "            self.curr_icustay_id = ''\n",
    "            self.curr_obs = []\n",
    "\n",
    "    data_stats = DataStats()\n",
    "\n",
    "    def write_current_observations():\n",
    "        dn = os.path.join(output_path, str(data_stats.curr_icustay_id))\n",
    "        try:\n",
    "            os.makedirs(dn)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if(table == 'PROCEDUREEVENTS_MV'):\n",
    "            fn = os.path.join(dn, 'ventilation.csv')\n",
    "        elif(table == 'OUTPUTEVENTS'):\n",
    "            fn = os.path.join(dn, 'urine.csv')\n",
    "        else:\n",
    "            fn = os.path.join(dn, 'events.csv')\n",
    "        \n",
    "        \n",
    "        if not os.path.exists(fn) or not os.path.isfile(fn):\n",
    "            f = open(fn, 'w')\n",
    "            f.write(','.join(obs_header) + '\\n')\n",
    "            f.close()\n",
    "        w = csv.DictWriter(open(fn, 'a'), fieldnames=obs_header, quoting=csv.QUOTE_MINIMAL)\n",
    "        w.writerows(data_stats.curr_obs)\n",
    "        data_stats.curr_obs = []\n",
    "\n",
    "    nb_rows_dict = {'chartevents': 330712484, 'outputevents': 4349219, 'procedureevents_mv': 258067}\n",
    "    nb_rows = nb_rows_dict[table.lower()]\n",
    "\n",
    "    for row, row_no, _ in tqdm(read_events_table_by_row(mimic3_path, table), total=nb_rows,\n",
    "                                                        desc='Processing {} table'.format(table)):\n",
    "\n",
    "        if (stays_to_keep is not None) and (row['ICUSTAY_ID'] not in stays_to_keep):\n",
    "            continue\n",
    "        if (items_to_keep is not None) and (row['ITEMID'] not in items_to_keep):\n",
    "            continue        \n",
    "        \n",
    "        if(table == 'PROCEDUREEVENTS_MV'):\n",
    "            row_out = {'SUBJECT_ID': row['SUBJECT_ID'],\n",
    "                       'HADM_ID': row['HADM_ID'],\n",
    "                       'ICUSTAY_ID': '' if 'ICUSTAY_ID' not in row else row['ICUSTAY_ID'],\n",
    "                       'STARTTIME': row['STARTTIME'],\n",
    "                       'ITEMID': row['ITEMID']}\n",
    "        \n",
    "        elif(table == 'OUTPUTEVENTS'):\n",
    "            row_out = {'SUBJECT_ID': row['SUBJECT_ID'],\n",
    "                       'HADM_ID': row['HADM_ID'],\n",
    "                       'ICUSTAY_ID': '' if 'ICUSTAY_ID' not in row else row['ICUSTAY_ID'],\n",
    "                       'CHARTTIME': row['CHARTTIME'],\n",
    "                       'ITEMID': row['ITEMID'],\n",
    "                       'VALUE': row['VALUE'],\n",
    "                       'VALUEUOM': row['VALUEUOM'],\n",
    "                        'ISERROR': row['ISERROR']}\n",
    "        \n",
    "        else:      \n",
    "            row_out = {'SUBJECT_ID': row['SUBJECT_ID'],\n",
    "                       'HADM_ID': row['HADM_ID'],\n",
    "                       'ICUSTAY_ID': '' if 'ICUSTAY_ID' not in row else row['ICUSTAY_ID'],\n",
    "                       'CHARTTIME': row['CHARTTIME'],\n",
    "                       'ITEMID': row['ITEMID'],\n",
    "                       'VALUE': row['VALUE'],\n",
    "                       'VALUENUM': row['VALUENUM'],\n",
    "                       'VALUEUOM': row['VALUEUOM'],\n",
    "                       'ERROR': row['ERROR']}\n",
    "            \n",
    "        if data_stats.curr_icustay_id != '' and data_stats.curr_icustay_id != row['ICUSTAY_ID']:\n",
    "            write_current_observations()\n",
    "        data_stats.curr_obs.append(row_out)\n",
    "        data_stats.curr_icustay_id = row['ICUSTAY_ID']\n",
    "\n",
    "    if data_stats.curr_icustay_id != '':\n",
    "        write_current_observations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Breaking up stays: 100%|██████████████████████| 136/136 [00:00<00:00, 262.71it/s]\n"
     ]
    }
   ],
   "source": [
    "break_up_stays(admissions, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemids = [223762,223761,676,677,678,679,220045,211,220210,615,618,220052,220181,225312,456,52,6702,443,220739,184,223901,454,223900,723,198,225792,225794,40055,226559,40069,226560,40094,40715,40473,40085,40057,40056,40405,40428,40086,40096,40651,226561,226584,226563,226564,226565,226567,226557,226558]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://github.com/MIT-LCP/mimic-code/blob/master/concepts/firstday/gcs_first_day.sql\n",
    "\n",
    "723  Verbal Response\n",
    "454  Motor Response\n",
    "184  Eye Opening\n",
    "198  GCS Total\n",
    "\n",
    "223900 GCS - Verbal Response\n",
    "223901 GCS - Motor Response\n",
    "220739 GCS - Eye Opening\n",
    "\n",
    "https://github.com/MIT-LCP/mimic-code/blob/master/concepts/cookbook/temp.sql\n",
    "676 -- Temperature C\n",
    "677 -- Temperature C (calc)\n",
    "678 -- Temperature F\n",
    "679 -- Temperature F (calc)\n",
    "223761 -- Temperature Fahrenheit\n",
    "223762 -- Temperature Celsius\n",
    "\n",
    "\n",
    "#TODO: review ventilation itemIDs\n",
    "https://github.com/MIT-LCP/mimic-code/blob/master/concepts/durations/ventilation_classification.sql\n",
    "¿¿226260 Mechanically Ventilated?? \n",
    "Si en chartevents.csv hay 720, 223849 -- Ventilator Mode, 223848 -- Ventilator Type\n",
    "indica que ese ICUSTAY_ID fue ventilated?\n",
    "Actual:\n",
    "225792\tInvasive Ventilation\n",
    "225794\tNon-invasive Ventilation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://github.com/MIT-LCP/mimic-code/blob/master/concepts/firstday/vitals_first_day.sql\n",
    "\n",
    "220045,211  HeartRate\n",
    "\n",
    "MAP:\n",
    "456\tNBP Mean\n",
    "52 Arterial BP Mean\n",
    "6702 Arterial BP Mean #2\n",
    "443 Manual BP Mean(calc)\n",
    "220052 Arterial Blood Pressure mean\n",
    "220181 Non Invasive Blood Pressure mean\n",
    "225312 ART BP mean\n",
    "\n",
    "RespRate:\n",
    "615 Resp Rate (Total)\n",
    "618 Respiratory Rate\n",
    "220210 Respiratory Rate\n",
    "224690 Respiratory Rate (Total)\n",
    "\n",
    "\n",
    "\n",
    "https://github.com/MIT-LCP/mimic-code/blob/master/concepts/firstday/urine_output_first_day.sql\n",
    "#TODO: revisar? ponerlos todos?\n",
    "urine(todo en mL):\n",
    "-- these are the most frequently occurring urine output observations in CareVue\n",
    "40055, -- \"Urine Out Foley\"\n",
    "43175, -- \"Urine .\"  <--- no uso\n",
    "40069, -- \"Urine Out Void\"\n",
    "40094, -- \"Urine Out Condom Cath\"\n",
    "40715, -- \"Urine Out Suprapubic\"\n",
    "40473, -- \"Urine Out IleoConduit\"\n",
    "40085, -- \"Urine Out Incontinent\"\n",
    "40057, -- \"Urine Out Rt Nephrostomy\"\n",
    "40056, -- \"Urine Out Lt Nephrostomy\"\n",
    "40405, -- \"Urine Out Other\"\n",
    "40428, -- \"Urine Out Straight Cath\"\n",
    "40086,--   Urine Out Incontinent\n",
    "40096, -- \"Urine Out Ureteral Stent #1\"\n",
    "40651, -- \"Urine Out Ureteral Stent #2\"\n",
    "\n",
    "-- these are the most frequently occurring urine output observations in MetaVision\n",
    "226559, -- \"Foley\"\n",
    "226560, -- \"Void\"\n",
    "226561, -- \"Condom Cath\"\n",
    "226584, -- \"Ileoconduit\"\n",
    "226563, -- \"Suprapubic\"\n",
    "226564, -- \"R Nephrostomy\"\n",
    "226565, -- \"L Nephrostomy\"\n",
    "226567, --  Straight Cath\n",
    "226557, -- R Ureteral Stent\n",
    "226558, -- L Ureteral Stent\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_tables = ['PROCEDUREEVENTS_MV','OUTPUTEVENTS','CHARTEVENTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic3_path = '/data/demo/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PROCEDUREEVENTS_MV table:   0%| | 753/258067 [00:00<02:31, 1695.91it/s\n",
      "Processing OUTPUTEVENTS table:   0%|  | 11320/4349219 [00:00<01:46, 40691.49it/s]\n",
      "Processing CHARTEVENTS table:   0%| | 758355/330712484 [00:06<48:51, 112551.33it/\n"
     ]
    }
   ],
   "source": [
    "#Esta celda tarda mucho, 1h aprox (para 10000 icustay_id)\n",
    "#Ejecutar solo una vez\n",
    "items_to_keep = set([int(itemid) for itemid in itemids]) \n",
    "for table in event_tables:\n",
    "    read_events_table_and_break_up_by_stays(mimic3_path, table, output_path, items_to_keep=items_to_keep,stays_to_keep=admissions.ICUSTAY_ID.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCvTmsPwbSqR"
   },
   "source": [
    "### Ahora vamos a sacar todos los datos de los variables requeridos del events,urine, ventilation, para luego mergearlos con la  información general del paciente: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "stays_root_path = 'eficienteV3_3_demo/data/root/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stays(subject_path):\n",
    "    stays = pd.read_csv(os.path.join(subject_path, 'stays.csv'))\n",
    "    return stays\n",
    "\n",
    "def read_ventilation(subject_path):\n",
    "    fn = os.path.join(subject_path, 'ventilation.csv')\n",
    "    if not os.path.exists(fn) or not os.path.isfile(fn):\n",
    "        ventilations = pd.DataFrame(columns=['SUBJECT_ID','HADM_ID','ICUSTAY_ID','STARTTIME'])         \n",
    "    else:\n",
    "        ventilations = pd.read_csv(fn)\n",
    "    return ventilations\n",
    "\n",
    "def read_urine(subject_path):\n",
    "    fn = os.path.join(subject_path, 'urine.csv')\n",
    "    if not os.path.exists(fn) or not os.path.isfile(fn):\n",
    "        urine = pd.DataFrame(columns=['SUBJECT_ID','HADM_ID','ICUSTAY_ID','URINE_TIME','URINE']) #create empty dataframe with columns name URINE    \n",
    "    else:\n",
    "        urine = pd.read_csv(fn)\n",
    "        urine=urine[urine['ISERROR'].isnull()]\n",
    "        urine=urine.rename({'CHARTTIME':'URINE_TIME', 'VALUE':'URINE'}, axis='columns')\n",
    "        urine = urine.drop(['ITEMID','VALUEUOM'],axis=1)\n",
    "\n",
    "    return urine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_events(subject_path):\n",
    "    fn = os.path.join(subject_path, 'events.csv')\n",
    "    if not os.path.exists(fn) or not os.path.isfile(fn):\n",
    "        df_temp = pd.DataFrame(columns=['SUBJECT_ID','HADM_ID','ICUSTAY_ID','TEMP_C_TIME','TEMP_C'])\n",
    "        df_hrate = pd.DataFrame(columns=['SUBJECT_ID','HADM_ID','ICUSTAY_ID','HRATE_TIME','HRATE'])\n",
    "        df_resp_rate = pd.DataFrame(columns=['SUBJECT_ID','HADM_ID','ICUSTAY_ID','RESP_RATE_TIME','RESP_RATE'])\n",
    "        df_MAP = pd.DataFrame(columns=['SUBJECT_ID','HADM_ID','ICUSTAY_ID','MAP_TIME','MAP'])\n",
    "        \n",
    "        df_GCS_E = pd.DataFrame(columns=['SUBJECT_ID','HADM_ID','ICUSTAY_ID','GCS_E_TIME','GCS_E'])\n",
    "        df_GCS_M = pd.DataFrame(columns=['SUBJECT_ID','HADM_ID','ICUSTAY_ID','GCS_M_TIME','GCS_M'])\n",
    "        df_GCS_V = pd.DataFrame(columns=['SUBJECT_ID','HADM_ID','ICUSTAY_ID','GCS_V_TIME','GCS_V'])\n",
    "        df_GCS_TOTAL_CAREVUE = pd.DataFrame(columns=['SUBJECT_ID','HADM_ID','ICUSTAY_ID','GCS_TOTAL_CAREVUE_TIME','GCS_TOTAL_CAREVUE'])\n",
    "    else:\n",
    "        events = pd.read_csv(fn)\n",
    "        events.fillna(value=np.nan, inplace=True)\n",
    "        \n",
    "        #filtrar filas con error\n",
    "        events = events.loc[(events['ERROR'] == 0.0) | (events['ERROR'].isna()) ]\n",
    "        \n",
    "        df_temp_C = events.loc[events['ITEMID'].isin([223762,676,677])]\n",
    "        df_temp_C=df_temp_C.rename({'CHARTTIME':'TEMP_C_TIME', 'VALUE':'TEMP_C'}, axis='columns')\n",
    "\n",
    "        \n",
    "        df_temp_F = events.loc[events['ITEMID'].isin([223761,678,679])].copy()\n",
    "        df_temp_F['VALUE'] = pd.to_numeric(df_temp_F['VALUE'])\n",
    "        df_temp_F['VALUE'] = (df_temp_F['VALUE']- 32) * 5 / 9  #convert fahrenheit to celsius\n",
    "        df_temp_F=df_temp_F.rename({'CHARTTIME':'TEMP_C_TIME', 'VALUE':'TEMP_C'}, axis='columns')\n",
    "        \n",
    "        df_temp = pd.concat([df_temp_C,df_temp_F])\n",
    "        df_temp = df_temp.drop(['ITEMID','VALUEUOM','VALUENUM','ERROR'],axis=1)\n",
    "\n",
    "        \n",
    "        df_hrate = events.loc[events['ITEMID'].isin([220045,211])]\n",
    "        df_hrate=df_hrate.rename({'CHARTTIME':'HRATE_TIME', 'VALUE':'HRATE'}, axis='columns')\n",
    "        df_hrate = df_hrate.drop(['ITEMID','VALUEUOM','VALUENUM','ERROR'],axis=1)\n",
    "        \n",
    "        df_resp_rate = events.loc[events['ITEMID'].isin([220210,224690,615,618])]\n",
    "        df_resp_rate=df_resp_rate.rename({'CHARTTIME':'RESP_RATE_TIME', 'VALUE':'RESP_RATE'}, axis='columns')\n",
    "        df_resp_rate = df_resp_rate.drop(['ITEMID','VALUEUOM','VALUENUM','ERROR'],axis=1)\n",
    "        \n",
    "        df_MAP = events.loc[events['ITEMID'].isin([220052,220181,225312,456,52,6702,443])]\n",
    "        df_MAP=df_MAP.rename({'CHARTTIME':'MAP_TIME', 'VALUE':'MAP'}, axis='columns')\n",
    "        df_MAP = df_MAP.drop(['ITEMID','VALUEUOM','VALUENUM','ERROR'],axis=1)\n",
    "\n",
    "        df_GCS_E = events.loc[events['ITEMID'].isin([220739,184])]\n",
    "        df_GCS_E = df_GCS_E.rename({'CHARTTIME':'GCS_E_TIME', 'VALUENUM':'GCS_E'}, axis='columns')\n",
    "        df_GCS_E = df_GCS_E.drop(['ITEMID','VALUEUOM','VALUE','ERROR'],axis=1)\n",
    "\n",
    "        \n",
    "        df_GCS_M = events.loc[events['ITEMID'].isin([223901,454])]\n",
    "        df_GCS_M=df_GCS_M.rename({'CHARTTIME':'GCS_M_TIME', 'VALUENUM':'GCS_M'}, axis='columns')\n",
    "        df_GCS_M = df_GCS_M.drop(['ITEMID','VALUEUOM','VALUE','ERROR'],axis=1)\n",
    "\n",
    "        \n",
    "        df_GCS_V = events.loc[events['ITEMID'].isin([223900,723])]\n",
    "        df_GCS_V=df_GCS_V.rename({'CHARTTIME':'GCS_V_TIME', 'VALUENUM':'GCS_V'}, axis='columns')\n",
    "        df_GCS_V = df_GCS_V.drop(['ITEMID','VALUEUOM','VALUE','ERROR'],axis=1)\n",
    "\n",
    "        \n",
    "        df_GCS_TOTAL_CAREVUE = events.loc[events['ITEMID'] == 198]\n",
    "        df_GCS_TOTAL_CAREVUE=df_GCS_TOTAL_CAREVUE.rename({'CHARTTIME':'GCS_TOTAL_CAREVUE_TIME', 'VALUENUM':'GCS_TOTAL_CAREVUE'}, axis='columns')\n",
    "        df_GCS_TOTAL_CAREVUE = df_GCS_TOTAL_CAREVUE.drop(['ITEMID','VALUEUOM','VALUE','ERROR'],axis=1)\n",
    "        \n",
    "        \n",
    "    return df_temp,df_hrate,df_resp_rate,df_MAP,df_GCS_E,df_GCS_M,df_GCS_V,df_GCS_TOTAL_CAREVUE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVyb1AABhWOu"
   },
   "source": [
    "### For each variable, the worst score across the first day in ICU should be used to tabulate OASIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "kmNIesp5tla8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# The MIT License\n",
    "\n",
    "# Copyright (c) 2015 Tom Pollard\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "# THE SOFTWARE.\n",
    "\n",
    "def compute_oasis(pd_dataframe):\n",
    "    \"\"\"\n",
    "    Takes Pandas DataFrame as an argument and computes Oxford Acute \n",
    "    Severity of Illness Score (OASIS) (http://oasisicu.com/)\n",
    "    \n",
    "    The DataFrame should include only measurements taken over the first 24h \n",
    "    from admission. pd_dataframe should contain the following columns:\n",
    "    \n",
    "    'prelos' => Pre-ICU length of stay, hours\n",
    "    'age' => Age of patient, years\n",
    "    'GCS_total' => Total Glasgow Coma Scale for patient\n",
    "    'hrate' => All heart rate measurements\n",
    "    'MAP' => All mean arterial blood pressure measurements\n",
    "    'resp_rate' => All respiratory rate measurements\n",
    "    'temp_c' => All temperature measurements, C\n",
    "    'urine' => Total urine output over 24 h (note, not consecutive measurements)\n",
    "    'ventilated' => Is patient ventilated? (y,n)\n",
    "    'admission_type' => Type of admission (elective, urgent, emergency) \n",
    "    \n",
    "    Reference:\n",
    "    Johnson AE, Kramer AA, Clifford GD. A new severity of illness scale \n",
    "    using a subset of Acute Physiology And Chronic Health Evaluation \n",
    "    data elements shows comparable predictive accuracy.\n",
    "    Crit Care Med. 2013 Jul;41(7):1711-8. doi: 10.1097/CCM.0b013e31828a24fe\n",
    "    http://www.ncbi.nlm.nih.gov/pubmed/23660729\n",
    "    \"\"\"\n",
    "    \n",
    "    # 10 variables\n",
    "    oasis_score, oasis_prelos, oasis_age, oasis_gcs, oasis_hr, oasis_map, oasis_resp, \\\n",
    "        oasis_temp, oasis_urine, oasis_vent, oasis_surg = 0,0,0,0,0,0,0,0,0,0,0   \n",
    "    # Pre-ICU length of stay, hours\n",
    "    for val in pd_dataframe['PRELOS']:\n",
    "        if val >= 4.95 and val <= 24.0:\n",
    "            oasis_prelos = np.nanmax([0,oasis_prelos])\n",
    "        elif val > 311.8:\n",
    "            oasis_prelos = np.nanmax([1,oasis_prelos])\n",
    "        elif val > 24.0 and val <= 311.8:\n",
    "            oasis_prelos = np.nanmax([2,oasis_prelos])\n",
    "        elif val >= 0.17 and val < 4.95:\n",
    "            oasis_prelos = np.nanmax([3,oasis_prelos])\n",
    "        elif val < 0.17:\n",
    "            oasis_prelos = np.nanmax([5,oasis_prelos])\n",
    "        else:\n",
    "            oasis_prelos = np.nanmax([np.nan,oasis_prelos])  \n",
    "    if pd_dataframe['PRELOS'].isnull().all():\n",
    "        oasis_prelos = np.nan \n",
    "    # Age, years\n",
    "    for val in pd_dataframe['AGE']:\n",
    "        if val < 24:\n",
    "            oasis_age = np.nanmax([0,oasis_age])\n",
    "        elif val >= 24 and val <= 53:\n",
    "            oasis_age = np.nanmax([3,oasis_age])\n",
    "        elif val > 53 and val <= 77:\n",
    "            oasis_age = np.nanmax([6,oasis_age])\n",
    "        elif val > 77 and val <= 89:\n",
    "            oasis_age = np.nanmax([9,oasis_age])\n",
    "        elif val > 89:\n",
    "            oasis_age = np.nanmax([7,oasis_age])\n",
    "        else:\n",
    "            oasis_age = np.nanmax([np.nan,oasis_age])\n",
    "\n",
    "    if pd_dataframe['AGE'].isnull().all():\n",
    "        oasis_age = np.nan \n",
    "\n",
    "    # Glasgow Coma Scale\n",
    "    for val in pd_dataframe['GCS_TOTAL']:\n",
    "        if val == 15:\n",
    "            oasis_gcs = np.nanmax([0,oasis_gcs])\n",
    "        elif val == 14:\n",
    "            oasis_gcs = np.nanmax([3,oasis_gcs])\n",
    "        elif val >= 8 and val <= 13:\n",
    "            oasis_gcs = np.nanmax([4,oasis_gcs])\n",
    "        elif val >= 3 and val <= 7:\n",
    "            oasis_gcs = np.nanmax([10,oasis_gcs])\n",
    "        else:\n",
    "            oasis_gcs = np.nanmax([np.nan,oasis_gcs])\n",
    "    if pd_dataframe['GCS_TOTAL'].isnull().all():\n",
    "        oasis_gcs = np.nan\n",
    "     \n",
    "    # Heart rate\n",
    "    for val in pd_dataframe['HRATE']:\n",
    "        if val >= 33 and val <= 88:\n",
    "            oasis_hr = np.nanmax([0,oasis_hr])\n",
    "        elif val > 88 and val <= 106:\n",
    "            oasis_hr = np.nanmax([1,oasis_hr])\n",
    "        elif val > 106 and val <= 125:\n",
    "            oasis_hr = np.nanmax([3,oasis_hr])\n",
    "        elif val < 33:\n",
    "            oasis_hr = np.nanmax([4,oasis_hr])\n",
    "        elif val > 125:\n",
    "            oasis_hr = np.nanmax([6,oasis_hr])\n",
    "        else:\n",
    "            oasis_hr = np.nanmax([np.nan,oasis_hr])\n",
    "    if pd_dataframe['HRATE'].isnull().all():\n",
    "        oasis_hr = np.nan\n",
    " \n",
    "    # Mean arterial pressure\n",
    "    for val in pd_dataframe['MAP']:\n",
    "        if val >=61.33 and val <= 143.44:\n",
    "            oasis_map = np.nanmax([0,oasis_map])\n",
    "        elif val >= 51.0 and val < 61.33:\n",
    "            oasis_map = np.nanmax([2,oasis_map])\n",
    "        elif (val >= 20.65 and val < 51.0) or (val > 143.44):\n",
    "            oasis_map = np.nanmax([3,oasis_map])\n",
    "        elif val < 20.65:\n",
    "            oasis_map = np.nanmax([4,oasis_map])\n",
    "        else:\n",
    "            oasis_map = np.nanmax([np.nan,oasis_map])\n",
    "    if pd_dataframe['MAP'].isnull().all():\n",
    "        oasis_map = np.nan\n",
    " \n",
    "    # Respiratory Rate\n",
    "    for val in pd_dataframe['RESP_RATE']:\n",
    "        if val >=13 and val <= 22:\n",
    "            oasis_resp = np.nanmax([0,oasis_resp])\n",
    "        elif (val >= 6 and val <= 12) or (val >= 23 and val <= 30):\n",
    "            oasis_resp = np.nanmax([1,oasis_resp])\n",
    "        elif val > 30 and val <= 44:\n",
    "            oasis_resp = np.nanmax([6,oasis_resp])\n",
    "        elif val > 44:\n",
    "            oasis_resp = np.nanmax([9,oasis_resp])\n",
    "        elif val < 6:\n",
    "            oasis_resp = np.nanmax([10,oasis_resp])\n",
    "        else:\n",
    "            oasis_resp = np.nanmax([np.nan,oasis_resp])\n",
    "    if pd_dataframe['RESP_RATE'].isnull().all():\n",
    "        oasis_resp = np.nan\n",
    " \n",
    "    # Temperature, C\n",
    "    for val in pd_dataframe['TEMP_C']:\n",
    "        if val >= 36.40 and val <= 36.88:\n",
    "            oasis_temp = np.nanmax([0,oasis_temp])\n",
    "        elif (val >= 35.94 and val < 36.40) or (val > 36.88 and val <= 39.88):\n",
    "            oasis_temp = np.nanmax([2,oasis_temp])\n",
    "        elif val < 33.22:\n",
    "            oasis_temp = np.nanmax([3,oasis_temp])            \n",
    "        elif val >= 33.22 and val < 35.94:\n",
    "            oasis_temp = np.nanmax([4,oasis_temp])\n",
    "        elif val > 39.88:\n",
    "            oasis_temp = np.nanmax([6,oasis_temp])\n",
    "        else:\n",
    "            oasis_temp = np.nanmax([np.nan,oasis_temp])\n",
    "    if pd_dataframe['TEMP_C'].isnull().all():\n",
    "        oasis_temp = np.nan \n",
    "\n",
    "    # Urine output, cc/day (total over 24h)\n",
    "    val = np.max(pd_dataframe['URINE'])\n",
    "    if val >=2544.0 and val <= 6896.0:\n",
    "        oasis_urine = np.nanmax([0,oasis_urine])\n",
    "    elif val >= 1427.0 and val < 2544.0:\n",
    "        oasis_urine = np.nanmax([1,oasis_urine])\n",
    "    elif val >= 671.0 and val < 1427.0:\n",
    "        oasis_urine = np.nanmax([5,oasis_urine])\n",
    "    elif val > 6896.0:\n",
    "        oasis_urine = np.nanmax([8,oasis_urine])\n",
    "    elif val < 671:\n",
    "        oasis_urine = np.nanmax([10,oasis_urine])\n",
    "    else:\n",
    "        oasis_urine = np.nanmax([np.nan,oasis_urine])\n",
    "    if pd_dataframe['URINE'].isnull().all():\n",
    "        oasis_urine = np.nan\n",
    "\n",
    "    # Ventilated y/n\n",
    "    for val in pd_dataframe['VENTILATED']:\n",
    "        if val == 'n':\n",
    "            oasis_vent = np.nanmax([0,oasis_vent])\n",
    "        elif val == 'y':\n",
    "            oasis_vent = np.nanmax([9,oasis_vent])\n",
    "        else:\n",
    "            oasis_vent = np.nanmax([np.nan,oasis_vent])\n",
    "    if pd_dataframe['VENTILATED'].isnull().all():\n",
    "        oasis_vent = np.nan \n",
    "\n",
    "    # Elective surgery y/n\n",
    "    for val in pd_dataframe['ADMISSION_TYPE']:\n",
    "        if val == 'ELECTIVE':\n",
    "            oasis_surg = np.nanmax([0,oasis_surg])\n",
    "        elif val in ['URGENT','EMERGENCY']:\n",
    "            oasis_surg = np.nanmax([6,oasis_surg])\n",
    "        else:\n",
    "            oasis_surg = np.nanmax([np.nan,oasis_surg])\n",
    "    if pd_dataframe['ADMISSION_TYPE'].isnull().all():\n",
    "        oasis_surg = np.nan \n",
    "    # Return sum\n",
    "    oasis_score = sum([oasis_prelos, oasis_age, oasis_gcs, oasis_hr, oasis_map, oasis_resp, \\\n",
    "        oasis_temp, oasis_urine, oasis_vent, oasis_surg])\n",
    "    return oasis_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "dknZwe4ueDzs"
   },
   "outputs": [],
   "source": [
    "# The MIT License\n",
    "\n",
    "# Copyright (c) 2015 Tom Pollard\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "# THE SOFTWARE.\n",
    "\n",
    "def compute_oasis_nonNAN(pd_dataframe):\n",
    "    \"\"\"\n",
    "    Takes Pandas DataFrame as an argument and computes Oxford Acute \n",
    "    Severity of Illness Score (OASIS) (http://oasisicu.com/)\n",
    "    \n",
    "    The DataFrame should include only measurements taken over the first 24h \n",
    "    from admission. pd_dataframe should contain the following columns:\n",
    "    \n",
    "    'prelos' => Pre-ICU length of stay, hours\n",
    "    'age' => Age of patient, years\n",
    "    'GCS_total' => Total Glasgow Coma Scale for patient\n",
    "    'hrate' => All heart rate measurements\n",
    "    'MAP' => All mean arterial blood pressure measurements\n",
    "    'resp_rate' => All respiratory rate measurements\n",
    "    'temp_c' => All temperature measurements, C\n",
    "    'urine' => Total urine output over 24 h (note, not consecutive measurements)\n",
    "    'ventilated' => Is patient ventilated? (y,n)\n",
    "    'admission_type' => Type of admission (elective, urgent, emergency) \n",
    "    \n",
    "    Reference:\n",
    "    Johnson AE, Kramer AA, Clifford GD. A new severity of illness scale \n",
    "    using a subset of Acute Physiology And Chronic Health Evaluation \n",
    "    data elements shows comparable predictive accuracy.\n",
    "    Crit Care Med. 2013 Jul;41(7):1711-8. doi: 10.1097/CCM.0b013e31828a24fe\n",
    "    http://www.ncbi.nlm.nih.gov/pubmed/23660729\n",
    "    \"\"\"\n",
    "    \n",
    "    # 10 variables\n",
    "    oasis_score, oasis_prelos, oasis_age, oasis_gcs, oasis_hr, oasis_map, oasis_resp, \\\n",
    "        oasis_temp, oasis_urine, oasis_vent, oasis_surg = 0,0,0,0,0,0,0,0,0,0,0   \n",
    "    # Pre-ICU length of stay, hours\n",
    "    for val in pd_dataframe['PRELOS']:\n",
    "        if val >= 4.95 and val <= 24.0:\n",
    "            oasis_prelos = np.nanmax([0,oasis_prelos])\n",
    "        elif val > 311.8:\n",
    "            oasis_prelos = np.nanmax([1,oasis_prelos])\n",
    "        elif val > 24.0 and val <= 311.8:\n",
    "            oasis_prelos = np.nanmax([2,oasis_prelos])\n",
    "        elif val >= 0.17 and val < 4.95:\n",
    "            oasis_prelos = np.nanmax([3,oasis_prelos])\n",
    "        elif val < 0.17:\n",
    "            oasis_prelos = np.nanmax([5,oasis_prelos])\n",
    "        else:\n",
    "            oasis_prelos = np.nanmax([np.nan,oasis_prelos])  \n",
    "    if pd_dataframe['PRELOS'].isnull().all():\n",
    "        oasis_prelos = np.nan \n",
    "    # Age, years\n",
    "    for val in pd_dataframe['AGE']:\n",
    "        if val < 24:\n",
    "            oasis_age = np.nanmax([0,oasis_age])\n",
    "        elif val >= 24 and val <= 53:\n",
    "            oasis_age = np.nanmax([3,oasis_age])\n",
    "        elif val > 53 and val <= 77:\n",
    "            oasis_age = np.nanmax([6,oasis_age])\n",
    "        elif val > 77 and val <= 89:\n",
    "            oasis_age = np.nanmax([9,oasis_age])\n",
    "        elif val > 89:\n",
    "            oasis_age = np.nanmax([7,oasis_age])\n",
    "        else:\n",
    "            oasis_age = np.nanmax([np.nan,oasis_age])\n",
    "\n",
    "    if pd_dataframe['AGE'].isnull().all():\n",
    "        oasis_age = np.nan \n",
    "\n",
    "    # Glasgow Coma Scale\n",
    "    for val in pd_dataframe['GCS_TOTAL']:\n",
    "        if val == 15:\n",
    "            oasis_gcs = np.nanmax([0,oasis_gcs])\n",
    "        elif val == 14:\n",
    "            oasis_gcs = np.nanmax([3,oasis_gcs])\n",
    "        elif val >= 8 and val <= 13:\n",
    "            oasis_gcs = np.nanmax([4,oasis_gcs])\n",
    "        elif val >= 3 and val <= 7:\n",
    "            oasis_gcs = np.nanmax([10,oasis_gcs])\n",
    "        else:\n",
    "            oasis_gcs = np.nanmax([np.nan,oasis_gcs])\n",
    "    if pd_dataframe['GCS_TOTAL'].isnull().all():\n",
    "        oasis_gcs = np.nan\n",
    "     \n",
    "    # Heart rate\n",
    "    for val in pd_dataframe['HRATE']:\n",
    "        if val >= 33 and val <= 88:\n",
    "            oasis_hr = np.nanmax([0,oasis_hr])\n",
    "        elif val > 88 and val <= 106:\n",
    "            oasis_hr = np.nanmax([1,oasis_hr])\n",
    "        elif val > 106 and val <= 125:\n",
    "            oasis_hr = np.nanmax([3,oasis_hr])\n",
    "        elif val < 33:\n",
    "            oasis_hr = np.nanmax([4,oasis_hr])\n",
    "        elif val > 125:\n",
    "            oasis_hr = np.nanmax([6,oasis_hr])\n",
    "        else:\n",
    "            oasis_hr = np.nanmax([np.nan,oasis_hr])\n",
    "    if pd_dataframe['HRATE'].isnull().all():\n",
    "        oasis_hr = np.nan\n",
    " \n",
    "    # Mean arterial pressure\n",
    "    for val in pd_dataframe['MAP']:\n",
    "        if val >=61.33 and val <= 143.44:\n",
    "            oasis_map = np.nanmax([0,oasis_map])\n",
    "        elif val >= 51.0 and val < 61.33:\n",
    "            oasis_map = np.nanmax([2,oasis_map])\n",
    "        elif (val >= 20.65 and val < 51.0) or (val > 143.44):\n",
    "            oasis_map = np.nanmax([3,oasis_map])\n",
    "        elif val < 20.65:\n",
    "            oasis_map = np.nanmax([4,oasis_map])\n",
    "        else:\n",
    "            oasis_map = np.nanmax([np.nan,oasis_map])\n",
    "    if pd_dataframe['MAP'].isnull().all():\n",
    "        oasis_map = np.nan\n",
    " \n",
    "    # Respiratory Rate\n",
    "    for val in pd_dataframe['RESP_RATE']:\n",
    "        if val >=13 and val <= 22:\n",
    "            oasis_resp = np.nanmax([0,oasis_resp])\n",
    "        elif (val >= 6 and val <= 12) or (val >= 23 and val <= 30):\n",
    "            oasis_resp = np.nanmax([1,oasis_resp])\n",
    "        elif val > 30 and val <= 44:\n",
    "            oasis_resp = np.nanmax([6,oasis_resp])\n",
    "        elif val > 44:\n",
    "            oasis_resp = np.nanmax([9,oasis_resp])\n",
    "        elif val < 6:\n",
    "            oasis_resp = np.nanmax([10,oasis_resp])\n",
    "        else:\n",
    "            oasis_resp = np.nanmax([np.nan,oasis_resp])\n",
    "    if pd_dataframe['RESP_RATE'].isnull().all():\n",
    "        oasis_resp = np.nan\n",
    " \n",
    "    # Temperature, C\n",
    "    for val in pd_dataframe['TEMP_C']:\n",
    "        if val >= 36.40 and val <= 36.88:\n",
    "            oasis_temp = np.nanmax([0,oasis_temp])\n",
    "        elif (val >= 35.94 and val < 36.40) or (val > 36.88 and val <= 39.88):\n",
    "            oasis_temp = np.nanmax([2,oasis_temp])\n",
    "        elif val < 33.22:\n",
    "            oasis_temp = np.nanmax([3,oasis_temp])            \n",
    "        elif val >= 33.22 and val < 35.94:\n",
    "            oasis_temp = np.nanmax([4,oasis_temp])\n",
    "        elif val > 39.88:\n",
    "            oasis_temp = np.nanmax([6,oasis_temp])\n",
    "        else:\n",
    "            oasis_temp = np.nanmax([np.nan,oasis_temp])\n",
    "    if pd_dataframe['TEMP_C'].isnull().all():\n",
    "        oasis_temp = np.nan \n",
    "\n",
    "    # Urine output, cc/day (total over 24h)\n",
    "    val = np.max(pd_dataframe['URINE'])\n",
    "    if val >=2544.0 and val <= 6896.0:\n",
    "        oasis_urine = np.nanmax([0,oasis_urine])\n",
    "    elif val >= 1427.0 and val < 2544.0:\n",
    "        oasis_urine = np.nanmax([1,oasis_urine])\n",
    "    elif val >= 671.0 and val < 1427.0:\n",
    "        oasis_urine = np.nanmax([5,oasis_urine])\n",
    "    elif val > 6896.0:\n",
    "        oasis_urine = np.nanmax([8,oasis_urine])\n",
    "    elif val < 671:\n",
    "        oasis_urine = np.nanmax([10,oasis_urine])\n",
    "    else:\n",
    "        oasis_urine = np.nanmax([np.nan,oasis_urine])\n",
    "    if pd_dataframe['URINE'].isnull().all():\n",
    "        oasis_urine = np.nan\n",
    "\n",
    "    # Ventilated y/n\n",
    "    for val in pd_dataframe['VENTILATED']:\n",
    "        if val == 'n':\n",
    "            oasis_vent = np.nanmax([0,oasis_vent])\n",
    "        elif val == 'y':\n",
    "            oasis_vent = np.nanmax([9,oasis_vent])\n",
    "        else:\n",
    "            oasis_vent = np.nanmax([np.nan,oasis_vent])\n",
    "    if pd_dataframe['VENTILATED'].isnull().all():\n",
    "        oasis_vent = np.nan \n",
    "\n",
    "    # Elective surgery y/n\n",
    "    for val in pd_dataframe['ADMISSION_TYPE']:\n",
    "        if val == 'ELECTIVE':\n",
    "            oasis_surg = np.nanmax([0,oasis_surg])\n",
    "        elif val in ['URGENT','EMERGENCY']:\n",
    "            oasis_surg = np.nanmax([6,oasis_surg])\n",
    "        else:\n",
    "            oasis_surg = np.nanmax([np.nan,oasis_surg])\n",
    "    if pd_dataframe['ADMISSION_TYPE'].isnull().all():\n",
    "        oasis_surg = np.nan \n",
    "    # Return sum\n",
    "    oasis_score = np.nansum([oasis_prelos, oasis_age, oasis_gcs, oasis_hr, oasis_map, oasis_resp, \\\n",
    "        oasis_temp, oasis_urine, oasis_vent, oasis_surg])\n",
    "    return oasis_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "yRG-GZ2opVUq"
   },
   "outputs": [],
   "source": [
    "def get_oasis_for_single_icustay_id(admission_row, hours): #take argument a Series\n",
    "    admission = admission_row.to_frame().T #T = transpose series, transform a series to dataframe\n",
    "    #limpiamos --> quedar con los mesuras tomadas dentro de un dia ---> necesito relacionar con intime --> primero merge to admission\n",
    "    #temperatura: \n",
    "    df_temp_merged = pd.merge(admission,df_temp,how='left',on=['SUBJECT_ID', 'HADM_ID','ICUSTAY_ID']) \n",
    "    df_temp_merged.drop_duplicates()\n",
    "    day_1_tmp= pd.to_datetime(df_temp_merged['TEMP_C_TIME'])-pd.to_datetime(df_temp_merged['INTIME'])\n",
    "    df_temp_merged['DAY_1']=np.round(np.abs(day_1_tmp.dt.total_seconds()/3600),1) #hours\n",
    "    df_temp_merged['DAY_1'] = df_temp_merged['DAY_1'].fillna(hours+1) #o fillna(np.nan)??\n",
    "    #df_temp_merged=df_temp_merged[df_temp_merged['day_1'] <= 24.0]\n",
    "    df_temp_merged=df_temp_merged[df_temp_merged['DAY_1'] <= hours]\n",
    "\n",
    "    df_temp_merged=df_temp_merged.drop(['DAY_1','TEMP_C_TIME'], axis=1)\n",
    "    df_temp_merged['TEMP_C'] = pd.to_numeric(df_temp_merged['TEMP_C'])\n",
    "\n",
    "    #heart rate:\n",
    "    df_hrate_merged=pd.merge(admission,df_hrate,how='left',on=['SUBJECT_ID', 'HADM_ID','ICUSTAY_ID'])\n",
    "    df_hrate_merged.drop_duplicates()\n",
    "    day_1_tmp= pd.to_datetime(df_hrate_merged['HRATE_TIME'])-pd.to_datetime(df_hrate_merged['INTIME'])\n",
    "    df_hrate_merged['DAY_1']=np.round(np.abs(day_1_tmp.dt.total_seconds()/3600),1) #hours\n",
    "    df_hrate_merged['DAY_1'] = df_hrate_merged['DAY_1'].fillna(hours+1)\n",
    "    #df_hrate_merged=df_hrate_merged[df_hrate_merged['day_1'] <= 24.0]\n",
    "    df_hrate_merged=df_hrate_merged[df_hrate_merged['DAY_1'] <= hours]\n",
    "    df_hrate_merged=df_hrate_merged.drop(['DAY_1','HRATE_TIME'], axis=1)\n",
    "\n",
    "    #respiratory rate\n",
    "    df_resp_rate_merged=pd.merge(admission,df_resp_rate,how='left',on=['SUBJECT_ID', 'HADM_ID','ICUSTAY_ID'])\n",
    "    df_resp_rate_merged.drop_duplicates()\n",
    "    day_1_tmp= pd.to_datetime(df_resp_rate_merged['RESP_RATE_TIME'])-pd.to_datetime(df_resp_rate_merged['INTIME'])\n",
    "    df_resp_rate_merged['DAY_1']=np.round(np.abs(day_1_tmp.dt.total_seconds()/3600),1) #hours\n",
    "    df_resp_rate_merged['DAY_1'] = df_resp_rate_merged['DAY_1'].fillna(hours+1)\n",
    "    #df_resp_rate_merged=df_resp_rate_merged[df_resp_rate_merged['day_1'] <= 24.0]\n",
    "    df_resp_rate_merged=df_resp_rate_merged[df_resp_rate_merged['DAY_1'] <= hours]\n",
    "    df_resp_rate_merged=df_resp_rate_merged.drop(['DAY_1','RESP_RATE_TIME'], axis=1)\n",
    "\n",
    "    #Arterial Blood Pressure mean (MAP)\n",
    "    df_MAP_merged=pd.merge(admission,df_MAP,how='left',on=['SUBJECT_ID', 'HADM_ID','ICUSTAY_ID'])\n",
    "    df_MAP_merged.drop_duplicates()\n",
    "    day_1_tmp= pd.to_datetime(df_MAP_merged['MAP_TIME'])-pd.to_datetime(df_MAP_merged['INTIME'])\n",
    "    df_MAP_merged['DAY_1']=np.round(np.abs(day_1_tmp.dt.total_seconds()/3600),1) #hours\n",
    "    df_MAP_merged['DAY_1'] = df_MAP_merged['DAY_1'].fillna(hours+1)\n",
    "    #df_MAP_merged=df_MAP_merged[df_MAP_merged['day_1'] <= 24.0]\n",
    "    df_MAP_merged=df_MAP_merged[df_MAP_merged['DAY_1'] <= hours]\n",
    "    df_MAP_merged=df_MAP_merged.drop(['DAY_1','MAP_TIME'], axis=1)\n",
    "\n",
    "    #ventilation (invasive and non invasive)\n",
    "    df_ventilated_merged=pd.merge(admission,df_ventilated,how='left',on=['SUBJECT_ID', 'HADM_ID','ICUSTAY_ID'])\n",
    "    df_ventilated_merged.drop_duplicates()\n",
    "    day_1_tmp= pd.to_datetime(df_ventilated_merged['STARTTIME'])-pd.to_datetime(df_ventilated_merged['INTIME'])\n",
    "    df_ventilated_merged['DAY_1']=np.round(np.abs(day_1_tmp.dt.total_seconds()/3600),1) #hours\n",
    "    #df_ventilated_merged['DAY_1'] = df_ventilated_merged['DAY_1'].fillna(np.nan)\n",
    "    #df_ventilated_merged=df_ventilated_merged[df_ventilated_merged['day_1'] <= 24.0]\n",
    "    df_ventilated_merged=df_ventilated_merged[~(df_ventilated_merged['DAY_1'] > hours)]\n",
    "    df_ventilated_merged=df_ventilated_merged.drop(['DAY_1'], axis=1)\n",
    "\n",
    "    df_ventilated_merged['VENTILATED'] = df_ventilated_merged['STARTTIME'].apply(lambda x: 'y' if not pd.isnull(x) else 'n')\n",
    "    df_ventilated_merged=df_ventilated_merged.drop(['STARTTIME'], axis=1)\n",
    "\n",
    "    \n",
    "\n",
    "    #GCS_total = GCS_M + GCS_V + GCS_E for metavision\n",
    "    #GCS_total = GCS  carevue\n",
    "    df_GCS_E_merged=pd.merge(admission,df_GCS_E,how='left',on=['SUBJECT_ID', 'HADM_ID','ICUSTAY_ID'])\n",
    "    df_GCS_E_merged.drop_duplicates()\n",
    "    day_1_tmp= pd.to_datetime(df_GCS_E_merged['GCS_E_TIME'])-pd.to_datetime(df_GCS_E_merged['INTIME'])\n",
    "    df_GCS_E_merged['DAY_1']=np.round(np.abs(day_1_tmp.dt.total_seconds()/3600),1) #hours\n",
    "    df_GCS_E_merged['DAY_1'] = df_GCS_E_merged['DAY_1'].fillna(hours+1)\n",
    "    #df_220739_merged=df_220739_merged[df_220739_merged['day_1'] <= 24.0]\n",
    "    df_GCS_E_merged=df_GCS_E_merged[df_GCS_E_merged['DAY_1'] <= hours]\n",
    "    df_GCS_E_merged=df_GCS_E_merged.drop(['DAY_1','GCS_E_TIME'], axis=1)\n",
    "\n",
    "\n",
    "    df_GCS_M_merged=pd.merge(admission,df_GCS_M,how='left',on=['SUBJECT_ID', 'HADM_ID','ICUSTAY_ID'])\n",
    "    df_GCS_M_merged.drop_duplicates()\n",
    "    day_1_tmp= pd.to_datetime(df_GCS_M_merged['GCS_M_TIME'])-pd.to_datetime(df_GCS_M_merged['INTIME'])\n",
    "    df_GCS_M_merged['DAY_1']=np.round(np.abs(day_1_tmp.dt.total_seconds()/3600),1) #hours\n",
    "    df_GCS_M_merged['DAY_1'] = df_GCS_M_merged['DAY_1'].fillna(hours+1)\n",
    "    #df_223901_merged=df_223901_merged[df_223901_merged['day_1'] <= 24.0]\n",
    "    df_GCS_M_merged=df_GCS_M_merged[df_GCS_M_merged['DAY_1'] <= hours]\n",
    "    df_GCS_M_merged=df_GCS_M_merged.drop(['DAY_1','GCS_M_TIME'], axis=1)\n",
    "\n",
    "    df_GCS_V_merged=pd.merge(admission,df_GCS_V,how='left',on=['SUBJECT_ID', 'HADM_ID','ICUSTAY_ID'])\n",
    "    df_GCS_V_merged.drop_duplicates()\n",
    "    day_1_tmp= pd.to_datetime(df_GCS_V_merged['GCS_V_TIME'])-pd.to_datetime(df_GCS_V_merged['INTIME'])\n",
    "    df_GCS_V_merged['DAY_1']=np.round(np.abs(day_1_tmp.dt.total_seconds()/3600),1) #hours\n",
    "    df_GCS_V_merged['DAY_1'] = df_GCS_V_merged['DAY_1'].fillna(hours+1)\n",
    "    #df_223900_merged=df_223900_merged[df_223900_merged['day_1'] <= 24.0]\n",
    "    df_GCS_V_merged=df_GCS_V_merged[df_GCS_V_merged['DAY_1'] <= hours]\n",
    "    df_GCS_V_merged=df_GCS_V_merged.drop(['DAY_1','GCS_V_TIME'], axis=1)\n",
    "\n",
    "    df_GCS_TOTAL_CAREVUE_merged=pd.merge(admission,df_GCS_TOTAL_CAREVUE,how='left',on=['SUBJECT_ID', 'HADM_ID','ICUSTAY_ID'])\n",
    "    df_GCS_TOTAL_CAREVUE_merged.drop_duplicates()\n",
    "    day_1_tmp= pd.to_datetime(df_GCS_TOTAL_CAREVUE_merged['GCS_TOTAL_CAREVUE_TIME'])-pd.to_datetime(df_GCS_TOTAL_CAREVUE_merged['INTIME'])\n",
    "    df_GCS_TOTAL_CAREVUE_merged['DAY_1']=np.round(np.abs(day_1_tmp.dt.total_seconds()/3600),1) #hours\n",
    "    df_GCS_TOTAL_CAREVUE_merged['DAY_1'] = df_GCS_TOTAL_CAREVUE_merged['DAY_1'].fillna(hours+1)\n",
    "    #df_198_merged=df_198_merged[df_198_merged['day_1'] <= 24.0]\n",
    "    df_GCS_TOTAL_CAREVUE_merged=df_GCS_TOTAL_CAREVUE_merged[df_GCS_TOTAL_CAREVUE_merged['DAY_1'] <= hours]\n",
    "    df_GCS_TOTAL_CAREVUE_merged=df_GCS_TOTAL_CAREVUE_merged.drop(['DAY_1','GCS_TOTAL_CAREVUE_TIME'], axis=1)\n",
    "\n",
    "    #TODO: importa que sean mesurados en el mismo tiempo los GCS, o solo coger el peor y ya esta??????\n",
    "    #min() de los dataframes, si es vacio retorna nan \n",
    "    #si solo esta un de los GCS? No consideramos ese GCS total: np.nan + x + y = np.nan\n",
    "    GCS_total_metavision = df_GCS_E_merged['GCS_E'].min() + df_GCS_M_merged['GCS_M'].min() + df_GCS_V_merged['GCS_V'].min()\n",
    "    GCS_total_carevue = df_GCS_TOTAL_CAREVUE_merged['GCS_TOTAL_CAREVUE'].min()\n",
    "\n",
    "\n",
    "    #total urine in 24 hours\n",
    "    df_urine_merged=pd.merge(admission,df_urine,how='left',on=['SUBJECT_ID', 'HADM_ID','ICUSTAY_ID'])\n",
    "    df_urine_merged.drop_duplicates()\n",
    "    day_1_tmp= pd.to_datetime(df_urine_merged['URINE_TIME'])-pd.to_datetime(df_urine_merged['INTIME'])\n",
    "    df_urine_merged['DAY_1']=np.round(np.abs(day_1_tmp.dt.total_seconds()/3600),1) #hours\n",
    "    df_urine_merged['DAY_1'] = df_urine_merged['DAY_1'].fillna(hours+1)\n",
    "    #df_urine_merged=df_urine_merged[df_urine_merged['day_1'] <= 24.0]\n",
    "    df_urine_merged=df_urine_merged[df_urine_merged['DAY_1'] <= hours]\n",
    "    df_urine_merged=df_urine_merged.drop(['DAY_1','URINE_TIME'], axis=1)\n",
    "    #sumamos todo para obtener total urine en 24 horas:\n",
    "    df_urine_merged['URINE'] = df_urine_merged['URINE'].sum(min_count=1)\n",
    "    #Quoting from pandas latest docs it says the min_count will be 0 for all-NA series. If you say min_count=1 then the result of the sum will be a nan.\n",
    "    #print(df_urine_merged['urine'])\n",
    "\n",
    "\n",
    "    #ultimo paso, concatenar columnas de diferentes variables para obtener un unico dataframe para compute oasis\n",
    "    df_final_merge = pd.concat([df_temp_merged, df_hrate_merged['HRATE'],df_resp_rate_merged['RESP_RATE'],df_MAP_merged['MAP'],\n",
    "                              df_ventilated_merged['VENTILATED'],df_urine_merged['URINE']], axis=1) \n",
    "\n",
    "    df_final_merge['HRATE'] = pd.to_numeric(df_final_merge['HRATE'])\n",
    "    \n",
    "    #obs Unable to parse string \">60/min retracts\", hay algunas filas con RESP_RATE = >60/min retracts los considero como 60, ya que OASIS para los >44 les asignan un mismo score \n",
    "    \n",
    "    #df_final_merge['RESP_RATE'] = pd.to_numeric(df_final_merge['RESP_RATE'])\n",
    "    df_final_merge['RESP_RATE']=df_final_merge['RESP_RATE'].apply(lambda rate: pd.to_numeric(rate) if (rate != '>60/min retracts' and rate != '>60/minute') else 60 )\n",
    "    df_final_merge['MAP'] = pd.to_numeric(df_final_merge['MAP'])\n",
    "\n",
    "\n",
    "    if np.isnan(GCS_total_metavision) and np.isnan(GCS_total_carevue):\n",
    "        GCS_total_min = np.nan\n",
    "    else:\n",
    "        GCS_total_min = np.nanmin([GCS_total_metavision,GCS_total_carevue])\n",
    "\n",
    "    df_final_merge['GCS_TOTAL'] = GCS_total_min\n",
    "\n",
    "\n",
    "    #print(df_final_merge.shape)\n",
    "    #print(df_final_merge.isnull().sum())\n",
    "    #print(df_final_merge.iloc[0:10,12:19] )\n",
    "    oasis = compute_oasis(df_final_merge)\n",
    "    oasis_nonan = compute_oasis_nonNAN(df_final_merge)\n",
    "\n",
    "    #return pd.Series({'OASIS' : oasis})\n",
    "    return pd.Series({'OASIS': oasis,'OASIS_NONAN': oasis_nonan})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating over stays:   0%|                              | 0/137 [00:00<?, ?it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:   1%|▏                     | 1/137 [00:00<00:54,  2.49it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:   1%|▎                     | 2/137 [00:00<00:38,  3.53it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:   2%|▍                     | 3/137 [00:00<00:32,  4.14it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:   3%|▋                     | 4/137 [00:00<00:29,  4.47it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:   4%|▊                     | 5/137 [00:01<00:28,  4.65it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:   4%|▉                     | 6/137 [00:01<00:29,  4.51it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:   5%|█                     | 7/137 [00:01<00:27,  4.75it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:   6%|█▎                    | 8/137 [00:01<00:27,  4.73it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:   7%|█▌                   | 10/137 [00:02<00:19,  6.36it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:   8%|█▋                   | 11/137 [00:02<00:20,  6.13it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:   9%|█▊                   | 12/137 [00:02<00:23,  5.39it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:   9%|█▉                   | 13/137 [00:02<00:23,  5.37it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  10%|██▏                  | 14/137 [00:02<00:22,  5.36it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  11%|██▎                  | 15/137 [00:03<00:22,  5.36it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  12%|██▍                  | 16/137 [00:03<00:23,  5.19it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  12%|██▌                  | 17/137 [00:03<00:26,  4.51it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  13%|██▊                  | 18/137 [00:03<00:25,  4.66it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  14%|██▉                  | 19/137 [00:03<00:24,  4.87it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  15%|███                  | 20/137 [00:04<00:26,  4.41it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  15%|███▏                 | 21/137 [00:04<00:24,  4.65it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  16%|███▎                 | 22/137 [00:04<00:23,  4.91it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  17%|███▌                 | 23/137 [00:04<00:23,  4.75it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  18%|███▋                 | 24/137 [00:05<00:28,  4.02it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating over stays:  18%|███▊                 | 25/137 [00:05<00:26,  4.28it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  19%|███▉                 | 26/137 [00:05<00:28,  3.88it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  20%|████▏                | 27/137 [00:05<00:26,  4.21it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  20%|████▎                | 28/137 [00:06<00:26,  4.18it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  21%|████▍                | 29/137 [00:06<00:23,  4.56it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  22%|████▌                | 30/137 [00:06<00:25,  4.26it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  23%|████▊                | 31/137 [00:06<00:23,  4.57it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  23%|████▉                | 32/137 [00:06<00:22,  4.75it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  24%|█████                | 33/137 [00:07<00:21,  4.89it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  25%|█████▏               | 34/137 [00:07<00:20,  5.03it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  26%|█████▎               | 35/137 [00:07<00:20,  5.08it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  26%|█████▌               | 36/137 [00:07<00:20,  4.96it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  27%|█████▋               | 37/137 [00:07<00:20,  4.79it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  28%|█████▊               | 38/137 [00:08<00:19,  5.08it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  28%|█████▉               | 39/137 [00:08<00:18,  5.18it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  29%|██████▏              | 40/137 [00:08<00:19,  5.10it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  30%|██████▎              | 41/137 [00:08<00:19,  4.96it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  31%|██████▍              | 42/137 [00:08<00:19,  4.80it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  31%|██████▌              | 43/137 [00:09<00:19,  4.79it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  32%|██████▋              | 44/137 [00:09<00:19,  4.82it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  33%|██████▉              | 45/137 [00:09<00:18,  4.90it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  34%|███████              | 46/137 [00:09<00:17,  5.15it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  34%|███████▏             | 47/137 [00:09<00:18,  4.96it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  35%|███████▎             | 48/137 [00:10<00:17,  5.12it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating over stays:  36%|███████▌             | 49/137 [00:10<00:16,  5.20it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  36%|███████▋             | 50/137 [00:10<00:17,  5.10it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  37%|███████▊             | 51/137 [00:10<00:16,  5.16it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  38%|███████▉             | 52/137 [00:10<00:16,  5.19it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  39%|████████             | 53/137 [00:10<00:14,  5.61it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  39%|████████▎            | 54/137 [00:11<00:16,  5.06it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  40%|████████▍            | 55/137 [00:11<00:16,  4.92it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  41%|████████▌            | 56/137 [00:11<00:16,  4.80it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  42%|████████▋            | 57/137 [00:11<00:16,  4.89it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  42%|████████▉            | 58/137 [00:12<00:15,  5.05it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  43%|█████████            | 59/137 [00:12<00:15,  5.18it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  44%|█████████▏           | 60/137 [00:12<00:14,  5.26it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  45%|█████████▎           | 61/137 [00:12<00:14,  5.11it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  45%|█████████▌           | 62/137 [00:12<00:14,  5.30it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  46%|█████████▋           | 63/137 [00:12<00:14,  5.20it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  47%|█████████▊           | 64/137 [00:13<00:14,  5.15it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  47%|█████████▉           | 65/137 [00:13<00:12,  5.66it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  48%|██████████           | 66/137 [00:13<00:13,  5.34it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  49%|██████████▎          | 67/137 [00:13<00:13,  5.05it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  50%|██████████▍          | 68/137 [00:13<00:13,  5.17it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  50%|██████████▌          | 69/137 [00:14<00:13,  5.13it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  51%|██████████▋          | 70/137 [00:14<00:13,  4.91it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  52%|██████████▉          | 71/137 [00:14<00:12,  5.11it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  53%|███████████          | 72/137 [00:14<00:12,  5.25it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating over stays:  53%|███████████▏         | 73/137 [00:14<00:12,  5.11it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  54%|███████████▎         | 74/137 [00:15<00:13,  4.75it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  55%|███████████▍         | 75/137 [00:15<00:12,  4.81it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  55%|███████████▋         | 76/137 [00:15<00:12,  5.02it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  56%|███████████▊         | 77/137 [00:15<00:11,  5.05it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  57%|███████████▉         | 78/137 [00:15<00:11,  5.16it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  58%|████████████         | 79/137 [00:16<00:11,  4.92it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  58%|████████████▎        | 80/137 [00:16<00:11,  4.89it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  59%|████████████▍        | 81/137 [00:16<00:10,  5.50it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  60%|████████████▌        | 82/137 [00:16<00:09,  5.63it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  61%|████████████▋        | 83/137 [00:16<00:10,  5.32it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  61%|████████████▉        | 84/137 [00:17<00:09,  5.31it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  62%|█████████████        | 85/137 [00:17<00:10,  4.97it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  63%|█████████████▏       | 86/137 [00:17<00:10,  5.02it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  64%|█████████████▎       | 87/137 [00:17<00:09,  5.03it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  64%|█████████████▍       | 88/137 [00:17<00:09,  5.20it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  65%|█████████████▋       | 89/137 [00:18<00:08,  5.35it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  66%|█████████████▊       | 90/137 [00:18<00:08,  5.48it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  66%|█████████████▉       | 91/137 [00:18<00:08,  5.69it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  67%|██████████████       | 92/137 [00:18<00:07,  5.66it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  68%|██████████████▎      | 93/137 [00:18<00:07,  5.54it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  69%|██████████████▍      | 94/137 [00:18<00:07,  5.58it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  69%|██████████████▌      | 95/137 [00:19<00:07,  5.59it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  70%|██████████████▋      | 96/137 [00:19<00:07,  5.48it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating over stays:  71%|██████████████▊      | 97/137 [00:19<00:07,  5.31it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  72%|███████████████      | 98/137 [00:19<00:07,  5.07it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  72%|███████████████▏     | 99/137 [00:19<00:07,  5.26it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  73%|██████████████▌     | 100/137 [00:20<00:07,  5.13it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  74%|██████████████▋     | 101/137 [00:20<00:07,  4.94it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  74%|██████████████▉     | 102/137 [00:20<00:07,  4.81it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  75%|███████████████     | 103/137 [00:20<00:06,  4.93it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  76%|███████████████▏    | 104/137 [00:20<00:06,  5.07it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  77%|███████████████▎    | 105/137 [00:21<00:06,  5.21it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  77%|███████████████▍    | 106/137 [00:21<00:06,  5.06it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  78%|███████████████▌    | 107/137 [00:21<00:06,  4.83it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  79%|███████████████▊    | 108/137 [00:21<00:06,  4.81it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  80%|███████████████▉    | 109/137 [00:21<00:05,  5.02it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  80%|████████████████    | 110/137 [00:22<00:05,  4.87it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  81%|████████████████▏   | 111/137 [00:22<00:05,  5.05it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  82%|████████████████▎   | 112/137 [00:22<00:04,  5.28it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  82%|████████████████▍   | 113/137 [00:22<00:04,  5.22it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  83%|████████████████▋   | 114/137 [00:22<00:04,  5.34it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  84%|████████████████▊   | 115/137 [00:22<00:04,  5.47it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  85%|████████████████▉   | 116/137 [00:23<00:03,  5.58it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  85%|█████████████████   | 117/137 [00:23<00:03,  5.63it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  86%|█████████████████▏  | 118/137 [00:23<00:03,  5.39it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  87%|█████████████████▎  | 119/137 [00:23<00:03,  5.18it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  88%|█████████████████▌  | 120/137 [00:23<00:03,  5.00it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating over stays:  88%|█████████████████▋  | 121/137 [00:24<00:03,  5.15it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  89%|█████████████████▊  | 122/137 [00:24<00:02,  5.14it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  90%|█████████████████▉  | 123/137 [00:24<00:02,  5.22it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  91%|██████████████████  | 124/137 [00:24<00:02,  5.54it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  91%|██████████████████▏ | 125/137 [00:24<00:02,  5.44it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  92%|██████████████████▍ | 126/137 [00:25<00:01,  5.57it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  93%|██████████████████▌ | 127/137 [00:25<00:01,  5.61it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  93%|██████████████████▋ | 128/137 [00:25<00:01,  5.39it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  94%|██████████████████▊ | 129/137 [00:25<00:01,  5.41it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  95%|██████████████████▉ | 130/137 [00:25<00:01,  5.15it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  96%|███████████████████ | 131/137 [00:26<00:01,  5.15it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  96%|███████████████████▎| 132/137 [00:26<00:00,  5.20it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  97%|███████████████████▍| 133/137 [00:26<00:00,  5.37it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  98%|███████████████████▌| 134/137 [00:26<00:00,  5.28it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  99%|███████████████████▋| 135/137 [00:26<00:00,  5.40it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays:  99%|███████████████████▊| 136/137 [00:26<00:00,  4.97it/s]/tmp/ipykernel_2453/3610529308.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))\n",
      "Iterating over stays: 100%|████████████████████| 137/137 [00:27<00:00,  5.04it/s]\n"
     ]
    }
   ],
   "source": [
    "#Para ejecutar en 3 partes, por si tarda mucho(en total aprox. 6h) y passa algún problema...\n",
    "#Define dataset for train:\n",
    "result_24_horas_part1 = pd.DataFrame()\n",
    "for stay_dir in tqdm(os.listdir(stays_root_path)[0:20000], desc='Iterating over stays'):\n",
    "    dn = os.path.join(stays_root_path, stay_dir)\n",
    "    try:\n",
    "        icustay_id = int(stay_dir)\n",
    "        if not os.path.isdir(dn):\n",
    "            raise Exception\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # reading tables of this icustay_id\n",
    "        stays = read_stays(os.path.join(stays_root_path, stay_dir))\n",
    "        df_temp,df_hrate,df_resp_rate,df_MAP,df_GCS_E,df_GCS_M,df_GCS_V,df_GCS_TOTAL_CAREVUE = read_events(os.path.join(stays_root_path, stay_dir))\n",
    "        df_ventilated = read_ventilation(os.path.join(stays_root_path, stay_dir))\n",
    "        df_urine = read_urine(os.path.join(stays_root_path, stay_dir))\n",
    "    \n",
    "    except:\n",
    "        sys.stderr.write('Error reading from disk for icustay_id: {}\\n'.format(icustay_id))\n",
    "        continue\n",
    "    \n",
    "    stays_oasis = stays.apply(lambda x: get_oasis_for_single_icustay_id(x, 24.0), axis=1) \n",
    "    result_24_horas_part1 = result_24_horas_part1.append(pd.concat([stays, stays_oasis], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_24_horas_part1.to_csv('result_24_horas_part1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating over stays: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Para ejecutar en 3 partes:\n",
    "#Define dataset for train:\n",
    "result_24_horas_part2 = pd.DataFrame()\n",
    "\n",
    "for stay_dir in tqdm(os.listdir(stays_root_path)[20000:40000], desc='Iterating over stays'):\n",
    "    dn = os.path.join(stays_root_path, stay_dir)\n",
    "    try:\n",
    "        icustay_id = int(stay_dir)\n",
    "        if not os.path.isdir(dn):\n",
    "            raise Exception\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # reading tables of this icustay_id\n",
    "        stays = read_stays(os.path.join(stays_root_path, stay_dir))\n",
    "        df_temp,df_hrate,df_resp_rate,df_MAP,df_GCS_E,df_GCS_M,df_GCS_V,df_GCS_TOTAL_CAREVUE = read_events(os.path.join(stays_root_path, stay_dir))\n",
    "        df_ventilated = read_ventilation(os.path.join(stays_root_path, stay_dir))\n",
    "        df_urine = read_urine(os.path.join(stays_root_path, stay_dir))\n",
    "    except:\n",
    "        sys.stderr.write('Error reading from disk for icustay_id: {}\\n'.format(icustay_id))\n",
    "        continue\n",
    "\n",
    "        \n",
    "    stays_oasis = stays.apply(lambda x: get_oasis_for_single_icustay_id(x, 24.0), axis=1) \n",
    "    result_24_horas_part2 = result_24_horas_part2.append(pd.concat([stays, stays_oasis], axis=1))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_24_horas_part2.to_csv('result_24_horas_part2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating over stays: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Para ejecutar en 3 partes:\n",
    "#Define dataset for train:\n",
    "result_24_horas_part3 = pd.DataFrame()\n",
    "\n",
    "for stay_dir in tqdm(os.listdir(stays_root_path)[40000:], desc='Iterating over stays'):\n",
    "    dn = os.path.join(stays_root_path, stay_dir)\n",
    "    try:\n",
    "        icustay_id = int(stay_dir)\n",
    "        if not os.path.isdir(dn):\n",
    "            raise Exception\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # reading tables of this icustay_id\n",
    "        stays = read_stays(os.path.join(stays_root_path, stay_dir))\n",
    "        df_temp,df_hrate,df_resp_rate,df_MAP,df_GCS_E,df_GCS_M,df_GCS_V,df_GCS_TOTAL_CAREVUE = read_events(os.path.join(stays_root_path, stay_dir))\n",
    "        df_ventilated = read_ventilation(os.path.join(stays_root_path, stay_dir))\n",
    "        df_urine = read_urine(os.path.join(stays_root_path, stay_dir))\n",
    "    except:\n",
    "        sys.stderr.write('Error reading from disk for icustay_id: {}\\n'.format(icustay_id))\n",
    "        continue\n",
    "\n",
    "        \n",
    "    stays_oasis = stays.apply(lambda x: get_oasis_for_single_icustay_id(x, 24.0), axis=1) \n",
    "    result_24_horas_part3 = result_24_horas_part3.append(pd.concat([stays, stays_oasis], axis=1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_24_horas_part3.to_csv('result_24_horas_part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_24_horas_part1=pd.read_csv('result_24_horas_part1.csv')\n",
    "result_24_horas_part2=pd.read_csv('result_24_horas_part2.csv')\n",
    "result_24_horas_part3=pd.read_csv('result_24_horas_part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_24_horas_final = pd.concat([result_24_horas_part1, result_24_horas_part2,result_24_horas_part3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_24_horas_final = pd.concat([result_24_horas_part1, result_24_horas_part2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_24_horas_final.to_csv('result_24_horas_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_24_horas_final=pd.read_csv('result_24_horas_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            0\n",
       "Unnamed: 0.1          0\n",
       "SUBJECT_ID            0\n",
       "HADM_ID               0\n",
       "ADMITTIME             0\n",
       "ADMISSION_TYPE        0\n",
       "ICUSTAY_ID            0\n",
       "INTIME                0\n",
       "LOS                  10\n",
       "AGE                   0\n",
       "PRELOS                0\n",
       "OASIS             13655\n",
       "OASIS_NONAN           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_24_horas_final.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "enviadoaprofe.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
