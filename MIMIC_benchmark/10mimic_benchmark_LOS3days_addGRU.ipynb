{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este Notebook se ejecutan los comandos necesarios para entrenar y evaluar los 4 modelos predictivos (Logistic regression, Standard LSTM, Channel-wise LSTM y Channel-wise Gru) diseñados para la tarea 'Predicción de LOS >3 días'. \n",
    "\n",
    "Nota: Para obtener los archivos en el los3.zip primero ejecuta los siguientes comandos (para más detalles véase 'pasos_de_comandos_LOS3days.txt'): \n",
    "\n",
    "1. python3 -m mimic3benchmark.scripts.extract_subjects {PATH TO MIMIC-III CSVs} data/root/\n",
    "2. python3 -m mimic3benchmark.scripts.validate_events data/root/\n",
    "3. python3 -m mimic3benchmark.scripts.extract_episodes_from_subjects data/root/\n",
    "4. python3 -m mimic3benchmark.scripts.split_train_and_test data/root/\n",
    "5. python3 -m mimic3benchmark.scripts.create_losxdays data/root/ data/{task name}/ {un entero que indica días de estancia}\n",
    "6. python3 -m mimic3models.create_normalizer_state --impute_strategy previous --n_samples -1 --output_dir . --start_time zero --store_masks --task los --timestep 1.0 --data {PATH TO data/{task name}}\n",
    "7. python -m mimic3models.split_train_val {dataset-directory}\n",
    "\n",
    "Observación: el notebook se ejecutó en Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeQbdmLS0Zo7"
   },
   "source": [
    "### Setups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "skbTlOJYYyPD",
    "outputId": "9c8774b3-8a2e-4de6-a46f-fdbececd6142"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "krgQ9OrvZOvQ",
    "outputId": "7c097014-a245-40ed-d0c5-d5902793bc87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdrive\tlos3.zip  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nHYLr1oXay5L",
    "outputId": "58e6442a-d6e8-413f-800d-3d691248312a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "%cd /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "im7Vj7Mla2cQ",
    "outputId": "222b1c41-c539-4189-9e01-21b8d8c80119"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdrive\tlos3.zip  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fRMIr3IkkRxG",
    "outputId": "22cce42b-ba5e-4b31-eeef-3d26e9cfd9c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DJHXRAXFkcsH",
    "outputId": "b7f22ee4-4c63-49e7-b034-d15679f7c967"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow \n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RUFyhwPNNNcy"
   },
   "outputs": [],
   "source": [
    "#!pip3 install tensorflow==1.15.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFkl_9YBkxLl",
    "outputId": "5988da99-9590-440b-eac2-5b19e65abf17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.1.2\n",
      "  Using cached https://files.pythonhosted.org/packages/68/89/58ee5f56a9c26957d97217db41780ebedca3154392cb903c3f8a08a52208/Keras-2.1.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.2) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.2) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.2) (1.19.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.1.2) (3.13)\n",
      "\u001b[31mERROR: textgenrnn 1.4.1 has requirement keras>=2.1.5, but you'll have keras 2.1.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: keras\n",
      "  Found existing installation: Keras 2.4.3\n",
      "    Uninstalling Keras-2.4.3:\n",
      "      Successfully uninstalled Keras-2.4.3\n",
      "Successfully installed keras-2.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6NkUGHMVkpBM",
    "outputId": "3196002a-8478-4ffe-d0e8-c5bd80515914"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UfyTRZgGa4NP",
    "outputId": "d0048e12-7bbc-4707-d844-063892dd8acb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n",
      "  inflating: los3days/train/31568_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83557_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17080_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28700_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2358_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98748_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15121_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30552_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/21123_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/21123_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8674_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/29502_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/2427_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6440_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/6440_episode8_timeseries.csv  \n",
      "  inflating: los3days/train/66043_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3977_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/4576_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18321_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/353_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/30014_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99205_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16924_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/73594_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29422_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19609_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1335_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8575_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93505_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96659_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91762_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26459_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/43827_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/97091_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71728_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44258_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11068_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30507_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/81285_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/41624_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27569_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31056_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/66662_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14480_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12706_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/62653_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98887_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/73961_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57887_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17721_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/21916_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/60326_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32679_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/55992_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/89355_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56502_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23517_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6153_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/79945_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18605_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5400_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/23466_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9966_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/84454_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15590_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16813_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16989_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/14507_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/26121_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25967_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9993_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20449_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8203_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6903_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56636_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17253_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/76707_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30248_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/67301_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/88309_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5901_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/20315_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21731_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19842_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/23938_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30907_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18693_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16112_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5013_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24687_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/24687_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/56200_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8703_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17884_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/40697_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/7138_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/20479_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/5544_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24084_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18119_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92686_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/50020_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/41205_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18739_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/11442_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/97020_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/66386_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85441_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5195_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21216_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/62608_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/94977_episode8_timeseries.csv  \n",
      "  inflating: los3days/train/12168_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/90788_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46551_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/48118_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/95747_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99268_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/41203_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27750_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/25765_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6528_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98831_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65871_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96336_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22637_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/48217_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2515_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27310_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6887_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/493_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27481_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/90455_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/78705_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/2040_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/24706_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98829_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/31397_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30268_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81660_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/8072_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31226_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23325_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/26268_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/50303_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95863_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5727_episode12_timeseries.csv  \n",
      "  inflating: los3days/train/8103_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56611_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63486_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56714_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32396_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/4557_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64970_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54945_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/43881_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6147_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5353_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85421_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18369_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12765_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52482_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/16076_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69399_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/70492_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9096_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25302_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/8543_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9873_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17282_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/1339_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/29110_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72993_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/75795_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69225_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19356_episode6_timeseries.csv  \n",
      "  inflating: los3days/train/49872_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/71262_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20133_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/28524_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45236_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77361_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91419_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/94312_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7884_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/20040_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10359_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15568_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16605_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/48040_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/47324_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4550_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22587_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93472_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32707_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/25858_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/73639_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24415_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30887_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/27795_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13745_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/84853_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/70301_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18315_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56798_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/2589_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/2589_episode6_timeseries.csv  \n",
      "  inflating: los3days/train/52079_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24258_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/73384_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/49925_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/31062_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/83514_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32434_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/22521_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/75343_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96669_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25581_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/28019_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16738_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/27143_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52021_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/40723_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11861_episode18_timeseries.csv  \n",
      "  inflating: los3days/train/7908_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/20756_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8436_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58051_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/48986_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30140_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/1205_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7029_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/778_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30222_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/51558_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56758_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/4886_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11558_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56506_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58692_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59437_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13661_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58134_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/8060_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1029_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69108_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/84983_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10111_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27887_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17161_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/62506_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54398_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19002_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27359_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1325_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18602_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24569_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19632_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/4251_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25225_episode6_timeseries.csv  \n",
      "  inflating: los3days/train/50817_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11638_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/11747_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8339_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7629_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32640_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/50041_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/8533_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58518_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8551_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14816_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23487_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27296_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9640_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21137_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8153_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23419_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23318_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/23318_episode7_timeseries.csv  \n",
      "  inflating: los3days/train/21596_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21375_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32074_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/9257_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89459_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25326_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89815_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29089_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16699_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9473_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56327_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10200_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9428_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96435_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28097_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22392_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/25307_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5986_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5846_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14587_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3619_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/42851_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/14122_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/62914_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83509_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/86561_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/25053_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20694_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26928_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/76654_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/30007_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2744_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88315_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15381_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5909_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/9821_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4696_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/81543_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10552_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28004_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6689_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21376_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10835_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8492_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/53283_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1041_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99138_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6294_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25612_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23516_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19626_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45271_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72462_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/73953_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30774_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/43691_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83258_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99383_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/1242_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/50237_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/50237_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5058_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/81449_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22058_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17384_episode7_timeseries.csv  \n",
      "  inflating: los3days/train/90798_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22963_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23895_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17978_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/10891_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71645_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/18724_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28029_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15411_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/26895_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/76240_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/70278_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22819_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/86245_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8116_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12938_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1575_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18596_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/15652_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6983_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28513_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22951_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3654_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32475_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/2762_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15644_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9518_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2042_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6116_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74059_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10236_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/99823_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/47787_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10154_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19093_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64721_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7420_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11491_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22992_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88985_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7535_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3123_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/47654_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26369_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26422_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58305_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27332_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6567_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65219_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93517_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/99562_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91469_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20643_episode19_timeseries.csv  \n",
      "  inflating: los3days/train/18673_episode10_timeseries.csv  \n",
      "  inflating: los3days/train/32339_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28523_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30408_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/78859_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13033_episode35_timeseries.csv  \n",
      "  inflating: los3days/train/13033_episode27_timeseries.csv  \n",
      "  inflating: los3days/train/85350_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/43520_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7255_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/47677_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/54041_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/48482_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28814_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/82072_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46664_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/90814_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/94142_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25579_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/49592_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28534_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98883_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7251_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/26085_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30038_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44069_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2334_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8479_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12071_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80342_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/64041_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22390_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77280_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91652_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8766_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/78273_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28265_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10244_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29239_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4740_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12365_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/66362_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65786_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27077_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/51891_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16218_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/97151_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11265_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19239_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88432_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74556_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21893_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8037_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/22732_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/24981_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64370_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/49328_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3598_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/107_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/13174_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/980_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8948_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/960_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32766_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/67150_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28241_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17290_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/51905_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2441_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21218_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13542_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22976_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20254_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24573_episode10_timeseries.csv  \n",
      "  inflating: los3days/train/26686_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27247_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/155_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/40672_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17021_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2216_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27600_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19428_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6920_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/87771_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7697_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3567_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74821_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/310_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45008_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16745_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/12532_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/10304_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23104_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21944_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65341_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14711_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/25902_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/43673_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/3302_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31559_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11214_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46755_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/549_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9388_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88446_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11109_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/85866_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20037_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4121_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10417_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/23946_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/27925_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30882_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91103_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/9440_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22570_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14330_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/4595_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31684_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/44532_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25775_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/27039_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63163_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/48996_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83358_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4904_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5904_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/62186_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/28082_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/40213_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72766_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17844_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2104_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31467_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/90688_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/90688_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58522_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13137_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31728_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28380_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59839_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59911_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2345_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/50476_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11346_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/1167_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11226_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52350_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28050_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/15514_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15355_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2022_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1540_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5211_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83120_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/6024_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/14456_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/47912_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/70463_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10651_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5099_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/75864_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/73200_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52315_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46081_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74291_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14038_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/25616_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32411_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1133_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9213_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32232_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14016_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28127_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21322_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19940_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/27353_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13599_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/13150_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28641_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54047_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/75420_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/21074_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21769_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/7067_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74733_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10088_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/22766_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19708_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28919_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81439_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52710_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/97065_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/94611_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93565_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/73478_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/53479_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28551_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72627_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1239_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91261_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2962_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9828_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/41254_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95895_episode8_timeseries.csv  \n",
      "  inflating: los3days/train/28479_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71929_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18367_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3823_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26266_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19213_episode12_timeseries.csv  \n",
      "  inflating: los3days/train/5085_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19289_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26887_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31218_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9157_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96539_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85533_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/79142_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2921_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/2921_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/84909_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13998_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/99645_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4359_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92281_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/21635_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52659_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4368_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63785_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/90699_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17933_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31670_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29483_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/2033_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/66264_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/50762_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92094_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28207_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22119_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19992_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19200_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18908_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27172_episode8_timeseries.csv  \n",
      "  inflating: los3days/train/2268_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3506_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/69344_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99781_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/54825_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/72236_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13110_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89633_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/16352_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16128_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27374_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/44644_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61913_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16881_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/67987_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/69354_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/4177_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20083_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29921_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24933_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74081_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/74081_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/4611_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27840_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32122_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/27091_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10630_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/94329_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/82851_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12095_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81763_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/808_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28676_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/48942_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14107_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1420_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56689_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/42711_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15416_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8678_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83663_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2090_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/70080_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27193_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/40854_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74945_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91738_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/25318_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7180_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/2234_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27748_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/48290_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/90649_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77132_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69082_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21974_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/42811_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85264_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8981_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99660_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/30186_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/82802_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3891_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11704_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13588_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80889_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29824_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/50767_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68396_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12655_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7241_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16106_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14467_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/14467_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1443_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32036_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2034_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/10328_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/66086_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/50065_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52777_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18526_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17138_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31729_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93724_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61764_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10674_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11538_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13781_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1788_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32576_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14240_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57664_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23706_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/13993_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/382_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26356_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/30273_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30062_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13455_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57642_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59864_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/30065_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91008_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80239_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5397_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/26324_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45280_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2222_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12627_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/746_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61677_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32272_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68784_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/67272_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6224_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/82073_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/48065_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25946_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28874_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2114_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31381_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28675_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98235_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19058_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18985_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7900_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29027_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28043_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/28043_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/47335_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18795_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9683_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1478_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/27650_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5815_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/42307_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8201_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52271_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27442_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55423_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/14967_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74687_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/79713_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91024_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/17421_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8830_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/731_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/6758_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3313_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3602_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3980_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/3980_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31700_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28729_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19797_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/86621_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19059_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/2263_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/41311_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/23242_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31051_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26108_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52530_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19666_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74679_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68356_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98362_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1224_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3791_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10751_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/70285_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61521_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20947_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/4744_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22283_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57288_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/28900_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24990_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20616_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/94046_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72143_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21948_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23568_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/72530_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1333_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30754_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/8043_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28336_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17122_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/63410_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/84319_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22987_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/28222_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/25557_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/75947_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18859_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21864_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29663_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3483_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/41359_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/24466_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92057_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32079_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5183_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/16590_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15876_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88079_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45633_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/305_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4884_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69146_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12858_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/93462_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31994_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/6189_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/82713_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11197_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12739_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28188_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7263_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54392_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12639_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77746_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/79222_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7621_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7266_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19453_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52263_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/31485_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7708_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/42091_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12528_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14101_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/69289_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/84884_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/76143_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10105_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6214_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18197_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28054_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5506_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/9580_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91199_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/15777_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56319_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/49408_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93464_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27861_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14535_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31470_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11763_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/94906_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13453_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/60413_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11966_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30044_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6448_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/97019_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30143_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4787_episode6_timeseries.csv  \n",
      "  inflating: los3days/train/96651_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/10604_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/94757_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88817_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5023_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10385_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77195_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16200_episode9_timeseries.csv  \n",
      "  inflating: los3days/train/68299_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61893_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30211_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/86717_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85452_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/42820_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18857_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/73169_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8994_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13754_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46228_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/64063_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69011_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10814_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/24099_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/24971_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89197_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71962_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28628_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/63139_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69903_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28172_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5786_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30068_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96321_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27029_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3227_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/78415_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19221_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28327_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1467_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64735_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95404_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65161_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24603_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9402_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/3254_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1180_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5443_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21672_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16914_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/73143_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17643_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64361_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64361_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/13477_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/98759_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69746_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13699_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/22322_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24377_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26696_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/67248_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7477_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/50976_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/41792_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45437_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15107_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81662_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27726_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/605_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/10774_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/10774_episode7_timeseries.csv  \n",
      "  inflating: los3days/train/17691_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92426_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11651_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19151_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89816_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/86377_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59231_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28282_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23769_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96677_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21084_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25506_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/328_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/89536_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16976_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/79602_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/47305_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11035_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8114_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52191_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/6440_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/14268_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30816_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3977_episode6_timeseries.csv  \n",
      "  inflating: los3days/train/3977_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26350_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28643_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11764_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/353_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/32303_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72941_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83154_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5155_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30751_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7960_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59986_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/55046_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29742_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10425_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/88635_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/41300_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56243_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/20481_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59036_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/9613_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18183_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13602_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26231_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26190_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32649_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44748_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68875_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93705_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/78195_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59789_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21507_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29768_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10153_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4571_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/29127_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92446_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8115_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/53502_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65565_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10635_episode11_timeseries.csv  \n",
      "  inflating: los3days/train/50087_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9727_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/9727_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/852_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/87743_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/82217_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/67926_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/76932_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25528_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27414_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26277_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/26277_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/8995_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/2336_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/82625_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25390_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85330_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13847_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99141_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10969_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24663_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18623_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92454_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12834_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13922_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/1569_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5948_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23037_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5077_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/5535_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/18764_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10489_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22371_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63896_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72408_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4805_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25217_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22761_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93045_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/75737_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22043_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/76945_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5901_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/27944_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52619_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4140_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16866_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7473_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7047_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7972_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28126_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/624_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20389_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/10229_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4765_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27690_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/7063_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7138_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/20479_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/12736_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25395_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/75796_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/42124_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7184_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1988_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/28752_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/45088_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58203_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1207_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/4166_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11478_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29656_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/62181_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28304_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3588_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25504_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13406_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17302_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21309_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10490_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/67256_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6731_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/78983_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88649_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/75181_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10904_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25863_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96083_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26220_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7051_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13718_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27770_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16732_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12396_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99100_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/6950_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/43484_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/22697_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/29025_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18006_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13487_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28790_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/54922_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/19851_episode8_timeseries.csv  \n",
      "  inflating: los3days/train/83171_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29625_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/76853_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/21150_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5727_episode17_timeseries.csv  \n",
      "  inflating: los3days/train/2403_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5080_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5872_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31821_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71774_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13239_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12954_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3432_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27758_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/9455_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99613_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/99613_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16076_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/18465_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13589_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8173_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13895_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/51582_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9873_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/464_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/82529_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3735_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95632_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7019_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11371_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30660_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12408_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/19648_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58857_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4113_episode7_timeseries.csv  \n",
      "  inflating: los3days/train/18458_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10180_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2852_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28524_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/69855_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99005_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77242_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63206_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31216_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77576_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14656_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/94135_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99322_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7031_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18780_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3078_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/70119_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/75829_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13866_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46564_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30085_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81515_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/11577_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74856_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19764_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56317_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13553_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/40433_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19246_episode7_timeseries.csv  \n",
      "  inflating: los3days/train/31724_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18121_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17582_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/53432_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/97971_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54188_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12434_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5502_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15872_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/76476_episode7_timeseries.csv  \n",
      "  inflating: los3days/train/81668_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/70133_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8749_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69851_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/74515_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13992_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6464_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11861_episode20_timeseries.csv  \n",
      "  inflating: los3days/train/11861_episode8_timeseries.csv  \n",
      "  inflating: los3days/train/262_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7908_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/11395_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/765_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31013_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98484_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23619_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15116_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8917_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57575_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96442_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/9129_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96361_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30659_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/78946_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/31392_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/78325_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23782_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22401_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64514_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98220_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/53836_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10741_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/293_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8748_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2410_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/60500_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27696_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63145_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25225_episode7_timeseries.csv  \n",
      "  inflating: los3days/train/14477_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/78260_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26017_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5370_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/14087_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/95911_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71349_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14515_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23127_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4852_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23282_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3763_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/84332_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21610_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28176_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26118_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/16462_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8551_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/52254_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29344_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74463_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/68944_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/12727_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61723_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15623_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7614_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/17533_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92352_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30107_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31719_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32581_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99023_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11752_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24400_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28371_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18370_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5349_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24042_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31413_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89575_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14115_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95011_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/41192_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93956_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85539_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27919_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/67924_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/13253_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/13514_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3147_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12935_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14571_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12330_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/96324_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12406_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13787_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10966_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99485_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14602_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/73572_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23744_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20918_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32067_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27439_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31720_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/66919_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89045_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8274_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/799_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22414_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17149_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/592_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27788_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24582_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65036_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2534_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4696_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/41982_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45032_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20832_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30740_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/414_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4240_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/70911_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96922_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13192_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/71988_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98365_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11646_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13920_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22010_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/18972_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13618_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/47157_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/41897_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/29390_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32551_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28087_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/41976_episode6_timeseries.csv  \n",
      "  inflating: los3days/train/29568_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85747_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81793_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2648_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/97917_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15458_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8206_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14828_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/14828_episode6_timeseries.csv  \n",
      "  inflating: los3days/train/15919_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/85755_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14363_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/76799_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52593_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22311_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7101_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/96429_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31651_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22936_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/89643_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55116_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/87728_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25454_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61676_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72421_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32684_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/59462_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55925_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/43459_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/47245_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30500_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83673_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13039_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24128_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/40771_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29376_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77643_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8926_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19980_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9163_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52314_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/49068_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/85361_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19879_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/587_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23797_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12878_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/67956_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/32117_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5453_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/66770_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31126_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21202_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/21202_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/8921_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/4893_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20643_episode11_timeseries.csv  \n",
      "  inflating: los3days/train/69776_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/43996_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17510_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46889_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/32565_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29035_episode8_timeseries.csv  \n",
      "  inflating: los3days/train/29035_episode6_timeseries.csv  \n",
      "  inflating: los3days/train/18232_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32199_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96149_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8001_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25997_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21138_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24504_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15246_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22624_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/24880_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5479_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26052_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/7671_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/13033_episode31_timeseries.csv  \n",
      "  inflating: los3days/train/22769_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92289_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30365_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61181_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12480_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3460_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30966_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/738_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28922_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61825_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/78934_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23985_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57308_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89894_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24074_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/28445_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69761_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/47967_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29260_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12912_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88046_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80616_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26737_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/77083_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77733_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18176_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46411_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55973_episode8_timeseries.csv  \n",
      "  inflating: los3days/train/55973_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/9272_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/66130_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65401_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21071_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26046_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52193_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24080_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12265_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/66768_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18363_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99135_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22020_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/11138_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13736_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56854_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14657_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24469_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99564_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23157_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/51833_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16396_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14493_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12259_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28834_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6495_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/49841_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/67774_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19523_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24902_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/50305_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3274_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68765_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18928_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/15881_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11201_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18790_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95834_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/13282_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17261_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/23631_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24573_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80237_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/17923_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89481_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/42694_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1715_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21965_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/17518_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63027_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3754_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/86146_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/16745_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/10331_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23417_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15422_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44421_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28907_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89712_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28447_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/21888_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/43673_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/4871_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10429_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1757_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54610_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19596_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/46449_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74164_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64550_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17451_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77129_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7537_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10417_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2479_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/85627_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/50807_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/29461_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/43540_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27201_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10426_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29584_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28082_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21220_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/22014_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/43893_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83684_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11054_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63053_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/67284_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/53193_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4910_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/10531_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/41473_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23949_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/87995_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83908_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61073_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/51746_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16406_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/49806_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25116_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/82021_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20282_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/60245_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19932_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3818_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17278_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44064_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/48687_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72714_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/91151_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12872_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20432_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12941_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10704_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/62_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15779_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7060_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/86306_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92644_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71555_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21139_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/56149_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/41246_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29795_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88857_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/3952_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/4825_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32464_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24105_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/84433_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/87213_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/60431_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91782_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31185_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/2707_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27195_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65217_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29481_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93336_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/87869_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17876_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8331_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/94541_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10088_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22449_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/22449_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54257_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6884_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/19215_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9498_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/66649_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/53554_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20886_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/50257_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/51986_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20376_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20900_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/3364_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28490_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17971_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29969_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81041_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16374_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95182_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/51458_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22227_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14617_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/7326_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6469_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2318_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12393_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80575_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9522_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19213_episode17_timeseries.csv  \n",
      "  inflating: los3days/train/19213_episode8_timeseries.csv  \n",
      "  inflating: los3days/train/14019_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/76652_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/1551_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22517_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/419_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26799_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/266_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72562_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32135_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/25477_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/21195_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/56985_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96111_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12899_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/60449_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29154_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8883_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23198_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28607_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25140_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/70191_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/11339_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/41603_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/13853_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24383_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19983_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5035_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15191_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81229_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31585_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83599_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18711_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71571_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3100_episode8_timeseries.csv  \n",
      "  inflating: los3days/train/6383_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/60598_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99781_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29202_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55111_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2859_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/67446_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/29651_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23735_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/79939_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95057_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/27217_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19098_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/5018_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88003_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26218_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/32120_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/94561_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16655_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/8798_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13494_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/74081_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7878_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14197_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/5393_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/10940_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29139_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/62126_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/76386_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/808_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/6488_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/24295_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9075_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65999_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30992_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20473_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6953_episode6_timeseries.csv  \n",
      "  inflating: los3days/train/14990_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17182_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/11043_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/22520_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/2090_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/31319_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24804_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74835_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/20536_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8852_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65449_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/25318_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/81723_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63364_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/1340_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85842_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26881_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99260_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/4290_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/53541_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/43043_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8660_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2482_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10514_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7210_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32497_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52172_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17841_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58199_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21828_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10250_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98558_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85615_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/273_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11007_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28264_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/51890_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8842_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/97518_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11550_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30405_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24772_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95611_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59198_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18469_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89931_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13227_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52957_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58995_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/90303_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32559_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26889_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5834_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25201_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/76479_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/97768_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/70111_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2256_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63280_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83182_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/58736_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10369_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16579_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/97207_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63028_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12189_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27239_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57901_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52693_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57470_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4091_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23511_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15250_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14613_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5397_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/17775_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/4954_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/4954_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/1105_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4895_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29463_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/29463_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/40071_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5976_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4833_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58702_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/82073_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32072_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/87331_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8977_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59256_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9478_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81237_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10631_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/97156_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45589_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/86326_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/41525_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30239_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/27464_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23356_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/76835_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/14229_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28043_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/17659_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58223_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58618_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21357_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17216_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/41621_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/8947_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/23761_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/66014_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/75300_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/59113_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18244_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83332_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1423_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/97828_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88294_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4512_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1213_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61379_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31700_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/3993_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19059_episode11_timeseries.csv  \n",
      "  inflating: los3days/train/15722_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/76571_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/53974_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45304_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/75817_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46576_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29372_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/19592_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93459_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/9805_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/15679_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2006_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/40216_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/62527_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5543_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8540_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9484_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15275_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55588_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5382_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58113_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28911_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19620_episode8_timeseries.csv  \n",
      "  inflating: los3days/train/17996_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24114_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/18622_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4317_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68836_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21090_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/1912_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/222_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/222_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31408_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15445_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4076_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7490_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15769_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11318_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/11318_episode17_timeseries.csv  \n",
      "  inflating: los3days/train/18353_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/83856_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/84904_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13913_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/62058_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4726_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28757_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/462_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45999_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13902_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25197_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74253_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/49552_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/82599_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31872_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91038_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8513_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/18177_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61163_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/76820_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96785_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22667_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/26349_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54393_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/240_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99499_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16194_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9256_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/29403_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/50434_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95238_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3176_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9490_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31810_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23739_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/22901_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2522_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3876_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5272_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29667_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89124_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/89124_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15832_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/65247_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/86883_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65267_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/15124_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22946_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/47357_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27643_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/88191_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29044_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8258_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/29703_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26102_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19706_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/94696_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/46566_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28073_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14101_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/84179_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/66745_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/42411_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/48420_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91199_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25473_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/13360_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52697_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/47164_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9783_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30717_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89050_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/43128_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32436_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/68922_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96746_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6206_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56134_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/70608_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/78292_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5060_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/5060_episode8_timeseries.csv  \n",
      "  inflating: los3days/train/5060_episode7_timeseries.csv  \n",
      "  inflating: los3days/train/18657_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/8698_episode6_timeseries.csv  \n",
      "  inflating: los3days/train/25009_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/6534_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18341_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4787_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/30568_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8980_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/60168_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7133_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28015_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6202_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/6202_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46797_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16163_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10197_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12028_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/42696_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46228_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/23942_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/43225_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29590_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77429_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19942_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64008_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19371_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/45410_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30616_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16691_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25725_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/23571_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/79532_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/66016_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/84266_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77781_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98196_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44851_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3151_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9548_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9400_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15476_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85685_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/81902_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11667_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27116_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54662_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14659_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16258_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/49457_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26528_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18333_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88636_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98759_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/25029_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12792_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4064_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/28848_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8827_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19714_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19897_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/15912_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28471_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28503_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59875_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/11758_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/90648_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20475_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59311_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16492_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/20573_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17385_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4449_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1453_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95726_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6440_episode7_timeseries.csv  \n",
      "  inflating: los3days/train/93755_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7423_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45157_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9487_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31751_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21391_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30181_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4431_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/50447_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45812_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99110_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12715_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/94525_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3225_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/14169_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/330_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7519_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74215_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20009_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/22017_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89167_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/86947_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3267_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/27461_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/66878_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98473_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19181_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28109_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/45186_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/67227_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8556_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/62536_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20690_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25528_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/7825_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88065_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3728_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18848_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/59537_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68450_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81562_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/75894_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44724_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/84270_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10298_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/40406_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81857_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/51027_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71514_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29668_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14677_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30648_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58389_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23405_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6799_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81938_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8914_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/41013_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5548_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93923_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4527_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/62345_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29526_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16423_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/73186_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19842_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/22300_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6317_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/84886_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6331_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/44414_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/199_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28639_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/53810_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45291_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11811_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55515_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/48038_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/61800_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9403_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/78565_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28152_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/79023_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/82563_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65490_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3132_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25433_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/42709_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/40474_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/30738_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5661_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15817_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/86662_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59630_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/94669_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3461_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1539_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15885_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56429_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26748_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12592_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18773_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3575_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8095_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17325_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5282_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9589_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98797_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12156_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92580_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18875_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91299_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2369_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/21162_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61833_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57001_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/15943_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31211_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72328_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24069_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8899_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27124_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12272_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/23120_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65086_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/969_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15460_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26861_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17341_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88826_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29110_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/26178_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/31236_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13428_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/79831_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22674_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16483_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/75819_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/78337_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5675_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1317_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8216_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26757_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14328_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/64785_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18868_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/1521_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98899_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28920_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45885_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22059_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1487_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26715_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/30299_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/15303_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/84257_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52803_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/42830_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28020_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71257_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85780_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30357_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19052_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/48100_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91158_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/13079_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77947_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/62522_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24252_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10063_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88766_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4602_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/86764_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15730_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23207_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5806_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52680_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26868_episode7_timeseries.csv  \n",
      "  inflating: los3days/train/70026_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/253_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27028_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25373_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65375_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21951_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/26167_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15352_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6607_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25708_episode7_timeseries.csv  \n",
      "  inflating: los3days/train/53359_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/62009_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44082_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15046_episode7_timeseries.csv  \n",
      "  inflating: los3days/train/56108_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11861_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25052_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8917_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/10989_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26788_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8896_episode6_timeseries.csv  \n",
      "  inflating: los3days/train/32249_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8063_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54609_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4914_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6946_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29316_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/31611_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93799_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23950_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30680_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/51004_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/18782_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4587_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/96260_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/62450_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8770_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26262_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1937_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12193_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21706_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/76261_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5131_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20920_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/63875_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55360_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64384_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81309_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12660_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91410_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9710_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3712_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16685_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45505_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/53399_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1903_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46489_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83394_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19079_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/31932_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30911_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/91465_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/22289_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/87962_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57056_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8363_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64383_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14633_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30389_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9417_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13759_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18644_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85158_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29615_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/20717_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4902_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6978_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9981_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/773_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/59943_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/49952_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/3866_episode8_timeseries.csv  \n",
      "  inflating: los3days/train/73280_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16129_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/78509_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22201_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22274_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19830_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45013_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1692_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74926_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22851_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/53716_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69483_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32590_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21056_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6237_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28180_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12820_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/13117_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17085_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17735_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/49780_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5845_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12008_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/76243_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1476_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27067_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/23209_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/79596_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15019_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46403_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14004_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21793_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23418_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19322_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/79348_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/24794_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/70763_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18224_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4696_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/34_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/9813_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81543_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/13844_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85163_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80586_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63360_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5686_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91090_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17882_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/26004_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98982_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80802_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77511_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14563_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83524_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2259_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95084_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/41619_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21002_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31966_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/44795_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24132_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/63249_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22003_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27362_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/82293_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55677_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/13920_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/16536_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/75369_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55597_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/75360_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2215_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/27904_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/79813_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22320_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83746_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/90152_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26725_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25381_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29972_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/9251_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/94734_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13168_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6895_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/86845_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95403_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27099_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/90460_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/44723_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16053_episode12_timeseries.csv  \n",
      "  inflating: los3days/train/22963_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/23895_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/8512_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/42390_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/51669_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5645_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/41383_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4577_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/23254_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88977_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30632_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13984_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29919_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27640_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32177_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46837_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81534_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18258_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/75930_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13171_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61453_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96226_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14076_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54935_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29414_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/562_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18893_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69890_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19296_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15987_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20137_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17838_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16671_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5865_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/85757_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31745_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25966_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23058_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5348_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/20643_episode8_timeseries.csv  \n",
      "  inflating: los3days/train/20643_episode6_timeseries.csv  \n",
      "  inflating: los3days/train/32317_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/8389_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2123_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15438_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29252_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/82065_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11362_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69778_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22624_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55896_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/117_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/41289_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13033_episode26_timeseries.csv  \n",
      "  inflating: los3days/train/13033_episode32_timeseries.csv  \n",
      "  inflating: los3days/train/9298_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56316_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6894_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/96686_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/9643_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3577_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23780_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55672_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/87185_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11956_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9054_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/92316_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7787_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/17481_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/511_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85845_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72992_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/11422_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28984_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12248_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95839_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55973_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/5797_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81362_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/79808_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19141_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16961_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26682_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13830_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/17514_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/97353_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/27389_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54993_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72439_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/73038_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16265_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/73249_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/90396_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2265_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/90354_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44622_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19978_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52412_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24129_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/53492_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/27836_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17127_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19583_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89100_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1598_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72725_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/82646_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80891_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25086_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29292_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11242_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/4729_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17261_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/48239_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56025_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/78100_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/42292_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91043_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/87119_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/50760_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/27247_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/9425_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1095_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56683_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44225_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/40978_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69270_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81807_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/92105_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31591_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12081_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65113_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81975_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31244_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72120_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24121_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16745_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4677_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27888_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6889_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27745_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/19433_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88928_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23851_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/75890_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68900_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68477_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98931_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30827_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32175_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12115_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21193_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24777_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91103_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/77581_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/62456_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31684_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93388_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27386_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26746_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6615_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71527_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/28519_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91181_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28958_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19786_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26155_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30763_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21129_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12149_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/90452_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12412_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/60408_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/76021_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21176_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9036_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/66068_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93970_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/90135_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17124_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1136_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72714_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/9862_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6024_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/25112_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/66338_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/59415_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31911_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/13645_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6166_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/90834_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27530_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/51439_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32420_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25862_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92644_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/12285_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80472_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81973_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5072_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/423_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/51670_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91867_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4127_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55354_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10859_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19717_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88445_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31822_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3551_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26733_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14975_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/5882_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56120_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5166_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25525_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/82784_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27043_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/27043_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64893_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59120_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29384_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14152_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24863_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17906_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/46728_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16072_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/43637_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65502_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28915_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/95933_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12807_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15141_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23546_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/53419_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/62242_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31144_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19272_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29528_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/43770_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/653_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/4579_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80518_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68251_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20944_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/22977_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12123_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14463_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8735_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93114_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22431_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23272_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95227_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/877_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/94597_episode6_timeseries.csv  \n",
      "  inflating: los3days/train/4657_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1332_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/52900_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19827_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19827_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/52260_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/28564_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4406_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20776_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/87118_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/48351_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25937_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9544_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/56204_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56545_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80320_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98001_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/90868_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89334_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21620_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6426_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16832_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/41603_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26005_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72727_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2658_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18250_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3100_episode13_timeseries.csv  \n",
      "  inflating: los3days/train/1563_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44602_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45893_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25941_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/63363_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2425_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/10693_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57143_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13930_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7702_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/76732_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/48010_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1610_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/62518_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63771_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58055_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80018_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69264_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15168_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12067_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29612_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11506_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30539_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/94956_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14927_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7897_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26817_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12220_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/90901_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83793_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/580_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/22958_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15453_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/10091_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/51841_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20528_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/21896_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2432_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27251_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24394_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59845_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/21231_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3045_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/18254_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/28264_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11949_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16718_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52551_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/51327_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/75335_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/47436_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55539_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13725_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3358_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1447_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1716_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6038_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/16624_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1004_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/87657_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1547_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32085_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5521_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13940_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2743_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/21847_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28591_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/47532_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14240_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/16283_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80174_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6860_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/86555_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57496_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/45321_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/76435_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/29338_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/24958_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/98554_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9597_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11096_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5321_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/45962_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2540_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30348_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25882_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20628_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/73068_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55954_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19549_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23309_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74562_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/21258_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65237_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99064_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46398_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16060_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69323_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/82073_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/44058_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/97144_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18922_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/97497_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1907_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27256_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/30239_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46462_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57172_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/6749_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/71821_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80551_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11312_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16381_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21436_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17512_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14450_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/49310_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9183_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3070_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/94123_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26967_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/58157_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5691_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/2846_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/84153_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7088_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83977_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/97273_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15143_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19059_episode10_timeseries.csv  \n",
      "  inflating: los3days/train/19059_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/97031_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2237_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20452_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71072_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44953_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7048_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69548_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19777_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/78229_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21244_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26851_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89092_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/62575_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1902_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20240_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7115_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32083_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9954_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24181_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/79754_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/40767_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19620_episode12_timeseries.csv  \n",
      "  inflating: los3days/train/93301_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45300_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25078_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18622_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/16420_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/222_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/156_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/67265_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74786_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44799_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/6707_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57288_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27910_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19293_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56802_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/209_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18353_episode8_timeseries.csv  \n",
      "  inflating: los3days/train/18104_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6858_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23568_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/26741_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9877_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28998_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/62402_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9688_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11479_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9882_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30754_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80745_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29083_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24249_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57337_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25076_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/73565_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/73565_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61163_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/41359_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28462_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/32425_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/23986_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/81560_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/7965_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16194_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/89268_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2497_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95238_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/26843_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31405_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20848_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68863_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28536_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32150_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/19543_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/76237_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59551_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10060_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23159_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83937_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/4332_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26735_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69727_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/79224_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3860_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/94005_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18027_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29368_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/60958_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27404_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12712_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20096_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44823_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25364_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25049_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/94696_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12000_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/46246_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14342_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/61081_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80823_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44412_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/66162_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61729_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99965_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15541_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20251_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9245_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21555_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2378_episode8_timeseries.csv  \n",
      "  inflating: los3days/train/2378_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/11135_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92933_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/94147_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21165_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71347_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31093_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5147_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13835_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15560_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19568_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/6851_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56620_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5060_episode18_timeseries.csv  \n",
      "  inflating: los3days/train/14879_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/75084_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55090_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10534_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16994_episode8_timeseries.csv  \n",
      "  inflating: los3days/train/12670_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/733_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28247_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31686_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24631_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99492_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/75627_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44413_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/19511_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16058_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52311_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9368_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26398_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/24099_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/25995_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92175_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18637_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/53600_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/5878_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13882_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10050_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22937_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7003_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21554_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17904_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7024_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32441_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/4679_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30081_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/66690_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13994_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64715_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21447_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/3442_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31380_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30034_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98040_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17683_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3080_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24285_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/56369_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17184_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/62383_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46108_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19363_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1944_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/24677_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/58570_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30170_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54320_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7883_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32605_episode6_timeseries.csv  \n",
      "  inflating: los3days/train/12984_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80142_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19897_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29057_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14117_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/87936_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30716_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95674_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/75251_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9168_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44751_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23115_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15223_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29433_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16492_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93039_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16084_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2170_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27491_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26668_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3977_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/53247_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64994_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23785_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/52503_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/66084_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96712_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22763_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54270_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93780_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74880_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/94961_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65950_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21004_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/78685_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77949_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6693_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61249_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9823_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20924_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/690_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/28228_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22152_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59385_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44265_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/24049_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/17859_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/83932_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83932_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/8791_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58240_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31664_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9032_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/16270_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98403_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26018_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/94195_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28109_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24910_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/87552_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99231_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93398_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95957_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23245_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5467_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31307_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55992_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55992_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/2314_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27414_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/84938_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16391_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/16852_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4985_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5289_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/50358_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/84742_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93272_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27002_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6070_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19142_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/10687_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/24746_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80317_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69650_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77265_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/43970_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71812_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6156_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83062_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13305_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/66080_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14950_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98605_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/87721_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/47381_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2688_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12119_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77689_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81161_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77115_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/53939_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18082_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/2031_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/53437_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/28437_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24373_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58149_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18132_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21179_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/82794_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17928_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7158_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20023_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61155_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25245_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32061_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/70864_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17788_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9273_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22285_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/22285_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30184_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5191_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64270_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55670_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/86313_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68024_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59979_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/13843_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4737_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10529_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/48527_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/10705_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59752_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/60864_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/90789_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3115_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/76437_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44511_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25229_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14858_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16330_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15642_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/97771_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92212_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/24995_episode9_timeseries.csv  \n",
      "  inflating: los3days/train/24995_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/7051_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/6511_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6718_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8965_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56861_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/50190_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55627_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71483_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59599_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26915_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98720_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2369_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18618_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23102_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80920_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22389_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/42950_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77019_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/1272_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/97239_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/47937_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59976_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/49407_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91534_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24438_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6174_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/22304_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/51687_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9950_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/787_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18679_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/477_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31054_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/21452_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61971_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14425_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89711_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30565_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/87905_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/97441_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/54971_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30660_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/22539_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20249_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74269_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4113_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/21269_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12798_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32253_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71146_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/608_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12829_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/82111_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89119_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17813_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2809_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92052_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22110_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28918_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5875_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9822_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64785_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/89419_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11018_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/26605_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19698_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/64965_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20463_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32502_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/23364_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80294_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44454_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24324_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5537_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10811_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29350_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/21458_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63721_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25113_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/22130_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/86929_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/41318_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22107_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2502_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58264_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25188_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55774_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12152_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99440_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8651_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81416_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/51933_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/356_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/26705_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/44570_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28292_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4096_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/17567_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/49496_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26868_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29284_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56840_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92787_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14300_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19937_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/66280_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1890_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21215_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63512_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69851_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/10502_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9118_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/62925_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25779_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/90070_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15046_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/77046_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11861_episode31_timeseries.csv  \n",
      "  inflating: los3days/train/11861_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/6833_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/7908_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/5170_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/72907_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5928_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19131_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31337_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96442_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46474_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22669_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30138_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/12694_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22224_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19678_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91529_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44136_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31797_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19347_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61113_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15050_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19998_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5993_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32536_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83527_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65508_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74456_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96388_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20113_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58183_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3982_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/60668_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/66001_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25337_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21706_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/13416_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/41861_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8822_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32380_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/47827_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/47827_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11638_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/1674_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4324_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25402_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/53549_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32143_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61856_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46943_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/51992_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/68944_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29967_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30911_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/81037_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9045_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31284_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7381_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/53310_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32046_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32511_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/83396_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23006_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4792_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27595_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32157_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3853_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31160_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/2704_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24714_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/18876_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30799_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96984_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65360_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10188_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27257_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57063_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68059_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/1500_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44849_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16031_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3866_episode10_timeseries.csv  \n",
      "  inflating: los3days/train/2317_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20356_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89984_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98448_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65236_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/49687_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/75891_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95045_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22855_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/1322_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2964_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23897_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/72844_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/25972_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89927_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/55910_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11759_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3832_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18068_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/58433_episode8_timeseries.csv  \n",
      "  inflating: los3days/train/27314_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12008_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/41182_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31037_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12089_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27826_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17929_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13306_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17149_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/17149_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/11991_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81601_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21094_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91842_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/20854_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56390_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20966_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/13442_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3165_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4410_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/11461_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28827_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/3096_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55746_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27519_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11512_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/64765_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6706_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/28240_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/40708_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77731_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83724_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65906_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/76028_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/55549_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22010_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/8984_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17955_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/79053_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31198_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/44732_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85042_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16680_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/82621_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3102_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19900_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/50544_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92579_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24156_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21280_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/50017_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/98656_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59318_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/62958_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29643_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24690_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15452_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29340_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/3363_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14363_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/10675_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/91588_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/29333_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2460_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/849_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11503_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25760_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65656_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56819_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2905_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/30318_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9518_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/43460_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5863_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/78956_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/785_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19150_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5975_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28588_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7795_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7454_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32613_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/48716_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/367_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2105_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19354_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12423_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57105_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/57105_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/57105_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20839_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/67956_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8663_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22360_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23394_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/15392_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/53220_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46926_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6856_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7709_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32578_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32394_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13837_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/6954_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/24436_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31000_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/87310_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85870_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80158_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7253_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54355_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56339_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1094_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46781_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22624_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/17647_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9832_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6894_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55320_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99572_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/48023_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9652_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52724_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18377_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22836_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/10247_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/14131_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14348_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28049_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/50026_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29219_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24907_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1158_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/15566_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/19990_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10340_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68645_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3708_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89725_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/949_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/83310_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63320_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/77325_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29987_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/823_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/70485_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/46411_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/854_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/65401_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/7799_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5426_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96430_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/60600_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16009_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27355_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14626_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/97353_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/4653_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77355_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/48693_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/19278_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92253_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23725_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/48238_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/48523_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11683_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/43274_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10852_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/59762_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/73129_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/67771_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/494_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/84350_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/9030_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/22385_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/94575_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/96181_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30550_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27390_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/109_episode22_timeseries.csv  \n",
      "  inflating: los3days/train/20620_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72202_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24573_episode8_timeseries.csv  \n",
      "  inflating: los3days/train/40187_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32713_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64172_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54050_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/87348_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11049_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/15298_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29142_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/10255_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19310_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/88500_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18982_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/19127_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32529_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5832_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19965_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74866_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27379_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/94539_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/41520_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28648_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93550_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27745_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/3722_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/47941_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77771_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16349_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19670_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29541_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16992_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/49854_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1990_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31364_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3205_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15982_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17470_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54120_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4430_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95071_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30286_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20908_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/76711_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6076_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18322_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31833_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63733_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/79878_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22074_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17946_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74955_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/17236_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/40644_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20176_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8915_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32287_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/10305_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/29050_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/22351_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/76899_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/66772_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/84686_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/346_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/8057_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/26590_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11957_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/89697_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/50216_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59716_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/8817_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46188_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45346_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22866_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21067_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3753_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58308_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/2176_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28412_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3952_episode9_timeseries.csv  \n",
      "  inflating: los3days/train/3952_episode7_timeseries.csv  \n",
      "  inflating: los3days/train/23023_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/88265_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29918_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32674_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/70337_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71013_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27075_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/902_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64673_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/79591_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14166_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5377_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9498_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27101_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80260_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/91258_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26594_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7479_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/51776_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/653_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4267_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/10727_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16625_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/49562_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26263_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/95895_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26995_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72795_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/90111_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20975_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/47643_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1639_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12203_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22064_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12312_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26023_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14205_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5662_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4798_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80048_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/51826_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31293_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3892_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8493_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26571_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13806_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13586_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15070_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52249_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/60274_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/6155_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/22119_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/29861_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/63792_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18250_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/18250_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/3100_episode12_timeseries.csv  \n",
      "  inflating: los3days/train/21489_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52687_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27172_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/1620_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/79905_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/70469_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29983_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17476_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13026_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21502_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2806_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25196_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6054_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/76797_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59448_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/98518_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/3830_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28250_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29209_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22919_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30608_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/48999_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/28065_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/99822_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30175_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17286_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12125_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/7574_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/808_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/48539_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95931_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16676_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52453_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/45419_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65015_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4422_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29137_episode6_timeseries.csv  \n",
      "  inflating: los3days/train/11043_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/47146_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/50445_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5074_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/5074_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27251_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/64714_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26372_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16892_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68663_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14662_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8686_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/48177_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/67624_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18559_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/67386_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26362_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55440_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27603_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25016_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98103_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/8324_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2219_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3393_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/14892_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8895_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28543_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3008_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85370_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16561_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80181_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/87060_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/904_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/78670_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30120_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19812_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89132_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29164_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/66275_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52730_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12726_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85027_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14267_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4374_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32665_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/43923_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68065_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56179_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/13995_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6655_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32349_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59937_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72233_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/2116_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/9194_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1163_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/1047_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23693_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93647_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2568_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19950_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29900_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13055_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6251_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1021_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/62648_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1028_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21432_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10823_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/40303_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26215_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11819_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63572_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/66787_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14161_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95603_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31336_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/27981_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/13499_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/47257_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/66507_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/84071_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9321_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55136_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88532_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12226_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45835_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64327_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8947_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20510_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9910_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1853_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46119_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99165_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11647_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3995_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91705_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/23109_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13226_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64656_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/87602_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5922_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/50391_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/12467_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77691_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54883_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28892_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23177_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15418_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/53676_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80267_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/49750_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26856_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57858_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/50479_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32594_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7009_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/80963_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27034_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12686_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46850_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28939_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/5104_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17382_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83919_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/60049_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46278_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7595_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1357_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/6286_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1709_episode6_timeseries.csv  \n",
      "  inflating: los3days/train/23575_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20947_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/28807_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/76477_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18065_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29046_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18805_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99995_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/50191_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11318_episode12_timeseries.csv  \n",
      "  inflating: los3days/train/18849_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1985_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24374_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/12257_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13011_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68285_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16535_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99258_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6943_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/87053_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/67117_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81303_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/84838_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/82150_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7493_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71702_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11563_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69501_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23959_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2569_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13330_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/24762_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22667_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/528_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32425_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/82593_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88510_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92649_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31942_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/90046_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91992_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13241_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/43724_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/305_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/69896_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/78476_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/82090_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/82436_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28100_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10679_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19472_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/41027_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16081_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1758_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4562_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18750_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/164_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/47748_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/83272_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27266_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32775_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/25950_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/67134_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23476_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23382_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14664_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31123_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/42075_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/75714_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/53787_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/70226_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74012_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21977_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/750_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46851_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81904_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/49471_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18570_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/18570_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64295_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/172_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88851_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24198_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/25492_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46845_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/78473_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5060_episode9_timeseries.csv  \n",
      "  inflating: los3days/train/21144_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/48253_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93632_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/279_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15068_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/97381_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13325_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9646_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96877_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/73558_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30464_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/5774_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/97978_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12240_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/86927_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26095_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/24327_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15922_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91210_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10197_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/10642_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/22960_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31254_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46446_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20381_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89428_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10721_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/10814_episode6_timeseries.csv  \n",
      "  inflating: los3days/train/9811_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74388_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11288_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/21634_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8882_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54147_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29896_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/73559_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/87779_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19824_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5319_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/61846_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/859_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12399_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45933_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17072_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/82451_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13861_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/17041_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/41457_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3475_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/87631_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4606_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/73654_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16001_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/43566_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30708_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30986_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7160_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7390_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16982_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/49225_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89037_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93900_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7630_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16856_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/4064_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/22297_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81025_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/86866_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25739_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/84427_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24228_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/76173_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30829_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/31139_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/20582_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13592_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26631_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28484_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10264_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71139_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25886_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11474_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/57920_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30552_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12933_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29225_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71307_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26803_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/84721_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29175_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9259_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89187_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16811_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32070_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98864_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/79016_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15677_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9584_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/11737_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22540_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31626_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23059_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8579_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8168_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57711_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4195_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88678_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68209_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21749_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13552_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/23860_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26237_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26390_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2793_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/70682_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63167_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23590_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68998_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80957_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/94264_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/60603_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15507_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69698_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21758_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/41024_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/28109_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/24193_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29491_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17206_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/1778_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/94016_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/55992_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/58917_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15946_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24663_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/28423_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/20436_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27899_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22662_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71384_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57158_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26521_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10889_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64700_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46163_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69943_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96817_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5425_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7289_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/62561_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72532_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21667_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/3488_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/67819_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26317_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28122_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99674_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11141_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20005_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28165_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58362_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2223_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/77850_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32599_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/76646_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26593_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15805_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26136_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71614_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4364_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20471_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20389_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16024_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91101_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23197_episode8_timeseries.csv  \n",
      "  inflating: los3days/train/23197_episode7_timeseries.csv  \n",
      "  inflating: los3days/train/31339_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7138_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/42956_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/67423_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21797_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16684_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/42141_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9021_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8952_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/79427_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1988_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/72860_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26479_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32092_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31551_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24514_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13373_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/25698_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/86359_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45176_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/26913_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2373_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4900_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/3242_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/3242_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/84501_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24379_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15079_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21753_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/79837_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/40286_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12666_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54783_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10220_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/70386_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12880_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15013_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56593_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31258_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3320_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31705_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54755_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/87263_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28256_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19047_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23474_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68785_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/82815_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5727_episode16_timeseries.csv  \n",
      "  inflating: los3days/train/5727_episode8_timeseries.csv  \n",
      "  inflating: los3days/train/67375_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/42870_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7107_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/94530_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/15975_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31916_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74252_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/65890_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13234_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/86108_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19850_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19677_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8907_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19922_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/723_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22528_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9172_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93011_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63947_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/70303_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/87008_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16164_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/366_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4041_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14130_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/82075_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13480_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/638_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/47965_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7915_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6543_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/89419_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/7410_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31793_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19113_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61991_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24546_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21771_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/388_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95465_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18744_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15441_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/5712_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/31627_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30329_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/62028_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14862_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63969_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9271_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/5775_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12713_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/74793_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57637_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/91373_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6838_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16351_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/8581_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/9725_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15071_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25546_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64846_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4656_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14332_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12191_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99464_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/28576_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5593_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11861_episode22_timeseries.csv  \n",
      "  inflating: los3days/train/11861_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/28741_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74779_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56613_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6477_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/78152_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/550_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/53833_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/41508_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7365_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80024_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29633_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17231_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24141_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/74514_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/46466_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29639_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29316_episode6_timeseries.csv  \n",
      "  inflating: los3days/train/73429_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19206_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72067_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22423_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/29374_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31049_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29365_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18418_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96260_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/3029_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/75350_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/132_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95410_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24167_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5415_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30979_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20006_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29706_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25225_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/25225_episode9_timeseries.csv  \n",
      "  inflating: los3days/train/93662_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29007_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24048_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80257_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23947_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7689_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30089_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44128_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31260_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/1008_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68958_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26118_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/69585_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12733_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6283_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/30396_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/70957_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20731_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21734_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/53650_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/17273_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9951_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83335_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26927_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23368_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98228_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/49261_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24204_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46000_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6697_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/64216_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26720_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18120_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80983_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24714_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/9981_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/26337_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/4242_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56703_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3306_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/84355_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/51039_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2950_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17139_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83509_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/10487_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/86561_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28180_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/20792_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54187_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/76974_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14615_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20384_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23954_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3463_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58433_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/28119_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85444_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23167_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19207_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28864_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/913_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26311_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9059_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14322_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14252_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52726_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68602_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69447_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/28980_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85402_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5391_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/70332_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/40582_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63944_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63130_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72083_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/63494_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29476_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27399_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/27094_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13905_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20584_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/53119_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/10731_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44951_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5058_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/41976_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/75534_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89193_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8656_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/86780_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71287_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17009_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10739_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/75444_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61111_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/70330_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5317_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15411_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/94665_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54900_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28698_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/50093_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/29575_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16075_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20327_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6939_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2460_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/7920_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54003_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32453_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/42491_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89493_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/25520_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72545_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/23828_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29553_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/68907_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/41070_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88731_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32180_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7573_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98187_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54289_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4935_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/679_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52156_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13186_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21202_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/19080_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14516_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/9704_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57985_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/4081_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58217_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26271_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/57546_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5264_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25658_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/60046_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99178_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29141_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/6398_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6243_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/55920_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/9278_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/71676_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21138_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/58732_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/8643_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13033_episode16_timeseries.csv  \n",
      "  inflating: los3days/train/63921_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/42924_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3836_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1173_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17977_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17977_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/6673_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26691_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16188_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57203_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15814_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3913_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/87704_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11066_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/83751_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/13569_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96140_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1299_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/87344_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/78356_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65353_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52861_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19029_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/5969_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11549_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8228_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/78173_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92449_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/97382_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10386_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/87308_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93093_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/53944_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85298_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9602_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20778_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8800_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/9960_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14256_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/70705_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21813_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8037_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/49328_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/31031_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/51605_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/918_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7166_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9030_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/26949_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83960_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/94575_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/77471_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/50718_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13408_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/18897_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26795_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6743_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/49024_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/109_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/18103_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44383_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61421_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54788_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21303_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68916_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77882_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16000_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85889_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/42694_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/548_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/67348_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/19458_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/97132_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2253_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/82057_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61620_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/30642_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/67216_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/79826_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/66283_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/47045_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/16712_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29088_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31110_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/84208_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24868_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/26695_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85490_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/79565_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29426_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/29426_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/20046_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/70104_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17130_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24408_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54368_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/50164_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/51301_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45213_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/86848_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7230_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/81157_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22695_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61771_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/97263_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16463_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7245_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16117_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23949_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/24110_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91309_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/203_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/14813_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28650_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9036_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/346_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8823_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10541_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44064_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/98402_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/49999_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20804_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81778_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22442_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/17574_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/40703_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/90115_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4802_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17651_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/26435_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74575_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8808_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26059_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68234_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3365_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/86413_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85714_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92590_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8204_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44706_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9619_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10088_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/5611_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25191_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4208_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14827_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57773_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71652_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11048_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9828_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/92007_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24548_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45162_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22406_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2863_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72324_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29540_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72997_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2921_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/13998_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26260_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18524_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27529_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21104_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24343_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12915_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74444_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10633_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9250_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68623_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13794_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/62084_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11844_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16860_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/16860_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/29861_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/72760_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27172_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/31382_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27458_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6626_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24727_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16881_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/65476_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24361_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16348_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58167_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/40586_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8200_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68641_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71713_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7789_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52109_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/28676_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/6598_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/875_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/88888_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31521_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/58218_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21450_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18763_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/48833_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9812_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92947_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/43741_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4363_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/77500_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12566_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/21410_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25534_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16642_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28185_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19642_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/47848_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/51180_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/93833_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46671_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3045_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23251_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18254_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/4002_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2092_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/29299_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11255_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/10445_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46600_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65112_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31262_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/46854_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/82175_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/75762_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/79426_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30120_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/20361_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21900_episode6_timeseries.csv  \n",
      "  inflating: los3days/train/90865_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7492_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72224_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7670_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20263_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54736_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28626_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/805_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/24806_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/51948_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24958_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/13819_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59005_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80020_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92775_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/47520_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89585_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17990_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8489_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23110_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18094_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/18094_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92379_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74918_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2938_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4954_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/25814_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7294_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54385_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21925_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74509_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30590_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/17018_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/41567_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1147_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17292_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/48636_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1593_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20777_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32709_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96553_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/48189_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14265_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63103_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15819_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28416_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/49082_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88483_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7226_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20152_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23046_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18774_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19059_episode7_timeseries.csv  \n",
      "  inflating: los3days/train/73126_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5504_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99756_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29465_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65050_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28944_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/31030_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/82585_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24237_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9484_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/7009_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/606_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8366_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68356_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/30021_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28093_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5778_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22056_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/79038_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61182_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14457_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24639_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/78536_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5138_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/6927_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46532_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92984_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28526_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19765_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12136_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72836_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9865_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/19520_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31841_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28680_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/94046_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/1415_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7809_episode17_timeseries.csv  \n",
      "  inflating: los3days/train/13529_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12184_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17198_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6736_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/12252_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1331_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/96171_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23983_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/94950_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7118_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/58528_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26781_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31829_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17782_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11855_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19251_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8861_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21335_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21423_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18921_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/13330_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/24286_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11154_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99293_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89992_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/23986_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8124_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2362_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11860_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/17210_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2005_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29809_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20501_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14058_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4992_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3056_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12773_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/94024_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21662_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72300_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64927_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6699_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91975_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44820_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57911_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/7187_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54768_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4151_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/23258_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98336_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/15796_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/93945_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/40239_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16945_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22497_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/89600_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25323_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10366_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1407_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29305_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9283_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14847_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54797_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/92551_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/73375_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24198_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/90890_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/11464_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20230_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/82579_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44373_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1359_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65669_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/63482_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4599_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10461_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3466_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9312_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17436_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6686_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4421_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2573_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19646_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16200_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/12567_episode9_timeseries.csv  \n",
      "  inflating: los3days/train/32725_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24712_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21935_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1354_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/22368_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29130_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25299_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/25725_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95977_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10513_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17993_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/51200_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16776_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19201_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21593_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/47918_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9594_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5308_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/48398_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3319_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19995_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/64485_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22640_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27499_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/19208_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27106_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/9249_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/27725_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/73713_episode14_timeseries.csv  \n",
      "  inflating: los3days/train/13091_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13616_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/40967_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4784_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/97683_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/90479_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/95767_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/71558_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28667_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/558_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99509_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15473_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19104_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/94908_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/81662_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/99611_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9485_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/43065_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/68109_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96540_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25415_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/13919_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1996_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2457_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10415_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10565_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/57669_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19385_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83879_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14749_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15736_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/19319_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/69574_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3036_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8682_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/88009_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27185_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13236_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56210_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6933_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17496_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52631_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10664_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/31295_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/83382_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/70731_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/67858_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3267_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/65732_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24061_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32486_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/6279_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/22941_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/18721_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/99231_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/17721_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8556_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/48939_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17815_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/54641_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29621_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/56502_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/23278_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/3728_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/26929_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28216_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17287_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27440_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/13825_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59590_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30964_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/30651_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/42819_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/79089_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/96238_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/46667_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/17089_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/2355_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12605_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16367_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24908_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27576_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/4147_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21543_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16687_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/31332_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/5901_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/14836_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/59710_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/85753_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72582_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/71889_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/40599_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/7666_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/6331_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/98198_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/28608_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32096_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/16560_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/9915_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26860_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/86645_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/28168_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/44206_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/97542_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5544_episode4_timeseries.csv  \n",
      "  inflating: los3days/train/19923_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/32421_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/27894_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/5195_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/24986_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/27666_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/31061_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/82459_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21717_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/15220_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8753_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/20386_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/14177_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/29645_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/4900_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/46287_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/42357_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/30075_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/45477_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/5096_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/74230_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/80511_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/20611_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/8070_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/26160_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/67554_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/91855_episode5_timeseries.csv  \n",
      "  inflating: los3days/train/40837_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/24476_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/21277_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/44787_episode3_timeseries.csv  \n",
      "  inflating: los3days/train/26220_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/24995_episode7_timeseries.csv  \n",
      "  inflating: los3days/train/76381_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/11922_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/9969_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10609_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/25482_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/19461_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/12378_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/61791_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/51544_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/52751_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/72897_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/1212_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/10947_episode2_timeseries.csv  \n",
      "  inflating: los3days/train/10947_episode1_timeseries.csv  \n",
      "  inflating: los3days/train/43874_episode1_timeseries.csv  \n"
     ]
    }
   ],
   "source": [
    "!unzip los3.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IIqxsOkmGIQR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pXKhqd3XZ4Uk",
    "outputId": "ccf747d1-a1df-436f-eb23-8eee05ce2ed8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/MyDrive/MIMIC_benchmark\n"
     ]
    }
   ],
   "source": [
    "%cd /content/gdrive/MyDrive/MIMIC_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xbC1jyIMaGau",
    "outputId": "ba3be371-ecd3-4b2d-cc7d-977e7a054bf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50epochsOutputLSTMMortality.txt\n",
      "data\n",
      "ihm_results_channelWise_epoch34.json\n",
      "ihm_results_channelWise_gru_epoch20.json\n",
      "ihm_results_evaluation_channelWise_epoch14.json\n",
      "ihm_results_evaluation_logistic.json\n",
      "ihm_results_lstm_epoch33.json\n",
      "LICENSE\n",
      "los3days_results_channelWise_lstm_epoch28.json\n",
      "los3days_results_channelWise_lstm.json\n",
      "los3days_results_logistic.json\n",
      "los3days_results_lstm_epoch35.json\n",
      "los3days_results_lstm.json\n",
      "los7days_results_channelWise_lstm.json\n",
      "los7days_results_logistic.json\n",
      "los7days_results_lstm.json\n",
      "los_results_channelWise.json\n",
      "los_results_logistic.json\n",
      "los_results_lstm.json\n",
      "mimic3benchmark\n",
      "mimic3models\n",
      "README.md\n",
      "requirements.txt\n",
      "scripts_pipeline_forLOS3days.txt\n",
      "scripts_pipeline_forLOS7days.txt\n",
      "scripts_pipeline_forLOSCustomized.txt\n",
      "scripts_pipeline.txt\n",
      "statistics.md\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ggSPBW6VVUo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6kHL0gI4VVfF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVCFO90JVVzX"
   },
   "source": [
    "## Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NE6zozjy_bXS",
    "outputId": "9ef56691-7160-4a64-ce0c-2269098a9db3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(C=0.001, data='/content/los3days', features='all', l2=True, output_dir='mimic3models/los3days/logistic', period='all')\n",
      "Reading data and extracting features ...\n",
      "  train data shape = (24490, 714)\n",
      "  validation data shape = (5356, 714)\n",
      "  test data shape = (5282, 714)\n",
      "Imputing missing values ...\n",
      "Normalizing the data to have zero mean and unit variance ...\n",
      "confusion matrix:\n",
      "[[13208  1871]\n",
      " [ 4577  4834]]\n",
      "accuracy = 0.7367088794708252\n",
      "precision class 0 = 0.7426483035087585\n",
      "precision class 1 = 0.7209545373916626\n",
      "recall class 0 = 0.8759201765060425\n",
      "recall class 1 = 0.5136542320251465\n",
      "AUC of ROC = 0.7750246111104193\n",
      "AUC of PRC = 0.6866349101668249\n",
      "min(+P, Se) = 0.6442154467226177\n",
      "confusion matrix:\n",
      "[[2832  422]\n",
      " [1045 1057]]\n",
      "accuracy = 0.7261015772819519\n",
      "precision class 0 = 0.7304617166519165\n",
      "precision class 1 = 0.7146720886230469\n",
      "recall class 0 = 0.8703134655952454\n",
      "recall class 1 = 0.5028544068336487\n",
      "AUC of ROC = 0.7624535300767205\n",
      "AUC of PRC = 0.6746714589723846\n",
      "min(+P, Se) = 0.6450999048525214\n",
      "confusion matrix:\n",
      "[[2823  417]\n",
      " [ 979 1063]]\n",
      "accuracy = 0.7357061505317688\n",
      "precision class 0 = 0.7425039410591125\n",
      "precision class 1 = 0.7182432413101196\n",
      "recall class 0 = 0.8712962865829468\n",
      "recall class 1 = 0.5205680727958679\n",
      "AUC of ROC = 0.7655743280008706\n",
      "AUC of PRC = 0.6657018117280922\n",
      "min(+P, Se) = 0.6341821743388835\n"
     ]
    }
   ],
   "source": [
    "!python -um mimic3models.los3days.logistic.main --data /content/los3days --l2 --C 0.001 --output_dir mimic3models/los3days/logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4g274ulhkioS"
   },
   "outputs": [],
   "source": [
    "#Runtime aprox 1 hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1mBD8goI_bas"
   },
   "outputs": [],
   "source": [
    "#Obs. Due to Deprecated warning:\n",
    "#we have changed the original benchmark version: mimic3models/los3days/logistic/main.py --> sklearn.preprocessing import Imputer, StandardScaler to \n",
    "#from sklearn.impute import SimpleImputer \n",
    "#and\n",
    "#imputer = SimpleImputer(missing_values=np.nan, strategy='mean') #insted of \n",
    "#from sklearn.preprocessing import Imputer\n",
    "#imputer = Imputer(missing_values='NaN', strategy='mean', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mzxH9o1u_bqX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhOze_AmL2JZ"
   },
   "source": [
    "Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5EmVt2Pq_bug",
    "outputId": "9f8bc071-46cd-4f87-f445-7f321fa69df7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the results in los3days_results_logistic.json ...\n",
      "{'n_iters': 10000, 'AUC of ROC': {'value': 0.7655737234132598, 'mean': 0.7656816839109378, 'median': 0.7657102575548695, 'std': 0.00679378985525277, '2.5% percentile': 0.7523271382810609, '97.5% percentile': 0.7789856914618944}, 'AUC of PRC': {'value': 0.6657014661218782, 'mean': 0.6662427290011623, 'median': 0.6662546699692931, 'std': 0.011886161832179555, '2.5% percentile': 0.6430259224989597, '97.5% percentile': 0.6896242051503305}, 'min(+P, Se)': {'value': 0.6341821743388835, 'mean': 0.6345678611355393, 'median': 0.6346433770014556, 'std': 0.008878271907149722, '2.5% percentile': 0.6170210088982643, '97.5% percentile': 0.6520259133680957}}\n"
     ]
    }
   ],
   "source": [
    "!python -m mimic3benchmark.evaluation.evaluate_los_customized /content/gdrive/MyDrive/MIMIC_benchmark/mimic3models/los3days/logistic/predictions/all.all.l2.C0.001.csv --test_listfile /content/los3days/test/listfile.csv --save_file los3days_results_logistic.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Uy28K4F_bx6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "egQOJn4S_b0c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhSzKIQhV6hR"
   },
   "source": [
    "## Bidirectional Standard LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DFd5oQcgbjg2",
    "outputId": "fa3c6a57-1ac0-44ab-f035-0e1df48b2a84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/MyDrive/MIMIC_benchmark/mimic3models/los3days/main.py:7: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Using TensorFlow backend.\n",
      "Namespace(batch_norm=False, batch_size=8, beta_1=0.9, data='/content/los3days/', depth=2, dim=16, dropout=0.3, epochs=50, imputation='previous', l1=0, l2=0, load_state='', lr=0.001, mode='train', network='mimic3models/keras_models/lstm.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/los3days', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=1)\n",
      "==> using model mimic3models/keras_models/lstm.py\n",
      "==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'size_coef', 'small_part', 'target_repl_coef', 'timestep', 'verbose', 'header'])\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1364: calling reduce_any_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2613: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "==> model.final_name: k_lstm.n16.d0.3.dep2.bs8.ts1.0\n",
      "==> compiling the model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2950: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "X (InputLayer)               (None, None, 76)          0         \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, None, 76)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 16)          5440      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 7,569\n",
      "Trainable params: 7,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "==> training\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:958: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:680: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:945: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2378: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 24490 samples, validate on 5356 samples\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "2021-04-04 19:05:50.917366: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
      "2021-04-04 19:05:50.918190: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55873d6136c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-04 19:05:50.918239: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-04-04 19:05:50.929213: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-04 19:05:50.943398: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-04-04 19:05:50.943524: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (95619bb58f7c): /proc/driver/nvidia/version does not exist\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:173: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:182: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:189: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5874\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[12928  2151]\n",
      " [ 4386  5025]]\n",
      "accuracy = 0.7330747246742249\n",
      "precision class 0 = 0.7466790080070496\n",
      "precision class 1 = 0.7002508640289307\n",
      "recall class 0 = 0.8573513031005859\n",
      "recall class 1 = 0.533949613571167\n",
      "AUC of ROC = 0.7629793363495451\n",
      "AUC of PRC = 0.6857252620054436\n",
      "min(+P, Se) = 0.6378028049298767\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2792  462]\n",
      " [ 991 1111]]\n",
      "accuracy = 0.7287154793739319\n",
      "precision class 0 = 0.7380385994911194\n",
      "precision class 1 = 0.7062937021255493\n",
      "recall class 0 = 0.8580209016799927\n",
      "recall class 1 = 0.5285442471504211\n",
      "AUC of ROC = 0.7603463379916806\n",
      "AUC of PRC = 0.6854491798098097\n",
      "min(+P, Se) = 0.6383483626008543\n",
      "Epoch 00001: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch1.test0.5653972550058115.state\n",
      "24490/24490 [==============================] - 185s 8ms/step - loss: 0.5874 - val_loss: 0.5654\n",
      "Epoch 2/50\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5675\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13263  1816]\n",
      " [ 4617  4794]]\n",
      "accuracy = 0.7373213768005371\n",
      "precision class 0 = 0.741778552532196\n",
      "precision class 1 = 0.7252647280693054\n",
      "recall class 0 = 0.8795676231384277\n",
      "recall class 1 = 0.5094038844108582\n",
      "AUC of ROC = 0.7715795876847914\n",
      "AUC of PRC = 0.6945377519637322\n",
      "min(+P, Se) = 0.6436085431941345\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2860  394]\n",
      " [1028 1074]]\n",
      "accuracy = 0.7345033884048462\n",
      "precision class 0 = 0.7355967164039612\n",
      "precision class 1 = 0.7316076159477234\n",
      "recall class 0 = 0.8789182305335999\n",
      "recall class 1 = 0.5109419822692871\n",
      "AUC of ROC = 0.7700145966875578\n",
      "AUC of PRC = 0.6964565378126519\n",
      "min(+P, Se) = 0.6446241674595623\n",
      "Epoch 00002: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch2.test0.5574366505507483.state\n",
      "24490/24490 [==============================] - 187s 8ms/step - loss: 0.5676 - val_loss: 0.5574\n",
      "Epoch 3/50\n",
      "24480/24490 [============================>.] - ETA: 0s - loss: 0.5624\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13227  1852]\n",
      " [ 4519  4892]]\n",
      "accuracy = 0.739853024482727\n",
      "precision class 0 = 0.7453510761260986\n",
      "precision class 1 = 0.7253855466842651\n",
      "recall class 0 = 0.8771801590919495\n",
      "recall class 1 = 0.5198172330856323\n",
      "AUC of ROC = 0.7779128848187347\n",
      "AUC of PRC = 0.6991824118778865\n",
      "min(+P, Se) = 0.6474338540006376\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2859  395]\n",
      " [1012 1090]]\n",
      "accuracy = 0.7373039722442627\n",
      "precision class 0 = 0.7385688424110413\n",
      "precision class 1 = 0.7340067625045776\n",
      "recall class 0 = 0.8786109685897827\n",
      "recall class 1 = 0.5185537338256836\n",
      "AUC of ROC = 0.7774622845804359\n",
      "AUC of PRC = 0.7029649184170608\n",
      "min(+P, Se) = 0.6533523537803139\n",
      "Epoch 00003: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch3.test0.5475460081914185.state\n",
      "24490/24490 [==============================] - 192s 8ms/step - loss: 0.5624 - val_loss: 0.5475\n",
      "Epoch 4/50\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5579\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13016  2063]\n",
      " [ 4261  5150]]\n",
      "accuracy = 0.7417721748352051\n",
      "precision class 0 = 0.75337153673172\n",
      "precision class 1 = 0.7139886021614075\n",
      "recall class 0 = 0.8631871938705444\n",
      "recall class 1 = 0.5472319722175598\n",
      "AUC of ROC = 0.7804028982935471\n",
      "AUC of PRC = 0.702642384941725\n",
      "min(+P, Se) = 0.6488152162363192\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2811  443]\n",
      " [ 954 1148]]\n",
      "accuracy = 0.739171028137207\n",
      "precision class 0 = 0.7466135621070862\n",
      "precision class 1 = 0.7215587496757507\n",
      "recall class 0 = 0.8638598918914795\n",
      "recall class 1 = 0.5461465120315552\n",
      "AUC of ROC = 0.7772309218194162\n",
      "AUC of PRC = 0.7034624452262055\n",
      "min(+P, Se) = 0.6531874405328258\n",
      "Epoch 00004: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch4.test0.5461677536980442.state\n",
      "24490/24490 [==============================] - 184s 8ms/step - loss: 0.5579 - val_loss: 0.5462\n",
      "Epoch 5/50\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5536\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13210  1869]\n",
      " [ 4451  4960]]\n",
      "accuracy = 0.7419354915618896\n",
      "precision class 0 = 0.747975766658783\n",
      "precision class 1 = 0.7263142466545105\n",
      "recall class 0 = 0.8760527968406677\n",
      "recall class 1 = 0.527042806148529\n",
      "AUC of ROC = 0.782621046387302\n",
      "AUC of PRC = 0.7054196965164976\n",
      "min(+P, Se) = 0.6522985454931521\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2858  396]\n",
      " [ 997 1105]]\n",
      "accuracy = 0.7399178743362427\n",
      "precision class 0 = 0.7413748502731323\n",
      "precision class 1 = 0.7361758947372437\n",
      "recall class 0 = 0.8783036470413208\n",
      "recall class 1 = 0.5256898403167725\n",
      "AUC of ROC = 0.7790360630581581\n",
      "AUC of PRC = 0.7076445408554503\n",
      "min(+P, Se) = 0.6565176022835395\n",
      "Epoch 00005: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch5.test0.5446302405794313.state\n",
      "24490/24490 [==============================] - 187s 8ms/step - loss: 0.5536 - val_loss: 0.5446\n",
      "Epoch 6/50\n",
      "24480/24490 [============================>.] - ETA: 0s - loss: 0.5515\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13030  2049]\n",
      " [ 4217  5194]]\n",
      "accuracy = 0.7441404461860657\n",
      "precision class 0 = 0.755493700504303\n",
      "precision class 1 = 0.7171061635017395\n",
      "recall class 0 = 0.8641156554222107\n",
      "recall class 1 = 0.5519073605537415\n",
      "AUC of ROC = 0.7873907088660086\n",
      "AUC of PRC = 0.7102099160590293\n",
      "min(+P, Se) = 0.6546961325966851\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2810  444]\n",
      " [ 944 1158]]\n",
      "accuracy = 0.7408514022827148\n",
      "precision class 0 = 0.7485349178314209\n",
      "precision class 1 = 0.7228464484214783\n",
      "recall class 0 = 0.8635525703430176\n",
      "recall class 1 = 0.5509039163589478\n",
      "AUC of ROC = 0.7840755314252765\n",
      "AUC of PRC = 0.7109546759321984\n",
      "min(+P, Se) = 0.6633380884450785\n",
      "Epoch 00006: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch6.test0.5399932860437839.state\n",
      "24490/24490 [==============================] - 191s 8ms/step - loss: 0.5516 - val_loss: 0.5400\n",
      "Epoch 7/50\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5519\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[12917  2162]\n",
      " [ 4067  5344]]\n",
      "accuracy = 0.7456513047218323\n",
      "precision class 0 = 0.7605393528938293\n",
      "precision class 1 = 0.7119637727737427\n",
      "recall class 0 = 0.8566218018531799\n",
      "recall class 1 = 0.5678461194038391\n",
      "AUC of ROC = 0.7886437912313746\n",
      "AUC of PRC = 0.7121741535156186\n",
      "min(+P, Se) = 0.6567846137498672\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2783  471]\n",
      " [ 911 1191]]\n",
      "accuracy = 0.7419716119766235\n",
      "precision class 0 = 0.7533838748931885\n",
      "precision class 1 = 0.7166064977645874\n",
      "recall class 0 = 0.8552550673484802\n",
      "recall class 1 = 0.5666032433509827\n",
      "AUC of ROC = 0.7838099576777933\n",
      "AUC of PRC = 0.7127158874578652\n",
      "min(+P, Se) = 0.6646051379638439\n",
      "Epoch 00007: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch7.test0.5422234502499276.state\n",
      "24490/24490 [==============================] - 189s 8ms/step - loss: 0.5518 - val_loss: 0.5422\n",
      "Epoch 8/50\n",
      "24480/24490 [============================>.] - ETA: 0s - loss: 0.5469\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13228  1851]\n",
      " [ 4330  5081]]\n",
      "accuracy = 0.7476112842559814\n",
      "precision class 0 = 0.7533887624740601\n",
      "precision class 1 = 0.7329775094985962\n",
      "recall class 0 = 0.8772464990615845\n",
      "recall class 1 = 0.5399001240730286\n",
      "AUC of ROC = 0.7899757941860398\n",
      "AUC of PRC = 0.7135896134853753\n",
      "min(+P, Se) = 0.6581659759855488\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2856  398]\n",
      " [ 979 1123]]\n",
      "accuracy = 0.7429051399230957\n",
      "precision class 0 = 0.7447196841239929\n",
      "precision class 1 = 0.738330066204071\n",
      "recall class 0 = 0.877689003944397\n",
      "recall class 1 = 0.5342531204223633\n",
      "AUC of ROC = 0.786695449704879\n",
      "AUC of PRC = 0.7136116984556381\n",
      "min(+P, Se) = 0.665080875356803\n",
      "Epoch 00008: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch8.test0.5372995811669661.state\n",
      "24490/24490 [==============================] - 188s 8ms/step - loss: 0.5469 - val_loss: 0.5373\n",
      "Epoch 9/50\n",
      "24480/24490 [============================>.] - ETA: 0s - loss: 0.5466\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13118  1961]\n",
      " [ 4176  5235]]\n",
      "accuracy = 0.749407947063446\n",
      "precision class 0 = 0.7585289478302002\n",
      "precision class 1 = 0.7274875044822693\n",
      "recall class 0 = 0.869951605796814\n",
      "recall class 1 = 0.5562639236450195\n",
      "AUC of ROC = 0.792046611397097\n",
      "AUC of PRC = 0.7158509484781013\n",
      "min(+P, Se) = 0.657315906917437\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2838  416]\n",
      " [ 946 1156]]\n",
      "accuracy = 0.7457057237625122\n",
      "precision class 0 = 0.75\n",
      "precision class 1 = 0.7353689670562744\n",
      "recall class 0 = 0.8721573352813721\n",
      "recall class 1 = 0.5499524474143982\n",
      "AUC of ROC = 0.7862573590171095\n",
      "AUC of PRC = 0.7156649266405242\n",
      "min(+P, Se) = 0.665080875356803\n",
      "Epoch 00009: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch9.test0.5370638814098894.state\n",
      "24490/24490 [==============================] - 190s 8ms/step - loss: 0.5467 - val_loss: 0.5371\n",
      "Epoch 10/50\n",
      "24480/24490 [============================>.] - ETA: 0s - loss: 0.5451\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13369  1710]\n",
      " [ 4464  4947]]\n",
      "accuracy = 0.7478970885276794\n",
      "precision class 0 = 0.7496775388717651\n",
      "precision class 1 = 0.7431275248527527\n",
      "recall class 0 = 0.8865972757339478\n",
      "recall class 1 = 0.5256614685058594\n",
      "AUC of ROC = 0.7945388269955895\n",
      "AUC of PRC = 0.7201007404018303\n",
      "min(+P, Se) = 0.6607161831898842\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2892  362]\n",
      " [1006 1096]]\n",
      "accuracy = 0.7445855140686035\n",
      "precision class 0 = 0.7419189214706421\n",
      "precision class 1 = 0.7517147064208984\n",
      "recall class 0 = 0.888752281665802\n",
      "recall class 1 = 0.521408200263977\n",
      "AUC of ROC = 0.7884209846097345\n",
      "AUC of PRC = 0.7157641357028162\n",
      "min(+P, Se) = 0.6669838249286394\n",
      "Epoch 00010: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch10.test0.5363570781587397.state\n",
      "24490/24490 [==============================] - 191s 8ms/step - loss: 0.5451 - val_loss: 0.5364\n",
      "Epoch 11/50\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5447\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13375  1704]\n",
      " [ 4539  4872]]\n",
      "accuracy = 0.7450796365737915\n",
      "precision class 0 = 0.7466227412223816\n",
      "precision class 1 = 0.7408758997917175\n",
      "recall class 0 = 0.8869951367378235\n",
      "recall class 1 = 0.5176920890808105\n",
      "AUC of ROC = 0.7864509587514471\n",
      "AUC of PRC = 0.7163779102396736\n",
      "min(+P, Se) = 0.6538093720114759\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2903  351]\n",
      " [1023 1079]]\n",
      "accuracy = 0.74346524477005\n",
      "precision class 0 = 0.7394294738769531\n",
      "precision class 1 = 0.7545454502105713\n",
      "recall class 0 = 0.8921327590942383\n",
      "recall class 1 = 0.5133206248283386\n",
      "AUC of ROC = 0.7820571563243248\n",
      "AUC of PRC = 0.713877056797012\n",
      "min(+P, Se) = 0.6522359657469077\n",
      "Epoch 00011: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch11.test0.5423247471195802.state\n",
      "24490/24490 [==============================] - 191s 8ms/step - loss: 0.5447 - val_loss: 0.5423\n",
      "Epoch 12/50\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5440\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13159  1920]\n",
      " [ 4201  5210]]\n",
      "accuracy = 0.7500612735748291\n",
      "precision class 0 = 0.7580069303512573\n",
      "precision class 1 = 0.730715274810791\n",
      "recall class 0 = 0.872670590877533\n",
      "recall class 1 = 0.5536074638366699\n",
      "AUC of ROC = 0.7976493707362878\n",
      "AUC of PRC = 0.722262890892509\n",
      "min(+P, Se) = 0.6639039421953034\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2839  415]\n",
      " [ 949 1153]]\n",
      "accuracy = 0.7453323602676392\n",
      "precision class 0 = 0.7494720220565796\n",
      "precision class 1 = 0.735331654548645\n",
      "recall class 0 = 0.872464656829834\n",
      "recall class 1 = 0.5485252141952515\n",
      "AUC of ROC = 0.7886161626735331\n",
      "AUC of PRC = 0.7155731893334447\n",
      "min(+P, Se) = 0.6669838249286394\n",
      "Epoch 00012: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch12.test0.534754834128815.state\n",
      "24490/24490 [==============================] - 192s 8ms/step - loss: 0.5440 - val_loss: 0.5348\n",
      "Epoch 13/50\n",
      "24480/24490 [============================>.] - ETA: 0s - loss: 0.5415\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13004  2075]\n",
      " [ 4059  5352]]\n",
      "accuracy = 0.7495304346084595\n",
      "precision class 0 = 0.7621168494224548\n",
      "precision class 1 = 0.720613956451416\n",
      "recall class 0 = 0.8623914122581482\n",
      "recall class 1 = 0.5686962008476257\n",
      "AUC of ROC = 0.7974397285619366\n",
      "AUC of PRC = 0.7234070777313453\n",
      "min(+P, Se) = 0.6629511677282378\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2829  425]\n",
      " [ 929 1173]]\n",
      "accuracy = 0.7471994161605835\n",
      "precision class 0 = 0.7527940273284912\n",
      "precision class 1 = 0.7340425252914429\n",
      "recall class 0 = 0.8693915009498596\n",
      "recall class 1 = 0.5580399632453918\n",
      "AUC of ROC = 0.7893603247295139\n",
      "AUC of PRC = 0.718028768716223\n",
      "min(+P, Se) = 0.6636536631779257\n",
      "Epoch 00013: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch13.test0.5340614218022771.state\n",
      "24490/24490 [==============================] - 186s 8ms/step - loss: 0.5414 - val_loss: 0.5341\n",
      "Epoch 14/50\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5409\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13317  1762]\n",
      " [ 4337  5074]]\n",
      "accuracy = 0.750959575176239\n",
      "precision class 0 = 0.7543333172798157\n",
      "precision class 1 = 0.7422469258308411\n",
      "recall class 0 = 0.883148729801178\n",
      "recall class 1 = 0.5391563177108765\n",
      "AUC of ROC = 0.7994585650839485\n",
      "AUC of PRC = 0.726494229440592\n",
      "min(+P, Se) = 0.6641164594623313\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2875  379]\n",
      " [ 989 1113]]\n",
      "accuracy = 0.7445855140686035\n",
      "precision class 0 = 0.7440476417541504\n",
      "precision class 1 = 0.7459785342216492\n",
      "recall class 0 = 0.8835279941558838\n",
      "recall class 1 = 0.5294957160949707\n",
      "AUC of ROC = 0.7906489385529747\n",
      "AUC of PRC = 0.7190037219595771\n",
      "min(+P, Se) = 0.6690442225392297\n",
      "Epoch 00014: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch14.test0.5346113071235105.state\n",
      "24490/24490 [==============================] - 170s 7ms/step - loss: 0.5409 - val_loss: 0.5346\n",
      "Epoch 15/50\n",
      "24480/24490 [============================>.] - ETA: 0s - loss: 0.5384\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13234  1845]\n",
      " [ 4242  5169]]\n",
      "accuracy = 0.7514495849609375\n",
      "precision class 0 = 0.7572671175003052\n",
      "precision class 1 = 0.7369546890258789\n",
      "recall class 0 = 0.877644419670105\n",
      "recall class 1 = 0.5492509007453918\n",
      "AUC of ROC = 0.8013550445674951\n",
      "AUC of PRC = 0.7296161698385182\n",
      "min(+P, Se) = 0.6653919694072657\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2850  404]\n",
      " [ 969 1133]]\n",
      "accuracy = 0.7436519861221313\n",
      "precision class 0 = 0.746268630027771\n",
      "precision class 1 = 0.7371503114700317\n",
      "recall class 0 = 0.8758451342582703\n",
      "recall class 1 = 0.5390104651451111\n",
      "AUC of ROC = 0.7906474034446078\n",
      "AUC of PRC = 0.7174833659136317\n",
      "min(+P, Se) = 0.667458432304038\n",
      "Epoch 00015: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch15.test0.5354885901863491.state\n",
      "24490/24490 [==============================] - 170s 7ms/step - loss: 0.5384 - val_loss: 0.5355\n",
      "Epoch 16/50\n",
      "24480/24490 [============================>.] - ETA: 0s - loss: 0.5393\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13389  1690]\n",
      " [ 4414  4997]]\n",
      "accuracy = 0.7507554292678833\n",
      "precision class 0 = 0.7520642876625061\n",
      "precision class 1 = 0.7472708225250244\n",
      "recall class 0 = 0.8879235982894897\n",
      "recall class 1 = 0.5309743881225586\n",
      "AUC of ROC = 0.7987505981760681\n",
      "AUC of PRC = 0.7271777103372561\n",
      "min(+P, Se) = 0.6654275092936803\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2884  370]\n",
      " [1008 1094]]\n",
      "accuracy = 0.7427184581756592\n",
      "precision class 0 = 0.7410072088241577\n",
      "precision class 1 = 0.7472677826881409\n",
      "recall class 0 = 0.8862937688827515\n",
      "recall class 1 = 0.5204567313194275\n",
      "AUC of ROC = 0.7873768185186116\n",
      "AUC of PRC = 0.7166848934285783\n",
      "min(+P, Se) = 0.6684085510688836\n",
      "Epoch 00016: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch16.test0.5378023979599749.state\n",
      "24490/24490 [==============================] - 170s 7ms/step - loss: 0.5393 - val_loss: 0.5378\n",
      "Epoch 17/50\n",
      "24480/24490 [============================>.] - ETA: 0s - loss: 0.5378\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13210  1869]\n",
      " [ 4255  5156]]\n",
      "accuracy = 0.7499387264251709\n",
      "precision class 0 = 0.7563698887825012\n",
      "precision class 1 = 0.7339501976966858\n",
      "recall class 0 = 0.8760527968406677\n",
      "recall class 1 = 0.5478695034980774\n",
      "AUC of ROC = 0.8002684885565217\n",
      "AUC of PRC = 0.7286185806349527\n",
      "min(+P, Se) = 0.6619912867920519\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2854  400]\n",
      " [ 976 1126]]\n",
      "accuracy = 0.743091881275177\n",
      "precision class 0 = 0.7451696991920471\n",
      "precision class 1 = 0.7378767728805542\n",
      "recall class 0 = 0.8770743608474731\n",
      "recall class 1 = 0.5356802940368652\n",
      "AUC of ROC = 0.7899535344627442\n",
      "AUC of PRC = 0.7182423485055969\n",
      "min(+P, Se) = 0.6668250950570342\n",
      "Epoch 00017: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch17.test0.5341773833731736.state\n",
      "24490/24490 [==============================] - 170s 7ms/step - loss: 0.5379 - val_loss: 0.5342\n",
      "Epoch 18/50\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5364\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[12917  2162]\n",
      " [ 3943  5468]]\n",
      "accuracy = 0.7507146000862122\n",
      "precision class 0 = 0.7661328315734863\n",
      "precision class 1 = 0.716644823551178\n",
      "recall class 0 = 0.8566218018531799\n",
      "recall class 1 = 0.5810222029685974\n",
      "AUC of ROC = 0.8024693085794619\n",
      "AUC of PRC = 0.73114423676308\n",
      "min(+P, Se) = 0.6651083722906928\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2795  459]\n",
      " [ 907 1195]]\n",
      "accuracy = 0.7449589371681213\n",
      "precision class 0 = 0.7549973130226135\n",
      "precision class 1 = 0.7224909067153931\n",
      "recall class 0 = 0.8589428663253784\n",
      "recall class 1 = 0.5685061812400818\n",
      "AUC of ROC = 0.7908943365904921\n",
      "AUC of PRC = 0.7176785409283892\n",
      "min(+P, Se) = 0.6655566127497621\n",
      "Epoch 00018: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch18.test0.532735556898231.state\n",
      "24490/24490 [==============================] - 172s 7ms/step - loss: 0.5365 - val_loss: 0.5327\n",
      "Epoch 19/50\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5372\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13120  1959]\n",
      " [ 4112  5299]]\n",
      "accuracy = 0.7521029114723206\n",
      "precision class 0 = 0.7613741755485535\n",
      "precision class 1 = 0.7300909161567688\n",
      "recall class 0 = 0.8700842261314392\n",
      "recall class 1 = 0.5630645155906677\n",
      "AUC of ROC = 0.8022676891821022\n",
      "AUC of PRC = 0.7319306761100388\n",
      "min(+P, Se) = 0.6644352353628732\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2835  419]\n",
      " [ 946 1156]]\n",
      "accuracy = 0.7451456189155579\n",
      "precision class 0 = 0.7498016357421875\n",
      "precision class 1 = 0.7339682579040527\n",
      "recall class 0 = 0.8712354302406311\n",
      "recall class 1 = 0.5499524474143982\n",
      "AUC of ROC = 0.7895546986889297\n",
      "AUC of PRC = 0.7183027055414523\n",
      "min(+P, Se) = 0.665080875356803\n",
      "Epoch 00019: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch19.test0.534026353149115.state\n",
      "24490/24490 [==============================] - 177s 7ms/step - loss: 0.5372 - val_loss: 0.5340\n",
      "Epoch 20/50\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5359\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[12780  2299]\n",
      " [ 3818  5593]]\n",
      "accuracy = 0.7502245903015137\n",
      "precision class 0 = 0.7699722647666931\n",
      "precision class 1 = 0.7086923718452454\n",
      "recall class 0 = 0.8475363254547119\n",
      "recall class 1 = 0.5943045616149902\n",
      "AUC of ROC = 0.8026544807554792\n",
      "AUC of PRC = 0.7326565615013241\n",
      "min(+P, Se) = 0.66755206119847\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2758  496]\n",
      " [ 871 1231]]\n",
      "accuracy = 0.74477219581604\n",
      "precision class 0 = 0.7599889636039734\n",
      "precision class 1 = 0.7127967476844788\n",
      "recall class 0 = 0.8475722074508667\n",
      "recall class 1 = 0.5856327414512634\n",
      "AUC of ROC = 0.7901859206293418\n",
      "AUC of PRC = 0.719459600723535\n",
      "min(+P, Se) = 0.6603235014272122\n",
      "Epoch 00020: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch20.test0.5333324407266983.state\n",
      "24490/24490 [==============================] - 174s 7ms/step - loss: 0.5359 - val_loss: 0.5333\n",
      "Epoch 21/50\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5371\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13246  1833]\n",
      " [ 4212  5199]]\n",
      "accuracy = 0.753164529800415\n",
      "precision class 0 = 0.7587352395057678\n",
      "precision class 1 = 0.7393344640731812\n",
      "recall class 0 = 0.8784402012825012\n",
      "recall class 1 = 0.5524386167526245\n",
      "AUC of ROC = 0.804545403840556\n",
      "AUC of PRC = 0.7332958474688388\n",
      "min(+P, Se) = 0.6700669429391138\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2869  385]\n",
      " [ 965 1137]]\n",
      "accuracy = 0.7479462027549744\n",
      "precision class 0 = 0.7483046650886536\n",
      "precision class 1 = 0.7470433712005615\n",
      "recall class 0 = 0.8816840648651123\n",
      "recall class 1 = 0.5409134030342102\n",
      "AUC of ROC = 0.7903689640270015\n",
      "AUC of PRC = 0.71979164285412\n",
      "min(+P, Se) = 0.6696768060836502\n",
      "Epoch 00021: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch21.test0.5322749396372946.state\n",
      "24490/24490 [==============================] - 176s 7ms/step - loss: 0.5371 - val_loss: 0.5323\n",
      "Epoch 22/50\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5345\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[12970  2109]\n",
      " [ 3973  5438]]\n",
      "accuracy = 0.7516537308692932\n",
      "precision class 0 = 0.7655078768730164\n",
      "precision class 1 = 0.7205511927604675\n",
      "recall class 0 = 0.8601366281509399\n",
      "recall class 1 = 0.57783442735672\n",
      "AUC of ROC = 0.802709343583997\n",
      "AUC of PRC = 0.7320769133613152\n",
      "min(+P, Se) = 0.6669144981412639\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2805  449]\n",
      " [ 918 1184]]\n",
      "accuracy = 0.74477219581604\n",
      "precision class 0 = 0.7534246444702148\n",
      "precision class 1 = 0.725045919418335\n",
      "recall class 0 = 0.862015962600708\n",
      "recall class 1 = 0.5632730722427368\n",
      "AUC of ROC = 0.7891679244808556\n",
      "AUC of PRC = 0.7179681016451746\n",
      "min(+P, Se) = 0.6607992388201712\n",
      "Epoch 00022: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch22.test0.5354078755483777.state\n",
      "24490/24490 [==============================] - 177s 7ms/step - loss: 0.5345 - val_loss: 0.5354\n",
      "Epoch 23/50\n",
      "24480/24490 [============================>.] - ETA: 0s - loss: 0.5342\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13102  1977]\n",
      " [ 4108  5303]]\n",
      "accuracy = 0.7515312433242798\n",
      "precision class 0 = 0.761301577091217\n",
      "precision class 1 = 0.7284340858459473\n",
      "recall class 0 = 0.8688905239105225\n",
      "recall class 1 = 0.563489556312561\n",
      "AUC of ROC = 0.8039231964372754\n",
      "AUC of PRC = 0.7336296741095025\n",
      "min(+P, Se) = 0.6675167357347784\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2827  427]\n",
      " [ 953 1149]]\n",
      "accuracy = 0.7423450350761414\n",
      "precision class 0 = 0.7478836178779602\n",
      "precision class 1 = 0.7290608882904053\n",
      "recall class 0 = 0.8687769174575806\n",
      "recall class 1 = 0.5466222763061523\n",
      "AUC of ROC = 0.7883803407882093\n",
      "AUC of PRC = 0.7177835688358059\n",
      "min(+P, Se) = 0.665080875356803\n",
      "Epoch 00023: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch23.test0.5349322527402189.state\n",
      "24490/24490 [==============================] - 179s 7ms/step - loss: 0.5341 - val_loss: 0.5349\n",
      "Epoch 24/50\n",
      "24480/24490 [============================>.] - ETA: 0s - loss: 0.5350\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13225  1854]\n",
      " [ 4141  5270]]\n",
      "accuracy = 0.7552062273025513\n",
      "precision class 0 = 0.7615455389022827\n",
      "precision class 1 = 0.7397529482841492\n",
      "recall class 0 = 0.8770475387573242\n",
      "recall class 1 = 0.5599830150604248\n",
      "AUC of ROC = 0.8047708519778336\n",
      "AUC of PRC = 0.737147410200533\n",
      "min(+P, Se) = 0.6674104771012644\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2855  399]\n",
      " [ 974 1128]]\n",
      "accuracy = 0.7436519861221313\n",
      "precision class 0 = 0.7456254959106445\n",
      "precision class 1 = 0.7387033104896545\n",
      "recall class 0 = 0.8773816823959351\n",
      "recall class 1 = 0.5366317629814148\n",
      "AUC of ROC = 0.7896878876148627\n",
      "AUC of PRC = 0.721146621691356\n",
      "min(+P, Se) = 0.6698382492863939\n",
      "Epoch 00024: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch24.test0.533679284895419.state\n",
      "24490/24490 [==============================] - 179s 7ms/step - loss: 0.5350 - val_loss: 0.5337\n",
      "Epoch 25/50\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5355\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13069  2010]\n",
      " [ 4047  5364]]\n",
      "accuracy = 0.7526745796203613\n",
      "precision class 0 = 0.763554573059082\n",
      "precision class 1 = 0.7274206876754761\n",
      "recall class 0 = 0.8667020201683044\n",
      "recall class 1 = 0.5699713230133057\n",
      "AUC of ROC = 0.8063627055267576\n",
      "AUC of PRC = 0.7374319145729514\n",
      "min(+P, Se) = 0.6694285107287019\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2821  433]\n",
      " [ 936 1166]]\n",
      "accuracy = 0.744398832321167\n",
      "precision class 0 = 0.7508650422096252\n",
      "precision class 1 = 0.7292057275772095\n",
      "recall class 0 = 0.8669329881668091\n",
      "recall class 1 = 0.554709792137146\n",
      "AUC of ROC = 0.7901040481831042\n",
      "AUC of PRC = 0.7199894448532854\n",
      "min(+P, Se) = 0.6631779257849667\n",
      "Epoch 00025: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch25.test0.5332292512426454.state\n",
      "24490/24490 [==============================] - 178s 7ms/step - loss: 0.5355 - val_loss: 0.5332\n",
      "Epoch 26/50\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5340\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13234  1845]\n",
      " [ 4197  5214]]\n",
      "accuracy = 0.7532870769500732\n",
      "precision class 0 = 0.7592220902442932\n",
      "precision class 1 = 0.738631546497345\n",
      "recall class 0 = 0.877644419670105\n",
      "recall class 1 = 0.5540325045585632\n",
      "AUC of ROC = 0.8064012691166444\n",
      "AUC of PRC = 0.7381966829263948\n",
      "min(+P, Se) = 0.6693582660433489\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2858  396]\n",
      " [ 967 1135]]\n",
      "accuracy = 0.7455190420150757\n",
      "precision class 0 = 0.7471895217895508\n",
      "precision class 1 = 0.7413455247879028\n",
      "recall class 0 = 0.8783036470413208\n",
      "recall class 1 = 0.5399619340896606\n",
      "AUC of ROC = 0.7896648609893584\n",
      "AUC of PRC = 0.7198872002074775\n",
      "min(+P, Se) = 0.6646051379638439\n",
      "Epoch 00026: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch26.test0.5334566390452053.state\n",
      "24490/24490 [==============================] - 175s 7ms/step - loss: 0.5340 - val_loss: 0.5335\n",
      "Epoch 27/50\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5302\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13417  1662]\n",
      " [ 4329  5082]]\n",
      "accuracy = 0.7553695440292358\n",
      "precision class 0 = 0.7560576796531677\n",
      "precision class 1 = 0.7535586953163147\n",
      "recall class 0 = 0.8897804617881775\n",
      "recall class 1 = 0.5400063991546631\n",
      "AUC of ROC = 0.8074932194497848\n",
      "AUC of PRC = 0.7388539897651455\n",
      "min(+P, Se) = 0.6715545638083095\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2890  364]\n",
      " [1008 1094]]\n",
      "accuracy = 0.7438386678695679\n",
      "precision class 0 = 0.7414058446884155\n",
      "precision class 1 = 0.7503429651260376\n",
      "recall class 0 = 0.888137698173523\n",
      "recall class 1 = 0.5204567313194275\n",
      "AUC of ROC = 0.7908707251618003\n",
      "AUC of PRC = 0.7216912231965179\n",
      "min(+P, Se) = 0.6706217370669197\n",
      "Epoch 00027: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch27.test0.5368555875702345.state\n",
      "24490/24490 [==============================] - 174s 7ms/step - loss: 0.5301 - val_loss: 0.5369\n",
      "Epoch 28/50\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5329\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13518  1561]\n",
      " [ 4471  4940]]\n",
      "accuracy = 0.7536953687667847\n",
      "precision class 0 = 0.7514592409133911\n",
      "precision class 1 = 0.7598831057548523\n",
      "recall class 0 = 0.896478533744812\n",
      "recall class 1 = 0.5249176621437073\n",
      "AUC of ROC = 0.8082904340261751\n",
      "AUC of PRC = 0.7411480678935052\n",
      "min(+P, Se) = 0.6710232706407395\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2909  345]\n",
      " [1025 1077]]\n",
      "accuracy = 0.7442120909690857\n",
      "precision class 0 = 0.7394509315490723\n",
      "precision class 1 = 0.7573839426040649\n",
      "recall class 0 = 0.893976628780365\n",
      "recall class 1 = 0.5123691558837891\n",
      "AUC of ROC = 0.7888392650895305\n",
      "AUC of PRC = 0.7210085413167023\n",
      "min(+P, Se) = 0.6623870660960532\n",
      "Epoch 00028: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch28.test0.5362849831135973.state\n",
      "24490/24490 [==============================] - 174s 7ms/step - loss: 0.5329 - val_loss: 0.5363\n",
      "Epoch 29/50\n",
      "24480/24490 [============================>.] - ETA: 0s - loss: 0.5321\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13051  2028]\n",
      " [ 4000  5411]]\n",
      "accuracy = 0.753858745098114\n",
      "precision class 0 = 0.7654096484184265\n",
      "precision class 1 = 0.7273827195167542\n",
      "recall class 0 = 0.8655083179473877\n",
      "recall class 1 = 0.5749654769897461\n",
      "AUC of ROC = 0.8081333151441441\n",
      "AUC of PRC = 0.7391520361237327\n",
      "min(+P, Se) = 0.6699946893255443\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2814  440]\n",
      " [ 935 1167]]\n",
      "accuracy = 0.7432785630226135\n",
      "precision class 0 = 0.7506001591682434\n",
      "precision class 1 = 0.7261978983879089\n",
      "recall class 0 = 0.8647817969322205\n",
      "recall class 1 = 0.5551855564117432\n",
      "AUC of ROC = 0.7904262747393678\n",
      "AUC of PRC = 0.7202246467226638\n",
      "min(+P, Se) = 0.6679334916864608\n",
      "Epoch 00029: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch29.test0.5336564099548289.state\n",
      "24490/24490 [==============================] - 173s 7ms/step - loss: 0.5321 - val_loss: 0.5337\n",
      "Epoch 30/50\n",
      "24480/24490 [============================>.] - ETA: 0s - loss: 0.5326\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[12864  2215]\n",
      " [ 3812  5599]]\n",
      "accuracy = 0.7538995742797852\n",
      "precision class 0 = 0.7714080214500427\n",
      "precision class 1 = 0.716534435749054\n",
      "recall class 0 = 0.8531069755554199\n",
      "recall class 1 = 0.5949420928955078\n",
      "AUC of ROC = 0.8079005982370229\n",
      "AUC of PRC = 0.7405751721793379\n",
      "min(+P, Se) = 0.6715545638083095\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2769  485]\n",
      " [ 896 1206]]\n",
      "accuracy = 0.7421583533287048\n",
      "precision class 0 = 0.7555252313613892\n",
      "precision class 1 = 0.7131874561309814\n",
      "recall class 0 = 0.850952684879303\n",
      "recall class 1 = 0.5737392902374268\n",
      "AUC of ROC = 0.7895956349120485\n",
      "AUC of PRC = 0.7232695768553175\n",
      "min(+P, Se) = 0.6663498098859315\n",
      "Epoch 00030: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch30.test0.5337686762603208.state\n",
      "24490/24490 [==============================] - 175s 7ms/step - loss: 0.5326 - val_loss: 0.5338\n",
      "Epoch 31/50\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5308\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13172  1907]\n",
      " [ 4041  5370]]\n",
      "accuracy = 0.7571253776550293\n",
      "precision class 0 = 0.7652356028556824\n",
      "precision class 1 = 0.7379414439201355\n",
      "recall class 0 = 0.8735327124595642\n",
      "recall class 1 = 0.5706088542938232\n",
      "AUC of ROC = 0.8104811841779507\n",
      "AUC of PRC = 0.7440401249320852\n",
      "min(+P, Se) = 0.6742456438589035\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2837  417]\n",
      " [ 945 1157]]\n",
      "accuracy = 0.7457057237625122\n",
      "precision class 0 = 0.7501322031021118\n",
      "precision class 1 = 0.7350698709487915\n",
      "recall class 0 = 0.8718500137329102\n",
      "recall class 1 = 0.5504281520843506\n",
      "AUC of ROC = 0.7912507010328209\n",
      "AUC of PRC = 0.7223523606401547\n",
      "min(+P, Se) = 0.6677756653992395\n",
      "Epoch 00031: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch31.test0.5311827841892983.state\n",
      "24490/24490 [==============================] - 177s 7ms/step - loss: 0.5308 - val_loss: 0.5312\n",
      "Epoch 32/50\n",
      "24480/24490 [============================>.] - ETA: 0s - loss: 0.5311\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13024  2055]\n",
      " [ 3904  5507]]\n",
      "accuracy = 0.756676197052002\n",
      "precision class 0 = 0.7693761587142944\n",
      "precision class 1 = 0.7282465100288391\n",
      "recall class 0 = 0.8637177348136902\n",
      "recall class 1 = 0.5851662755012512\n",
      "AUC of ROC = 0.8105409057721564\n",
      "AUC of PRC = 0.743575714914929\n",
      "min(+P, Se) = 0.6728644283892903\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2806  448]\n",
      " [ 915 1187]]\n",
      "accuracy = 0.7455190420150757\n",
      "precision class 0 = 0.7540983557701111\n",
      "precision class 1 = 0.7259938716888428\n",
      "recall class 0 = 0.8623232841491699\n",
      "recall class 1 = 0.5647003054618835\n",
      "AUC of ROC = 0.790999381863031\n",
      "AUC of PRC = 0.7224837127888993\n",
      "min(+P, Se) = 0.6679352997145576\n",
      "Epoch 00032: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch32.test0.5329250078578776.state\n",
      "24490/24490 [==============================] - 176s 7ms/step - loss: 0.5311 - val_loss: 0.5329\n",
      "Epoch 33/50\n",
      "10080/24490 [===========>..................] - ETA: 1:21 - loss: 0.5391"
     ]
    }
   ],
   "source": [
    "!python -um mimic3models.los3days.main --network mimic3models/keras_models/lstm.py --data /content/los3days/ --dim 16 --epochs 50 --timestep 1.0 --depth 2 --dropout 0.3 --mode train --batch_size 8 --output_dir mimic3models/los3days --verbose 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Imp8dU0Mbjjs"
   },
   "outputs": [],
   "source": [
    "#runtime: 21:00 to 22:45: aprox. 1.45 horas para 32 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OwI7-Tvp4s_u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mm62fzWE50t"
   },
   "source": [
    "Load epoch 32 y seguir entrenando hasta epoch 35:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MERXPPh8D2my",
    "outputId": "c5a525e1-7ace-441f-8399-79545a2e049b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/MyDrive/MIMIC_benchmark/mimic3models/los3days/main.py:7: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Using TensorFlow backend.\n",
      "Namespace(batch_norm=False, batch_size=8, beta_1=0.9, data='/content/los3days/', depth=2, dim=16, dropout=0.3, epochs=3, imputation='previous', l1=0, l2=0, load_state='mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch32.test0.5329250078578776.state', lr=0.001, mode='train', network='mimic3models/keras_models/lstm.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/los3days', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=1)\n",
      "==> using model mimic3models/keras_models/lstm.py\n",
      "==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'size_coef', 'small_part', 'target_repl_coef', 'timestep', 'verbose', 'header'])\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1364: calling reduce_any_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2613: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "==> model.final_name: k_lstm.n16.d0.3.dep2.bs8.ts1.0\n",
      "==> compiling the model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2950: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "X (InputLayer)               (None, None, 76)          0         \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, None, 76)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 16)          5440      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 7,569\n",
      "Trainable params: 7,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:169: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-04-21 20:26:52.603668: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
      "2021-04-21 20:26:52.604082: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fe148556c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-21 20:26:52.604124: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-04-21 20:26:52.657009: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-21 20:26:52.727447: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-04-21 20:26:52.727511: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (30dacc6a361f): /proc/driver/nvidia/version does not exist\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:173: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:182: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:189: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "==> training\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:958: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:680: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:945: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 24490 samples, validate on 5356 samples\n",
      "Epoch 33/35\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5307\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13042  2037]\n",
      " [ 3959  5452]]\n",
      "accuracy = 0.7551653981208801\n",
      "precision class 0 = 0.7671313285827637\n",
      "precision class 1 = 0.728001058101654\n",
      "recall class 0 = 0.8649114370346069\n",
      "recall class 1 = 0.579322099685669\n",
      "AUC of ROC = 0.8106596795149696\n",
      "AUC of PRC = 0.743214453656989\n",
      "min(+P, Se) = 0.6728486646884273\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2809  445]\n",
      " [ 903 1199]]\n",
      "accuracy = 0.7483196258544922\n",
      "precision class 0 = 0.7567349076271057\n",
      "precision class 1 = 0.7293187379837036\n",
      "recall class 0 = 0.8632452487945557\n",
      "recall class 1 = 0.5704091191291809\n",
      "AUC of ROC = 0.7902046343313389\n",
      "AUC of PRC = 0.721993458748366\n",
      "min(+P, Se) = 0.6647673314339981\n",
      "Epoch 00033: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch33.test0.532028335524282.state\n",
      "24490/24490 [==============================] - 181s 7ms/step - loss: 0.5308 - val_loss: 0.5320\n",
      "Epoch 34/35\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5291\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13065  2014]\n",
      " [ 3912  5499]]\n",
      "accuracy = 0.7580236792564392\n",
      "precision class 0 = 0.7695705890655518\n",
      "precision class 1 = 0.7319313287734985\n",
      "recall class 0 = 0.866436779499054\n",
      "recall class 1 = 0.5843162536621094\n",
      "AUC of ROC = 0.8119018921978505\n",
      "AUC of PRC = 0.7439266052619269\n",
      "min(+P, Se) = 0.675586704895402\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2812  442]\n",
      " [ 909 1193]]\n",
      "accuracy = 0.7477595210075378\n",
      "precision class 0 = 0.7557108402252197\n",
      "precision class 1 = 0.729663610458374\n",
      "recall class 0 = 0.8641671538352966\n",
      "recall class 1 = 0.5675547122955322\n",
      "AUC of ROC = 0.79053395162625\n",
      "AUC of PRC = 0.7209161490549529\n",
      "min(+P, Se) = 0.6607992388201712\n",
      "Epoch 00034: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch34.test0.5324534614242842.state\n",
      "24490/24490 [==============================] - 176s 7ms/step - loss: 0.5291 - val_loss: 0.5325\n",
      "Epoch 35/35\n",
      "24480/24490 [============================>.] - ETA: 0s - loss: 0.5306\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13212  1867]\n",
      " [ 4085  5326]]\n",
      "accuracy = 0.7569620013237\n",
      "precision class 0 = 0.7638318538665771\n",
      "precision class 1 = 0.7404420971870422\n",
      "recall class 0 = 0.876185417175293\n",
      "recall class 1 = 0.5659334659576416\n",
      "AUC of ROC = 0.8114513517864814\n",
      "AUC of PRC = 0.7444290698804612\n",
      "min(+P, Se) = 0.673534409515718\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2830  424]\n",
      " [ 949 1153]]\n",
      "accuracy = 0.7436519861221313\n",
      "precision class 0 = 0.7488753795623779\n",
      "precision class 1 = 0.7311350703239441\n",
      "recall class 0 = 0.8696988224983215\n",
      "recall class 1 = 0.5485252141952515\n",
      "AUC of ROC = 0.7916695663158042\n",
      "AUC of PRC = 0.723691527840633\n",
      "min(+P, Se) = 0.6669838249286394\n",
      "Epoch 00035: saving model to mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch35.test0.5336932081442612.state\n",
      "24490/24490 [==============================] - 174s 7ms/step - loss: 0.5305 - val_loss: 0.5337\n"
     ]
    }
   ],
   "source": [
    "##load previous models states and continue training:\n",
    "!python -um mimic3models.los3days.main --network mimic3models/keras_models/lstm.py --data /content/los3days/ --load_state mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch32.test0.5329250078578776.state --dim 16 --epochs 3 --timestep 1.0 --depth 2 --dropout 0.3 --mode train --batch_size 8 --output_dir mimic3models/los3days --verbose 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oOiLjpLoD2rQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "0-MfjKhcD2tQ",
    "outputId": "1a6a6b92-0c25-41f3-b718-879631bbef3d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_auprc</th>\n",
       "      <th>train_auroc</th>\n",
       "      <th>train_minpse</th>\n",
       "      <th>train_prec0</th>\n",
       "      <th>train_prec1</th>\n",
       "      <th>train_rec0</th>\n",
       "      <th>train_rec1</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_auprc</th>\n",
       "      <th>val_auroc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_minpse</th>\n",
       "      <th>val_prec0</th>\n",
       "      <th>val_prec1</th>\n",
       "      <th>val_rec0</th>\n",
       "      <th>val_rec1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.587417</td>\n",
       "      <td>0.733075</td>\n",
       "      <td>0.685725</td>\n",
       "      <td>0.762979</td>\n",
       "      <td>0.637803</td>\n",
       "      <td>0.746679</td>\n",
       "      <td>0.700251</td>\n",
       "      <td>0.857351</td>\n",
       "      <td>0.533950</td>\n",
       "      <td>0.728715</td>\n",
       "      <td>0.685449</td>\n",
       "      <td>0.760346</td>\n",
       "      <td>0.565397</td>\n",
       "      <td>0.638348</td>\n",
       "      <td>0.738039</td>\n",
       "      <td>0.706294</td>\n",
       "      <td>0.858021</td>\n",
       "      <td>0.528544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.567579</td>\n",
       "      <td>0.737321</td>\n",
       "      <td>0.694538</td>\n",
       "      <td>0.771580</td>\n",
       "      <td>0.643609</td>\n",
       "      <td>0.741779</td>\n",
       "      <td>0.725265</td>\n",
       "      <td>0.879568</td>\n",
       "      <td>0.509404</td>\n",
       "      <td>0.734503</td>\n",
       "      <td>0.696457</td>\n",
       "      <td>0.770015</td>\n",
       "      <td>0.557437</td>\n",
       "      <td>0.644624</td>\n",
       "      <td>0.735597</td>\n",
       "      <td>0.731608</td>\n",
       "      <td>0.878918</td>\n",
       "      <td>0.510942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.562441</td>\n",
       "      <td>0.739853</td>\n",
       "      <td>0.699182</td>\n",
       "      <td>0.777913</td>\n",
       "      <td>0.647434</td>\n",
       "      <td>0.745351</td>\n",
       "      <td>0.725386</td>\n",
       "      <td>0.877180</td>\n",
       "      <td>0.519817</td>\n",
       "      <td>0.737304</td>\n",
       "      <td>0.702965</td>\n",
       "      <td>0.777462</td>\n",
       "      <td>0.547546</td>\n",
       "      <td>0.653352</td>\n",
       "      <td>0.738569</td>\n",
       "      <td>0.734007</td>\n",
       "      <td>0.878611</td>\n",
       "      <td>0.518554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.557922</td>\n",
       "      <td>0.741772</td>\n",
       "      <td>0.702642</td>\n",
       "      <td>0.780403</td>\n",
       "      <td>0.648815</td>\n",
       "      <td>0.753372</td>\n",
       "      <td>0.713989</td>\n",
       "      <td>0.863187</td>\n",
       "      <td>0.547232</td>\n",
       "      <td>0.739171</td>\n",
       "      <td>0.703462</td>\n",
       "      <td>0.777231</td>\n",
       "      <td>0.546168</td>\n",
       "      <td>0.653187</td>\n",
       "      <td>0.746614</td>\n",
       "      <td>0.721559</td>\n",
       "      <td>0.863860</td>\n",
       "      <td>0.546146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.553568</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.705420</td>\n",
       "      <td>0.782621</td>\n",
       "      <td>0.652299</td>\n",
       "      <td>0.747976</td>\n",
       "      <td>0.726314</td>\n",
       "      <td>0.876053</td>\n",
       "      <td>0.527043</td>\n",
       "      <td>0.739918</td>\n",
       "      <td>0.707645</td>\n",
       "      <td>0.779036</td>\n",
       "      <td>0.544630</td>\n",
       "      <td>0.656518</td>\n",
       "      <td>0.741375</td>\n",
       "      <td>0.736176</td>\n",
       "      <td>0.878304</td>\n",
       "      <td>0.525690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch      loss  train_acc  ...  val_prec1  val_rec0  val_rec1\n",
       "0      0  0.587417   0.733075  ...   0.706294  0.858021  0.528544\n",
       "1      1  0.567579   0.737321  ...   0.731608  0.878918  0.510942\n",
       "2      2  0.562441   0.739853  ...   0.734007  0.878611  0.518554\n",
       "3      3  0.557922   0.741772  ...   0.721559  0.863860  0.546146\n",
       "4      4  0.553568   0.741935  ...   0.736176  0.878304  0.525690\n",
       "\n",
       "[5 rows x 19 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Escoger epoch con mejor aucpr en validation set\n",
    "import pandas as pd\n",
    "aucpr_lstm = pd.read_csv('mimic3models/los3days/keras_logs/k_lstm.n16.d0.3.dep2.bs8.ts1.0.csv', delimiter = \";\")\n",
    "aucpr_lstm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "um77bALfK4aS",
    "outputId": "babdcffb-4640-4c4c-f9d2-740c35ab1743"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucpr_lstm['epoch'][aucpr_lstm['val_auprc'].idxmax()]+1  #obs. epoch en dataframe empieza por 0, por lo tanto es epoch 35\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79ZshVZ3K4nl",
    "outputId": "e676190f-7345-47b5-aced-b01a4cc80c4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.723691527840633"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucpr_lstm['val_auprc'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5NOpRwLSK4q_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSXrDKxG4t6t"
   },
   "source": [
    "Predictiong in Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V3w6vstwY98G"
   },
   "outputs": [],
   "source": [
    "#revisando Keras_logs: epoch 35 tiene mejor performance (en validation dataset) en aucpr 0.7236 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51uaouDB4xfZ",
    "outputId": "bb59cc39-563a-4c40-dc82-0176217cc419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/MIMIC_benchmark/mimic3models/los3days/main.py:7: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Using TensorFlow backend.\n",
      "Namespace(batch_norm=False, batch_size=8, beta_1=0.9, data='/content/los3days/', depth=2, dim=16, dropout=0.3, epochs=50, imputation='previous', l1=0, l2=0, load_state='mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch35.test0.5336932081442612.state', lr=0.001, mode='test', network='mimic3models/keras_models/lstm.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/los3days', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)\n",
      "==> using model mimic3models/keras_models/lstm.py\n",
      "==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'size_coef', 'small_part', 'target_repl_coef', 'timestep', 'verbose', 'header'])\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1364: calling reduce_any_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2613: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "==> model.final_name: k_lstm.n16.d0.3.dep2.bs8.ts1.0\n",
      "==> compiling the model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2950: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "X (InputLayer)               (None, None, 76)          0         \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, None, 76)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 16)          5440      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 7,569\n",
      "Trainable params: 7,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:169: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-04-21 20:44:57.501961: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
      "2021-04-21 20:44:57.502367: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fe831156c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-21 20:44:57.502410: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-04-21 20:44:57.508559: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-21 20:44:57.520374: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-04-21 20:44:57.520439: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (30dacc6a361f): /proc/driver/nvidia/version does not exist\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:173: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:182: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:189: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "5282/5282 [==============================] - 5s 1ms/step\n",
      "confusion matrix:\n",
      "[[2798  442]\n",
      " [ 903 1139]]\n",
      "accuracy = 0.7453616261482239\n",
      "precision class 0 = 0.7560119032859802\n",
      "precision class 1 = 0.7204301357269287\n",
      "recall class 0 = 0.8635802268981934\n",
      "recall class 1 = 0.5577864646911621\n",
      "AUC of ROC = 0.7853260540984994\n",
      "AUC of PRC = 0.7126836787020691\n",
      "min(+P, Se) = 0.6518119490695397\n"
     ]
    }
   ],
   "source": [
    "!python3 -um mimic3models.los3days.main --network mimic3models/keras_models/lstm.py --data /content/los3days/ --dim 16 --timestep 1.0 --depth 2 --dropout 0.3 --batch_size 8 --epochs 50 --load_state mimic3models/los3days/keras_states/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch35.test0.5336932081442612.state --output_dir mimic3models/los3days --mode test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mmfO-Bs_441H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zho8busW45B5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EeOb1mZWERD"
   },
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rcadqvN4lgFj",
    "outputId": "ad7a0448-404c-4f7c-a9cf-4c93a54790f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the results in los3days_results_lstm_epoch35.json ...\n",
      "{'n_iters': 10000, 'AUC of ROC': {'value': 0.7853261296719508, 'mean': 0.7853141394894224, 'median': 0.7853430574482496, 'std': 0.006560660529273359, '2.5% percentile': 0.7723216687337059, '97.5% percentile': 0.7980868993639059}, 'AUC of PRC': {'value': 0.7126836374588981, 'mean': 0.7127860644603167, 'median': 0.7129193218321926, 'std': 0.010634197975967487, '2.5% percentile': 0.6917056609329736, '97.5% percentile': 0.7332218240290677}, 'min(+P, Se)': {'value': 0.6518119490695397, 'mean': 0.6514553968905032, 'median': 0.6515301085883515, 'std': 0.008640472447633362, '2.5% percentile': 0.6344030802481153, '97.5% percentile': 0.6680974876750959}}\n"
     ]
    }
   ],
   "source": [
    "!python3 -m mimic3benchmark.evaluation.evaluate_los_customized /content/gdrive/MyDrive/MIMIC_benchmark/mimic3models/los3days/test_predictions/k_lstm.n16.d0.3.dep2.bs8.ts1.0.epoch35.test0.5336932081442612.state.csv --test_listfile /content/los3days/test/listfile.csv --save_file los3days_results_lstm_epoch35.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tBCfOZZm_b3X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5w5h-EZ4_hQu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6P14T1oi_b6_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "brB5EdVoVgq8"
   },
   "source": [
    "## Channel-wise LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NDwniPjrbjXf",
    "outputId": "3e6c4584-c7bb-4165-fbf2-8c2b110857a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/MIMIC_benchmark/mimic3models/los3days/main.py:7: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Using TensorFlow backend.\n",
      "Namespace(batch_norm=False, batch_size=8, beta_1=0.9, data='/content/los3days/', depth=1, dim=8, dropout=0.3, epochs=6, imputation='previous', l1=0, l2=0, load_state='', lr=0.001, mode='train', network='mimic3models/keras_models/channel_wise_lstms.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/los3days', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)\n",
      "==> using model mimic3models/keras_models/channel_wise_lstms.py\n",
      "==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])\n",
      "==> found 17 channels: ['Capillary refill rate', 'Diastolic blood pressure', 'Fraction inspired oxygen', 'Glascow coma scale eye opening', 'Glascow coma scale motor response', 'Glascow coma scale total', 'Glascow coma scale verbal response', 'Glucose', 'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation', 'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight', 'pH']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1364: calling reduce_any_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2613: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1379: calling reduce_all_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "==> model.final_name: k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0\n",
      "==> compiling the model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2950: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X (InputLayer)                  (None, None, 76)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 76)     0           X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "slice_1 (Slice)                 (None, None, 3)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_2 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_3 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_4 (Slice)                 (None, None, 9)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_5 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_6 (Slice)                 (None, None, 14)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_7 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_8 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_9 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_10 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_11 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_12 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_13 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_14 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_15 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_16 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_17 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 8)      256         slice_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 8)      224         slice_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, None, 8)      224         slice_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 8)      448         slice_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, None, 8)      576         slice_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, None, 8)      608         slice_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, None, 8)      576         slice_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, None, 8)      224         slice_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, None, 8)      224         slice_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, None, 8)      224         slice_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, None, 8)      224         slice_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, None, 8)      224         slice_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, None, 8)      224         slice_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, None, 8)      224         slice_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, None, 8)      224         slice_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, None, 8)      224         slice_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, None, 8)      224         slice_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 136)    0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "                                                                 bidirectional_7[0][0]            \n",
      "                                                                 bidirectional_8[0][0]            \n",
      "                                                                 bidirectional_9[0][0]            \n",
      "                                                                 bidirectional_10[0][0]           \n",
      "                                                                 bidirectional_11[0][0]           \n",
      "                                                                 bidirectional_12[0][0]           \n",
      "                                                                 bidirectional_13[0][0]           \n",
      "                                                                 bidirectional_14[0][0]           \n",
      "                                                                 bidirectional_15[0][0]           \n",
      "                                                                 bidirectional_16[0][0]           \n",
      "                                                                 bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lstm_18 (LSTM)                  (None, 32)           21632       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           lstm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            33          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,817\n",
      "Trainable params: 26,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "==> training\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:958: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:680: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:945: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2378: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 24490 samples, validate on 5356 samples\n",
      "Epoch 1/6\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "2021-04-05 10:29:38.363273: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
      "2021-04-05 10:29:38.363537: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f957110f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-05 10:29:38.363573: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-04-05 10:29:38.365585: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-05 10:29:38.376306: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-04-05 10:29:38.376355: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (1864cda65bc6): /proc/driver/nvidia/version does not exist\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:173: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:182: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:189: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13162  1917]\n",
      " [ 4564  4847]]\n",
      "accuracy = 0.7353613972663879\n",
      "precision class 0 = 0.7425251007080078\n",
      "precision class 1 = 0.7165878415107727\n",
      "recall class 0 = 0.8728695511817932\n",
      "recall class 1 = 0.5150355696678162\n",
      "AUC of ROC = 0.7691838145332961\n",
      "AUC of PRC = 0.6901303439364371\n",
      "min(+P, Se) = 0.6422271809584529\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2849  405]\n",
      " [1011 1091]]\n",
      "accuracy = 0.7356235980987549\n",
      "precision class 0 = 0.7380828857421875\n",
      "precision class 1 = 0.7292780876159668\n",
      "recall class 0 = 0.8755378127098083\n",
      "recall class 1 = 0.5190294981002808\n",
      "AUC of ROC = 0.7682100402520032\n",
      "AUC of PRC = 0.691963989524753\n",
      "min(+P, Se) = 0.6458036984352774\n",
      "Epoch 00001: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch1.test0.5527024530625504.state\n",
      " - 1510s - loss: 0.5841 - val_loss: 0.5527\n",
      "Epoch 2/6\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[12905  2174]\n",
      " [ 4179  5232]]\n",
      "accuracy = 0.7405880093574524\n",
      "precision class 0 = 0.755385160446167\n",
      "precision class 1 = 0.7064542174339294\n",
      "recall class 0 = 0.8558259606361389\n",
      "recall class 1 = 0.5559451580047607\n",
      "AUC of ROC = 0.7771488430334627\n",
      "AUC of PRC = 0.6997953350394428\n",
      "min(+P, Se) = 0.6463712676654978\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2787  467]\n",
      " [ 942 1160]]\n",
      "accuracy = 0.7369305491447449\n",
      "precision class 0 = 0.7473853826522827\n",
      "precision class 1 = 0.712968647480011\n",
      "recall class 0 = 0.8564843535423279\n",
      "recall class 1 = 0.5518553853034973\n",
      "AUC of ROC = 0.7747022328370499\n",
      "AUC of PRC = 0.7019234365265883\n",
      "min(+P, Se) = 0.6503330161750713\n",
      "Epoch 00002: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch2.test0.5501062949038513.state\n",
      " - 1451s - loss: 0.5672 - val_loss: 0.5501\n",
      "Epoch 3/6\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13067  2012]\n",
      " [ 4320  5091]]\n",
      "accuracy = 0.7414454817771912\n",
      "precision class 0 = 0.7515385150909424\n",
      "precision class 1 = 0.7167394161224365\n",
      "recall class 0 = 0.8665693998336792\n",
      "recall class 1 = 0.5409626960754395\n",
      "AUC of ROC = 0.7815808653393337\n",
      "AUC of PRC = 0.7043413305896274\n",
      "min(+P, Se) = 0.649771543937945\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2838  416]\n",
      " [ 970 1132]]\n",
      "accuracy = 0.7412247657775879\n",
      "precision class 0 = 0.7452731132507324\n",
      "precision class 1 = 0.7312661409378052\n",
      "recall class 0 = 0.8721573352813721\n",
      "recall class 1 = 0.5385347008705139\n",
      "AUC of ROC = 0.7778104617781408\n",
      "AUC of PRC = 0.7055217710239414\n",
      "min(+P, Se) = 0.6531874405328258\n",
      "Epoch 00003: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch3.test0.5458507366684322.state\n",
      " - 1448s - loss: 0.5578 - val_loss: 0.5459\n",
      "Epoch 4/6\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13205  1874]\n",
      " [ 4383  5028]]\n",
      "accuracy = 0.7445079684257507\n",
      "precision class 0 = 0.7507960200309753\n",
      "precision class 1 = 0.7284845113754272\n",
      "recall class 0 = 0.8757212162017822\n",
      "recall class 1 = 0.5342684388160706\n",
      "AUC of ROC = 0.7855742457485044\n",
      "AUC of PRC = 0.708603357978448\n",
      "min(+P, Se) = 0.6569971310168952\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2851  403]\n",
      " [ 974 1128]]\n",
      "accuracy = 0.7429051399230957\n",
      "precision class 0 = 0.745359480381012\n",
      "precision class 1 = 0.7367733716964722\n",
      "recall class 0 = 0.8761524558067322\n",
      "recall class 1 = 0.5366317629814148\n",
      "AUC of ROC = 0.7790369402629391\n",
      "AUC of PRC = 0.7115726561897987\n",
      "min(+P, Se) = 0.6575082899099952\n",
      "Epoch 00004: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch4.test0.5428970179689563.state\n",
      " - 1450s - loss: 0.5527 - val_loss: 0.5429\n",
      "Epoch 5/6\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[12928  2151]\n",
      " [ 4067  5344]]\n",
      "accuracy = 0.7461004257202148\n",
      "precision class 0 = 0.7606943249702454\n",
      "precision class 1 = 0.7130087018013\n",
      "recall class 0 = 0.8573513031005859\n",
      "recall class 1 = 0.5678461194038391\n",
      "AUC of ROC = 0.7884027062542687\n",
      "AUC of PRC = 0.7126522003317791\n",
      "min(+P, Se) = 0.6578835529111772\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2802  452]\n",
      " [ 893 1209]]\n",
      "accuracy = 0.7488797903060913\n",
      "precision class 0 = 0.7583220601081848\n",
      "precision class 1 = 0.727874755859375\n",
      "recall class 0 = 0.861094057559967\n",
      "recall class 1 = 0.5751665234565735\n",
      "AUC of ROC = 0.7849850465824979\n",
      "AUC of PRC = 0.7175239809841427\n",
      "min(+P, Se) = 0.6607992388201712\n",
      "Epoch 00005: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch5.test0.5371807486019178.state\n",
      " - 1445s - loss: 0.5508 - val_loss: 0.5372\n",
      "Epoch 6/6\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13113  1966]\n",
      " [ 4194  5217]]\n",
      "accuracy = 0.7484687566757202\n",
      "precision class 0 = 0.7576702833175659\n",
      "precision class 1 = 0.7262982130050659\n",
      "recall class 0 = 0.8696200251579285\n",
      "recall class 1 = 0.554351270198822\n",
      "AUC of ROC = 0.7923479006739196\n",
      "AUC of PRC = 0.7179451978393092\n",
      "min(+P, Se) = 0.657422165550951\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2831  423]\n",
      " [ 932 1170]]\n",
      "accuracy = 0.7470126748085022\n",
      "precision class 0 = 0.7523252964019775\n",
      "precision class 1 = 0.7344632744789124\n",
      "recall class 0 = 0.8700061440467834\n",
      "recall class 1 = 0.5566127300262451\n",
      "AUC of ROC = 0.7874708256309881\n",
      "AUC of PRC = 0.7186183285526591\n",
      "min(+P, Se) = 0.6612826603325416\n",
      "Epoch 00006: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch6.test0.5352860175468211.state\n",
      " - 1449s - loss: 0.5478 - val_loss: 0.5353\n"
     ]
    }
   ],
   "source": [
    "!python -um mimic3models.los3days.main --data /content/los3days/ --network mimic3models/keras_models/channel_wise_lstms.py --dim 8 --depth 1 --batch_size 8 --dropout 0.3 --timestep 1.0 --epochs 6 --mode train --size_coef 4.0 --output_dir mimic3models/los3days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJkWS8HXO4Wp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLsHqJ-Rt-98"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g4wJJNUEO7Mp",
    "outputId": "6b2ff8a6-d884-489b-cd67-40019312472f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/MIMIC_benchmark/mimic3models/los3days/main.py:7: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Using TensorFlow backend.\n",
      "Namespace(batch_norm=False, batch_size=8, beta_1=0.9, data='/content/los3days/', depth=1, dim=8, dropout=0.3, epochs=3, imputation='previous', l1=0, l2=0, load_state='mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch7.test0.535226437607481.state', lr=0.001, mode='train', network='mimic3models/keras_models/channel_wise_lstms.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/los3days', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)\n",
      "==> using model mimic3models/keras_models/channel_wise_lstms.py\n",
      "==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])\n",
      "==> found 17 channels: ['Capillary refill rate', 'Diastolic blood pressure', 'Fraction inspired oxygen', 'Glascow coma scale eye opening', 'Glascow coma scale motor response', 'Glascow coma scale total', 'Glascow coma scale verbal response', 'Glucose', 'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation', 'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight', 'pH']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1364: calling reduce_any_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2613: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1379: calling reduce_all_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "==> model.final_name: k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0\n",
      "==> compiling the model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2950: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X (InputLayer)                  (None, None, 76)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 76)     0           X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "slice_1 (Slice)                 (None, None, 3)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_2 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_3 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_4 (Slice)                 (None, None, 9)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_5 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_6 (Slice)                 (None, None, 14)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_7 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_8 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_9 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_10 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_11 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_12 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_13 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_14 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_15 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_16 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_17 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 8)      256         slice_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 8)      224         slice_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, None, 8)      224         slice_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 8)      448         slice_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, None, 8)      576         slice_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, None, 8)      608         slice_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, None, 8)      576         slice_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, None, 8)      224         slice_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, None, 8)      224         slice_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, None, 8)      224         slice_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, None, 8)      224         slice_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, None, 8)      224         slice_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, None, 8)      224         slice_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, None, 8)      224         slice_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, None, 8)      224         slice_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, None, 8)      224         slice_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, None, 8)      224         slice_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 136)    0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "                                                                 bidirectional_7[0][0]            \n",
      "                                                                 bidirectional_8[0][0]            \n",
      "                                                                 bidirectional_9[0][0]            \n",
      "                                                                 bidirectional_10[0][0]           \n",
      "                                                                 bidirectional_11[0][0]           \n",
      "                                                                 bidirectional_12[0][0]           \n",
      "                                                                 bidirectional_13[0][0]           \n",
      "                                                                 bidirectional_14[0][0]           \n",
      "                                                                 bidirectional_15[0][0]           \n",
      "                                                                 bidirectional_16[0][0]           \n",
      "                                                                 bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lstm_18 (LSTM)                  (None, 32)           21632       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           lstm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            33          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,817\n",
      "Trainable params: 26,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:169: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-04-05 13:28:12.659036: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
      "2021-04-05 13:28:12.659313: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5565710e5d40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-05 13:28:12.659352: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-04-05 13:28:12.661342: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-05 13:28:12.672426: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-04-05 13:28:12.672475: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (1864cda65bc6): /proc/driver/nvidia/version does not exist\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:173: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:182: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:189: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "==> training\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:958: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:680: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:945: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 24490 samples, validate on 5356 samples\n",
      "Epoch 8/10\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13062  2017]\n",
      " [ 4116  5295]]\n",
      "accuracy = 0.7495712637901306\n",
      "precision class 0 = 0.7603911757469177\n",
      "precision class 1 = 0.7241520881652832\n",
      "recall class 0 = 0.8662378191947937\n",
      "recall class 1 = 0.5626394748687744\n",
      "AUC of ROC = 0.7942448417225895\n",
      "AUC of PRC = 0.7191580362822916\n",
      "min(+P, Se) = 0.6579534587185208\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2818  436]\n",
      " [ 908 1194]]\n",
      "accuracy = 0.7490664720535278\n",
      "precision class 0 = 0.7563070058822632\n",
      "precision class 1 = 0.7325153350830078\n",
      "recall class 0 = 0.8660110831260681\n",
      "recall class 1 = 0.5680304765701294\n",
      "AUC of ROC = 0.7893093006514122\n",
      "AUC of PRC = 0.7169040749157851\n",
      "min(+P, Se) = 0.6625475285171103\n",
      "Epoch 00008: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch8.test0.5352565264906609.state\n",
      " - 1547s - loss: 0.5453 - val_loss: 0.5353\n",
      "Epoch 9/10\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[12816  2263]\n",
      " [ 3878  5533]]\n",
      "accuracy = 0.7492445707321167\n",
      "precision class 0 = 0.7677009701728821\n",
      "precision class 1 = 0.7097229361534119\n",
      "recall class 0 = 0.8499237298965454\n",
      "recall class 1 = 0.5879290103912354\n",
      "AUC of ROC = 0.7959273628693719\n",
      "AUC of PRC = 0.719699068186961\n",
      "min(+P, Se) = 0.6611412177239401\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2762  492]\n",
      " [ 861 1241]]\n",
      "accuracy = 0.74738609790802\n",
      "precision class 0 = 0.7623516321182251\n",
      "precision class 1 = 0.7160992622375488\n",
      "recall class 0 = 0.8488014936447144\n",
      "recall class 1 = 0.5903900861740112\n",
      "AUC of ROC = 0.7883819489969748\n",
      "AUC of PRC = 0.722182356971634\n",
      "min(+P, Se) = 0.6612826603325416\n",
      "Epoch 00009: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch9.test0.5337889697277519.state\n",
      " - 1493s - loss: 0.5418 - val_loss: 0.5338\n",
      "Epoch 10/10\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13150  1929]\n",
      " [ 4143  5268]]\n",
      "accuracy = 0.7520620822906494\n",
      "precision class 0 = 0.7604233026504517\n",
      "precision class 1 = 0.7319716811180115\n",
      "recall class 0 = 0.872073769569397\n",
      "recall class 1 = 0.5597704648971558\n",
      "AUC of ROC = 0.798803537229339\n",
      "AUC of PRC = 0.7246438982428703\n",
      "min(+P, Se) = 0.6648602698969291\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2846  408]\n",
      " [ 920 1182]]\n",
      "accuracy = 0.7520537972450256\n",
      "precision class 0 = 0.7557089924812317\n",
      "precision class 1 = 0.7433962225914001\n",
      "recall class 0 = 0.8746158480644226\n",
      "recall class 1 = 0.5623216032981873\n",
      "AUC of ROC = 0.7933390332150667\n",
      "AUC of PRC = 0.7240410274264789\n",
      "min(+P, Se) = 0.6707897240723121\n",
      "Epoch 00010: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch10.test0.5291586841906604.state\n",
      " - 1483s - loss: 0.5437 - val_loss: 0.5292\n"
     ]
    }
   ],
   "source": [
    "#load previous models states and continue training:\n",
    "!python -um mimic3models.los3days.main --data /content/los3days/ --network mimic3models/keras_models/channel_wise_lstms.py --dim 8 --depth 1 --batch_size 8 --dropout 0.3 --timestep 1.0 --epochs 3 --load_state mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch7.test0.535226437607481.state  --mode train --size_coef 4.0 --output_dir mimic3models/los3days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-UMByttnOgq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbIiYFJv0slM"
   },
   "source": [
    "Load epoch 10 and continue training:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B9dCm720Wf6Y",
    "outputId": "b79943af-9e72-4efc-ab17-eb4306e7b4ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/MIMIC_benchmark/mimic3models/los3days/main.py:7: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Using TensorFlow backend.\n",
      "Namespace(batch_norm=False, batch_size=8, beta_1=0.9, data='/content/los3days/', depth=1, dim=8, dropout=0.3, epochs=5, imputation='previous', l1=0, l2=0, load_state='mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch10.test0.5291586841906604.state', lr=0.001, mode='train', network='mimic3models/keras_models/channel_wise_lstms.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/los3days', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)\n",
      "==> using model mimic3models/keras_models/channel_wise_lstms.py\n",
      "==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])\n",
      "==> found 17 channels: ['Capillary refill rate', 'Diastolic blood pressure', 'Fraction inspired oxygen', 'Glascow coma scale eye opening', 'Glascow coma scale motor response', 'Glascow coma scale total', 'Glascow coma scale verbal response', 'Glucose', 'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation', 'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight', 'pH']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1364: calling reduce_any_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2613: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1379: calling reduce_all_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "==> model.final_name: k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0\n",
      "==> compiling the model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2950: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X (InputLayer)                  (None, None, 76)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 76)     0           X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "slice_1 (Slice)                 (None, None, 3)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_2 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_3 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_4 (Slice)                 (None, None, 9)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_5 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_6 (Slice)                 (None, None, 14)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_7 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_8 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_9 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_10 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_11 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_12 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_13 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_14 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_15 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_16 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_17 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 8)      256         slice_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 8)      224         slice_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, None, 8)      224         slice_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 8)      448         slice_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, None, 8)      576         slice_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, None, 8)      608         slice_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, None, 8)      576         slice_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, None, 8)      224         slice_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, None, 8)      224         slice_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, None, 8)      224         slice_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, None, 8)      224         slice_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, None, 8)      224         slice_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, None, 8)      224         slice_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, None, 8)      224         slice_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, None, 8)      224         slice_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, None, 8)      224         slice_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, None, 8)      224         slice_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 136)    0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "                                                                 bidirectional_7[0][0]            \n",
      "                                                                 bidirectional_8[0][0]            \n",
      "                                                                 bidirectional_9[0][0]            \n",
      "                                                                 bidirectional_10[0][0]           \n",
      "                                                                 bidirectional_11[0][0]           \n",
      "                                                                 bidirectional_12[0][0]           \n",
      "                                                                 bidirectional_13[0][0]           \n",
      "                                                                 bidirectional_14[0][0]           \n",
      "                                                                 bidirectional_15[0][0]           \n",
      "                                                                 bidirectional_16[0][0]           \n",
      "                                                                 bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lstm_18 (LSTM)                  (None, 32)           21632       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           lstm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            33          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,817\n",
      "Trainable params: 26,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:169: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-04-22 09:06:30.794663: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
      "2021-04-22 09:06:30.795453: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55df88a01d40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-22 09:06:30.795516: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-04-22 09:06:30.864436: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-22 09:06:30.943159: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-04-22 09:06:30.943268: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (6b9dead74af2): /proc/driver/nvidia/version does not exist\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:173: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:182: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:189: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "==> training\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:958: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:680: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:945: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 24490 samples, validate on 5356 samples\n",
      "Epoch 11/15\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13328  1751]\n",
      " [ 4369  5042]]\n",
      "accuracy = 0.7501021027565002\n",
      "precision class 0 = 0.7531219720840454\n",
      "precision class 1 = 0.7422346472740173\n",
      "recall class 0 = 0.883878231048584\n",
      "recall class 1 = 0.5357560515403748\n",
      "AUC of ROC = 0.7965119262896142\n",
      "AUC of PRC = 0.7215595545455502\n",
      "min(+P, Se) = 0.6637628811218528\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2873  381]\n",
      " [ 970 1132]]\n",
      "accuracy = 0.7477595210075378\n",
      "precision class 0 = 0.7475930452346802\n",
      "precision class 1 = 0.7481824159622192\n",
      "recall class 0 = 0.88291335105896\n",
      "recall class 1 = 0.5385347008705139\n",
      "AUC of ROC = 0.788472154888633\n",
      "AUC of PRC = 0.7192054152157443\n",
      "min(+P, Se) = 0.6627021883920076\n",
      "Epoch 00011: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch11.test0.534096741961222.state\n",
      " - 1608s - loss: 0.5416 - val_loss: 0.5341\n",
      "Epoch 12/15\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13315  1764]\n",
      " [ 4371  5040]]\n",
      "accuracy = 0.7494896054267883\n",
      "precision class 0 = 0.7528553605079651\n",
      "precision class 1 = 0.7407407164573669\n",
      "recall class 0 = 0.8830161094665527\n",
      "recall class 1 = 0.5355435013771057\n",
      "AUC of ROC = 0.7986796792233732\n",
      "AUC of PRC = 0.7248744920848713\n",
      "min(+P, Se) = 0.6642227180958453\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2878  376]\n",
      " [ 960 1142]]\n",
      "accuracy = 0.7505601048469543\n",
      "precision class 0 = 0.749869704246521\n",
      "precision class 1 = 0.7523056864738464\n",
      "recall class 0 = 0.8844498991966248\n",
      "recall class 1 = 0.5432921051979065\n",
      "AUC of ROC = 0.7909185328223711\n",
      "AUC of PRC = 0.721402826713871\n",
      "min(+P, Se) = 0.6680932001902045\n",
      "Epoch 00012: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch12.test0.5371781995351677.state\n",
      " - 1514s - loss: 0.5394 - val_loss: 0.5372\n",
      "Epoch 13/15\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[12639  2440]\n",
      " [ 3675  5736]]\n",
      "accuracy = 0.750306248664856\n",
      "precision class 0 = 0.7747333645820618\n",
      "precision class 1 = 0.7015655636787415\n",
      "recall class 0 = 0.8381855487823486\n",
      "recall class 1 = 0.6094995141029358\n",
      "AUC of ROC = 0.8004860266655404\n",
      "AUC of PRC = 0.7264042692132522\n",
      "min(+P, Se) = 0.6645771355716107\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2735  519]\n",
      " [ 837 1265]]\n",
      "accuracy = 0.7468259930610657\n",
      "precision class 0 = 0.7656775116920471\n",
      "precision class 1 = 0.709080696105957\n",
      "recall class 0 = 0.840503990650177\n",
      "recall class 1 = 0.6018077731132507\n",
      "AUC of ROC = 0.7916913502345353\n",
      "AUC of PRC = 0.7228298479172773\n",
      "min(+P, Se) = 0.6679352997145576\n",
      "Epoch 00013: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch13.test0.5349201297163518.state\n",
      " - 1522s - loss: 0.5373 - val_loss: 0.5349\n",
      "Epoch 14/15\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[12795  2284]\n",
      " [ 3788  5623]]\n",
      "accuracy = 0.7520620822906494\n",
      "precision class 0 = 0.7715733051300049\n",
      "precision class 1 = 0.7111420035362244\n",
      "recall class 0 = 0.8485310673713684\n",
      "recall class 1 = 0.5974922776222229\n",
      "AUC of ROC = 0.8026302221610184\n",
      "AUC of PRC = 0.7319753031395063\n",
      "min(+P, Se) = 0.6673040152963671\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2772  482]\n",
      " [ 852 1250]]\n",
      "accuracy = 0.7509335279464722\n",
      "precision class 0 = 0.7649006843566895\n",
      "precision class 1 = 0.7217090129852295\n",
      "recall class 0 = 0.851874589920044\n",
      "recall class 1 = 0.5946717262268066\n",
      "AUC of ROC = 0.7932687837321789\n",
      "AUC of PRC = 0.7260443006316449\n",
      "min(+P, Se) = 0.6707897240723121\n",
      "Epoch 00014: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch14.test0.5295185902788178.state\n",
      " - 1530s - loss: 0.5369 - val_loss: 0.5295\n",
      "Epoch 15/15\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13115  1964]\n",
      " [ 4065  5346]]\n",
      "accuracy = 0.7538178563117981\n",
      "precision class 0 = 0.7633876800537109\n",
      "precision class 1 = 0.7313269376754761\n",
      "recall class 0 = 0.8697526454925537\n",
      "recall class 1 = 0.5680586695671082\n",
      "AUC of ROC = 0.8029746237344016\n",
      "AUC of PRC = 0.7315123275278975\n",
      "min(+P, Se) = 0.6679770505737357\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2843  411]\n",
      " [ 929 1173]]\n",
      "accuracy = 0.7498133182525635\n",
      "precision class 0 = 0.7537115812301636\n",
      "precision class 1 = 0.7405303120613098\n",
      "recall class 0 = 0.8736939430236816\n",
      "recall class 1 = 0.5580399632453918\n",
      "AUC of ROC = 0.7926513046666709\n",
      "AUC of PRC = 0.7257196557428974\n",
      "min(+P, Se) = 0.6703087885985748\n",
      "Epoch 00015: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch15.test0.5296070242524592.state\n",
      " - 1476s - loss: 0.5378 - val_loss: 0.5296\n"
     ]
    }
   ],
   "source": [
    "#load previous models states and continue training:\n",
    "!python -um mimic3models.los3days.main --data /content/los3days/ --network mimic3models/keras_models/channel_wise_lstms.py --dim 8 --depth 1 --batch_size 8 --dropout 0.3 --timestep 1.0 --epochs 5 --load_state mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch10.test0.5291586841906604.state  --mode train --size_coef 4.0 --output_dir mimic3models/los3days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4dbJtrXSoF2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WuzkXon0_lhp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YiFKePNEP5s-"
   },
   "source": [
    "Load epoch 15 and continue training:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hgminvVy14_B",
    "outputId": "fb751822-871c-4921-f153-39dd6a064cf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/MIMIC_benchmark/mimic3models/los3days/main.py:7: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Using TensorFlow backend.\n",
      "Namespace(batch_norm=False, batch_size=8, beta_1=0.9, data='/content/los3days/', depth=1, dim=8, dropout=0.3, epochs=5, imputation='previous', l1=0, l2=0, load_state='mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch15.test0.5296070242524592.state', lr=0.001, mode='train', network='mimic3models/keras_models/channel_wise_lstms.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/los3days', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=1)\n",
      "==> using model mimic3models/keras_models/channel_wise_lstms.py\n",
      "==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])\n",
      "==> found 17 channels: ['Capillary refill rate', 'Diastolic blood pressure', 'Fraction inspired oxygen', 'Glascow coma scale eye opening', 'Glascow coma scale motor response', 'Glascow coma scale total', 'Glascow coma scale verbal response', 'Glucose', 'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation', 'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight', 'pH']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1364: calling reduce_any_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2613: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1379: calling reduce_all_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "==> model.final_name: k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0\n",
      "==> compiling the model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2950: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X (InputLayer)                  (None, None, 76)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 76)     0           X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "slice_1 (Slice)                 (None, None, 3)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_2 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_3 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_4 (Slice)                 (None, None, 9)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_5 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_6 (Slice)                 (None, None, 14)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_7 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_8 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_9 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_10 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_11 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_12 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_13 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_14 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_15 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_16 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_17 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 8)      256         slice_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 8)      224         slice_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, None, 8)      224         slice_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 8)      448         slice_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, None, 8)      576         slice_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, None, 8)      608         slice_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, None, 8)      576         slice_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, None, 8)      224         slice_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, None, 8)      224         slice_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, None, 8)      224         slice_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, None, 8)      224         slice_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, None, 8)      224         slice_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, None, 8)      224         slice_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, None, 8)      224         slice_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, None, 8)      224         slice_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, None, 8)      224         slice_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, None, 8)      224         slice_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 136)    0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "                                                                 bidirectional_7[0][0]            \n",
      "                                                                 bidirectional_8[0][0]            \n",
      "                                                                 bidirectional_9[0][0]            \n",
      "                                                                 bidirectional_10[0][0]           \n",
      "                                                                 bidirectional_11[0][0]           \n",
      "                                                                 bidirectional_12[0][0]           \n",
      "                                                                 bidirectional_13[0][0]           \n",
      "                                                                 bidirectional_14[0][0]           \n",
      "                                                                 bidirectional_15[0][0]           \n",
      "                                                                 bidirectional_16[0][0]           \n",
      "                                                                 bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lstm_18 (LSTM)                  (None, 32)           21632       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           lstm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            33          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,817\n",
      "Trainable params: 26,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:169: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-04-22 12:51:12.251957: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
      "2021-04-22 12:51:12.252345: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55adda003d40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-22 12:51:12.252407: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-04-22 12:51:12.256252: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-22 12:51:12.267986: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-04-22 12:51:12.268067: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (6b9dead74af2): /proc/driver/nvidia/version does not exist\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:173: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:182: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:189: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "==> training\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:958: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:680: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:945: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 24490 samples, validate on 5356 samples\n",
      "Epoch 16/20\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5358\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13005  2074]\n",
      " [ 3962  5449]]\n",
      "accuracy = 0.7535320520401001\n",
      "precision class 0 = 0.7664878964424133\n",
      "precision class 1 = 0.7243121266365051\n",
      "recall class 0 = 0.8624577522277832\n",
      "recall class 1 = 0.5790032744407654\n",
      "AUC of ROC = 0.8034704080980537\n",
      "AUC of PRC = 0.7313492100432893\n",
      "min(+P, Se) = 0.6685082872928176\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2805  449]\n",
      " [ 894 1208]]\n",
      "accuracy = 0.7492531538009644\n",
      "precision class 0 = 0.7583130598068237\n",
      "precision class 1 = 0.7290283441543579\n",
      "recall class 0 = 0.862015962600708\n",
      "recall class 1 = 0.5746907591819763\n",
      "AUC of ROC = 0.7921295140227032\n",
      "AUC of PRC = 0.7238313182722163\n",
      "min(+P, Se) = 0.6646051379638439\n",
      "Epoch 00016: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch16.test0.5323451445385803.state\n",
      "24490/24490 [==============================] - 1574s 64ms/step - loss: 0.5358 - val_loss: 0.5323\n",
      "Epoch 17/20\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5343\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13264  1815]\n",
      " [ 4191  5220]]\n",
      "accuracy = 0.7547570466995239\n",
      "precision class 0 = 0.7598968744277954\n",
      "precision class 1 = 0.7420042753219604\n",
      "recall class 0 = 0.879633903503418\n",
      "recall class 1 = 0.5546700954437256\n",
      "AUC of ROC = 0.8027919813580682\n",
      "AUC of PRC = 0.7321187970041879\n",
      "min(+P, Se) = 0.6686855807034322\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2869  385]\n",
      " [ 944 1158]]\n",
      "accuracy = 0.7518670558929443\n",
      "precision class 0 = 0.7524259090423584\n",
      "precision class 1 = 0.7504860758781433\n",
      "recall class 0 = 0.8816840648651123\n",
      "recall class 1 = 0.5509039163589478\n",
      "AUC of ROC = 0.7916187615388979\n",
      "AUC of PRC = 0.7283413763628588\n",
      "min(+P, Se) = 0.664292497625831\n",
      "Epoch 00017: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch17.test0.530274282314601.state\n",
      "24490/24490 [==============================] - 1450s 59ms/step - loss: 0.5343 - val_loss: 0.5303\n",
      "Epoch 18/20\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5345\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13396  1683]\n",
      " [ 4363  5048]]\n",
      "accuracy = 0.7531237006187439\n",
      "precision class 0 = 0.7543217539787292\n",
      "precision class 1 = 0.7499628663063049\n",
      "recall class 0 = 0.8883877992630005\n",
      "recall class 1 = 0.5363935828208923\n",
      "AUC of ROC = 0.8039427830061362\n",
      "AUC of PRC = 0.7329817861777452\n",
      "min(+P, Se) = 0.6688980979704601\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2899  355]\n",
      " [ 990 1112]]\n",
      "accuracy = 0.7488797903060913\n",
      "precision class 0 = 0.7454358339309692\n",
      "precision class 1 = 0.7580095529556274\n",
      "recall class 0 = 0.8909035325050354\n",
      "recall class 1 = 0.5290199518203735\n",
      "AUC of ROC = 0.792876234592629\n",
      "AUC of PRC = 0.7274237217184213\n",
      "min(+P, Se) = 0.6679352997145576\n",
      "Epoch 00018: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch18.test0.5312321713560103.state\n",
      "24490/24490 [==============================] - 1352s 55ms/step - loss: 0.5344 - val_loss: 0.5312\n",
      "Epoch 19/20\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5321\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13257  1822]\n",
      " [ 4197  5214]]\n",
      "accuracy = 0.7542262077331543\n",
      "precision class 0 = 0.7595393657684326\n",
      "precision class 1 = 0.7410460710525513\n",
      "recall class 0 = 0.8791697025299072\n",
      "recall class 1 = 0.5540325045585632\n",
      "AUC of ROC = 0.8055878328163769\n",
      "AUC of PRC = 0.7359073540125102\n",
      "min(+P, Se) = 0.6699957501062473\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2874  380]\n",
      " [ 940 1162]]\n",
      "accuracy = 0.7535474300384521\n",
      "precision class 0 = 0.7535395622253418\n",
      "precision class 1 = 0.7535668015480042\n",
      "recall class 0 = 0.8832206726074219\n",
      "recall class 1 = 0.5528068542480469\n",
      "AUC of ROC = 0.793231429428583\n",
      "AUC of PRC = 0.7277413267510564\n",
      "min(+P, Se) = 0.6665080875356802\n",
      "Epoch 00019: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch19.test0.5293736811713374.state\n",
      "24490/24490 [==============================] - 1409s 58ms/step - loss: 0.5320 - val_loss: 0.5294\n",
      "Epoch 20/20\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5339\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13297  1782]\n",
      " [ 4235  5176]]\n",
      "accuracy = 0.7543078660964966\n",
      "precision class 0 = 0.758441686630249\n",
      "precision class 1 = 0.7438918948173523\n",
      "recall class 0 = 0.881822407245636\n",
      "recall class 1 = 0.549994707107544\n",
      "AUC of ROC = 0.8056250187576895\n",
      "AUC of PRC = 0.7371493482876426\n",
      "min(+P, Se) = 0.6713420465412815\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2881  373]\n",
      " [ 968 1134]]\n",
      "accuracy = 0.7496265769004822\n",
      "precision class 0 = 0.7485061287879944\n",
      "precision class 1 = 0.752488374710083\n",
      "recall class 0 = 0.8853718638420105\n",
      "recall class 1 = 0.5394862294197083\n",
      "AUC of ROC = 0.793558188209549\n",
      "AUC of PRC = 0.7302114838779445\n",
      "min(+P, Se) = 0.6731684110371076\n",
      "Epoch 00020: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch20.test0.5294502408002365.state\n",
      "24490/24490 [==============================] - 1441s 59ms/step - loss: 0.5340 - val_loss: 0.5295\n"
     ]
    }
   ],
   "source": [
    "#load previous models states and continue training:\n",
    "!python -um mimic3models.los3days.main --data /content/los3days/ --network mimic3models/keras_models/channel_wise_lstms.py --dim 8 --depth 1 --batch_size 8 --dropout 0.3 --timestep 1.0 --epochs 5 --load_state mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch15.test0.5296070242524592.state  --mode train --size_coef 4.0 --output_dir mimic3models/los3days --verbose 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "njlzP0sa15BB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1s-KZ8kQDw19"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Bwp-KdnFdy4"
   },
   "source": [
    "Load epoch 20 and continue training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QxjXOL0phkRD",
    "outputId": "5b7873f1-ef24-4eb8-b408-2e12ba2b6977"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/MIMIC_benchmark/mimic3models/los3days/main.py:7: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Using TensorFlow backend.\n",
      "Namespace(batch_norm=False, batch_size=8, beta_1=0.9, data='/content/los3days/', depth=1, dim=8, dropout=0.3, epochs=5, imputation='previous', l1=0, l2=0, load_state='mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch20.test0.5294502408002365.state', lr=0.001, mode='train', network='mimic3models/keras_models/channel_wise_lstms.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/los3days', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=1)\n",
      "==> using model mimic3models/keras_models/channel_wise_lstms.py\n",
      "==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])\n",
      "==> found 17 channels: ['Capillary refill rate', 'Diastolic blood pressure', 'Fraction inspired oxygen', 'Glascow coma scale eye opening', 'Glascow coma scale motor response', 'Glascow coma scale total', 'Glascow coma scale verbal response', 'Glucose', 'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation', 'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight', 'pH']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1364: calling reduce_any_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2613: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1379: calling reduce_all_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "==> model.final_name: k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0\n",
      "==> compiling the model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2950: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X (InputLayer)                  (None, None, 76)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 76)     0           X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "slice_1 (Slice)                 (None, None, 3)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_2 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_3 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_4 (Slice)                 (None, None, 9)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_5 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_6 (Slice)                 (None, None, 14)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_7 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_8 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_9 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_10 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_11 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_12 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_13 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_14 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_15 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_16 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_17 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 8)      256         slice_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 8)      224         slice_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, None, 8)      224         slice_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 8)      448         slice_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, None, 8)      576         slice_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, None, 8)      608         slice_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, None, 8)      576         slice_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, None, 8)      224         slice_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, None, 8)      224         slice_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, None, 8)      224         slice_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, None, 8)      224         slice_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, None, 8)      224         slice_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, None, 8)      224         slice_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, None, 8)      224         slice_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, None, 8)      224         slice_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, None, 8)      224         slice_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, None, 8)      224         slice_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 136)    0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "                                                                 bidirectional_7[0][0]            \n",
      "                                                                 bidirectional_8[0][0]            \n",
      "                                                                 bidirectional_9[0][0]            \n",
      "                                                                 bidirectional_10[0][0]           \n",
      "                                                                 bidirectional_11[0][0]           \n",
      "                                                                 bidirectional_12[0][0]           \n",
      "                                                                 bidirectional_13[0][0]           \n",
      "                                                                 bidirectional_14[0][0]           \n",
      "                                                                 bidirectional_15[0][0]           \n",
      "                                                                 bidirectional_16[0][0]           \n",
      "                                                                 bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lstm_18 (LSTM)                  (None, 32)           21632       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           lstm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            33          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,817\n",
      "Trainable params: 26,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:169: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-04-22 15:27:47.782524: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
      "2021-04-22 15:27:47.783004: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559042cebd40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-22 15:27:47.783066: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-04-22 15:27:47.790041: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-22 15:27:47.802354: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-04-22 15:27:47.802441: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (6b9dead74af2): /proc/driver/nvidia/version does not exist\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:173: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:182: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:189: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "==> training\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:958: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:680: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:945: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 24490 samples, validate on 5356 samples\n",
      "Epoch 21/25\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5319\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13304  1775]\n",
      " [ 4221  5190]]\n",
      "accuracy = 0.7551653981208801\n",
      "precision class 0 = 0.7591440677642822\n",
      "precision class 1 = 0.7451543211936951\n",
      "recall class 0 = 0.8822866082191467\n",
      "recall class 1 = 0.5514823198318481\n",
      "AUC of ROC = 0.8072052380467865\n",
      "AUC of PRC = 0.7381718314795886\n",
      "min(+P, Se) = 0.6699957501062473\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2887  367]\n",
      " [ 949 1153]]\n",
      "accuracy = 0.7542942762374878\n",
      "precision class 0 = 0.7526068687438965\n",
      "precision class 1 = 0.758552610874176\n",
      "recall class 0 = 0.8872157335281372\n",
      "recall class 1 = 0.5485252141952515\n",
      "AUC of ROC = 0.7968962448032927\n",
      "AUC of PRC = 0.7298152837885518\n",
      "min(+P, Se) = 0.6750713606089439\n",
      "Epoch 00021: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch21.test0.5263252791359497.state\n",
      "24490/24490 [==============================] - 1578s 64ms/step - loss: 0.5319 - val_loss: 0.5263\n",
      "Epoch 22/25\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5301\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13221  1858]\n",
      " [ 4104  5307]]\n",
      "accuracy = 0.7565537095069885\n",
      "precision class 0 = 0.7631168961524963\n",
      "precision class 1 = 0.7406838536262512\n",
      "recall class 0 = 0.8767822980880737\n",
      "recall class 1 = 0.5639145970344543\n",
      "AUC of ROC = 0.8091861346203376\n",
      "AUC of PRC = 0.7408561916457537\n",
      "min(+P, Se) = 0.6730013801889797\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2850  404]\n",
      " [ 932 1170]]\n",
      "accuracy = 0.7505601048469543\n",
      "precision class 0 = 0.7535695433616638\n",
      "precision class 1 = 0.7433291077613831\n",
      "recall class 0 = 0.8758451342582703\n",
      "recall class 1 = 0.5566127300262451\n",
      "AUC of ROC = 0.7969288475809909\n",
      "AUC of PRC = 0.73215518998239\n",
      "min(+P, Se) = 0.6736441484300666\n",
      "Epoch 00022: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch22.test0.5259785760330388.state\n",
      "24490/24490 [==============================] - 1547s 63ms/step - loss: 0.5301 - val_loss: 0.5260\n",
      "Epoch 23/25\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5298\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13009  2070]\n",
      " [ 3876  5535]]\n",
      "accuracy = 0.7572070360183716\n",
      "precision class 0 = 0.7704471349716187\n",
      "precision class 1 = 0.7278106212615967\n",
      "recall class 0 = 0.8627229928970337\n",
      "recall class 1 = 0.5881415605545044\n",
      "AUC of ROC = 0.8084739220180016\n",
      "AUC of PRC = 0.7403728518084842\n",
      "min(+P, Se) = 0.6720858569758793\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2816  438]\n",
      " [ 891 1211]]\n",
      "accuracy = 0.7518670558929443\n",
      "precision class 0 = 0.7596439123153687\n",
      "precision class 1 = 0.7343844771385193\n",
      "recall class 0 = 0.8653964400291443\n",
      "recall class 1 = 0.576117992401123\n",
      "AUC of ROC = 0.7953947626196142\n",
      "AUC of PRC = 0.7306184071543422\n",
      "min(+P, Se) = 0.6755470980019029\n",
      "Epoch 00023: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch23.test0.5267632004482876.state\n",
      "24490/24490 [==============================] - 1565s 64ms/step - loss: 0.5298 - val_loss: 0.5268\n",
      "Epoch 24/25\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5294\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13278  1801]\n",
      " [ 4157  5254]]\n",
      "accuracy = 0.7567170262336731\n",
      "precision class 0 = 0.7615715265274048\n",
      "precision class 1 = 0.7447200417518616\n",
      "recall class 0 = 0.8805623650550842\n",
      "recall class 1 = 0.5582828521728516\n",
      "AUC of ROC = 0.8099444861180202\n",
      "AUC of PRC = 0.7437851378584676\n",
      "min(+P, Se) = 0.6728644283892903\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2870  384]\n",
      " [ 952 1150]]\n",
      "accuracy = 0.7505601048469543\n",
      "precision class 0 = 0.7509157657623291\n",
      "precision class 1 = 0.7496740818023682\n",
      "recall class 0 = 0.8819913864135742\n",
      "recall class 1 = 0.5470979809761047\n",
      "AUC of ROC = 0.7958025897424351\n",
      "AUC of PRC = 0.7317183314481345\n",
      "min(+P, Se) = 0.6704707560627675\n",
      "Epoch 00024: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch24.test0.5289785877548998.state\n",
      "24490/24490 [==============================] - 1431s 58ms/step - loss: 0.5294 - val_loss: 0.5290\n",
      "Epoch 25/25\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5273\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13341  1738]\n",
      " [ 4171  5240]]\n",
      "accuracy = 0.7587178349494934\n",
      "precision class 0 = 0.7618204951286316\n",
      "precision class 1 = 0.7509315013885498\n",
      "recall class 0 = 0.8847403526306152\n",
      "recall class 1 = 0.5567952394485474\n",
      "AUC of ROC = 0.811345582905274\n",
      "AUC of PRC = 0.7468215721209432\n",
      "min(+P, Se) = 0.6756986505153544\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2875  379]\n",
      " [ 960 1142]]\n",
      "accuracy = 0.75\n",
      "precision class 0 = 0.7496740818023682\n",
      "precision class 1 = 0.7508218288421631\n",
      "recall class 0 = 0.8835279941558838\n",
      "recall class 1 = 0.5432921051979065\n",
      "AUC of ROC = 0.7949785289509742\n",
      "AUC of PRC = 0.7304821075843082\n",
      "min(+P, Se) = 0.6718972895863052\n",
      "Epoch 00025: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch25.test0.527318338300863.state\n",
      "24490/24490 [==============================] - 1472s 60ms/step - loss: 0.5273 - val_loss: 0.5273\n"
     ]
    }
   ],
   "source": [
    "#load previous models states and continue training:\n",
    "!python -um mimic3models.los3days.main --data /content/los3days/ --network mimic3models/keras_models/channel_wise_lstms.py --dim 8 --depth 1 --batch_size 8 --dropout 0.3 --timestep 1.0 --epochs 5 --load_state mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch20.test0.5294502408002365.state  --mode train --size_coef 4.0 --output_dir mimic3models/los3days --verbose 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qEJKJ8gzMgs_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MHMJ2UUKh4Ld"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7CD3o6J1UJ3"
   },
   "source": [
    "Load epoch 25 and continue training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8rqSs8PnL6k",
    "outputId": "d906afbb-85c0-47db-883b-038c1f3f52b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/MIMIC_benchmark/mimic3models/los3days/main.py:7: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Using TensorFlow backend.\n",
      "Namespace(batch_norm=False, batch_size=8, beta_1=0.9, data='/content/los3days/', depth=1, dim=8, dropout=0.3, epochs=5, imputation='previous', l1=0, l2=0, load_state='mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch25.test0.527318338300863.state', lr=0.001, mode='train', network='mimic3models/keras_models/channel_wise_lstms.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/los3days', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=1)\n",
      "==> using model mimic3models/keras_models/channel_wise_lstms.py\n",
      "==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])\n",
      "==> found 17 channels: ['Capillary refill rate', 'Diastolic blood pressure', 'Fraction inspired oxygen', 'Glascow coma scale eye opening', 'Glascow coma scale motor response', 'Glascow coma scale total', 'Glascow coma scale verbal response', 'Glucose', 'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation', 'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight', 'pH']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1364: calling reduce_any_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2613: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1379: calling reduce_all_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "==> model.final_name: k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0\n",
      "==> compiling the model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2950: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X (InputLayer)                  (None, None, 76)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 76)     0           X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "slice_1 (Slice)                 (None, None, 3)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_2 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_3 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_4 (Slice)                 (None, None, 9)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_5 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_6 (Slice)                 (None, None, 14)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_7 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_8 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_9 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_10 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_11 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_12 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_13 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_14 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_15 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_16 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_17 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 8)      256         slice_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 8)      224         slice_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, None, 8)      224         slice_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 8)      448         slice_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, None, 8)      576         slice_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, None, 8)      608         slice_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, None, 8)      576         slice_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, None, 8)      224         slice_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, None, 8)      224         slice_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, None, 8)      224         slice_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, None, 8)      224         slice_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, None, 8)      224         slice_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, None, 8)      224         slice_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, None, 8)      224         slice_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, None, 8)      224         slice_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, None, 8)      224         slice_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, None, 8)      224         slice_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 136)    0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "                                                                 bidirectional_7[0][0]            \n",
      "                                                                 bidirectional_8[0][0]            \n",
      "                                                                 bidirectional_9[0][0]            \n",
      "                                                                 bidirectional_10[0][0]           \n",
      "                                                                 bidirectional_11[0][0]           \n",
      "                                                                 bidirectional_12[0][0]           \n",
      "                                                                 bidirectional_13[0][0]           \n",
      "                                                                 bidirectional_14[0][0]           \n",
      "                                                                 bidirectional_15[0][0]           \n",
      "                                                                 bidirectional_16[0][0]           \n",
      "                                                                 bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lstm_18 (LSTM)                  (None, 32)           21632       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           lstm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            33          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,817\n",
      "Trainable params: 26,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:169: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-04-22 18:27:44.657091: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
      "2021-04-22 18:27:44.657481: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558f394a9d40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-22 18:27:44.657522: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-04-22 18:27:44.663350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-22 18:27:44.675466: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-04-22 18:27:44.675551: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (6b9dead74af2): /proc/driver/nvidia/version does not exist\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:173: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:182: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:189: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "==> training\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:958: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:680: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:945: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 24490 samples, validate on 5356 samples\n",
      "Epoch 26/30\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5265\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13215  1864]\n",
      " [ 4039  5372]]\n",
      "accuracy = 0.758962869644165\n",
      "precision class 0 = 0.7659093737602234\n",
      "precision class 1 = 0.7423990964889526\n",
      "recall class 0 = 0.8763843774795532\n",
      "recall class 1 = 0.5708214044570923\n",
      "AUC of ROC = 0.811565509878061\n",
      "AUC of PRC = 0.7453504513094624\n",
      "min(+P, Se) = 0.676761236850494\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2837  417]\n",
      " [ 937 1165]]\n",
      "accuracy = 0.7471994161605835\n",
      "precision class 0 = 0.7517223358154297\n",
      "precision class 1 = 0.736409604549408\n",
      "recall class 0 = 0.8718500137329102\n",
      "recall class 1 = 0.5542340874671936\n",
      "AUC of ROC = 0.796141994892329\n",
      "AUC of PRC = 0.7319853007691424\n",
      "min(+P, Se) = 0.6723728007608178\n",
      "Epoch 00026: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch26.test0.525701593315539.state\n",
      "24490/24490 [==============================] - 1585s 65ms/step - loss: 0.5265 - val_loss: 0.5257\n",
      "Epoch 27/30\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5287\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13265  1814]\n",
      " [ 4078  5333]]\n",
      "accuracy = 0.7594119906425476\n",
      "precision class 0 = 0.7648618817329407\n",
      "precision class 1 = 0.7461872100830078\n",
      "recall class 0 = 0.879700243473053\n",
      "recall class 1 = 0.5666772723197937\n",
      "AUC of ROC = 0.8111682044853855\n",
      "AUC of PRC = 0.7460777327253787\n",
      "min(+P, Se) = 0.6753798746148124\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2848  406]\n",
      " [ 938 1164]]\n",
      "accuracy = 0.7490664720535278\n",
      "precision class 0 = 0.7522451281547546\n",
      "precision class 1 = 0.7414012551307678\n",
      "recall class 0 = 0.8752304911613464\n",
      "recall class 1 = 0.5537583231925964\n",
      "AUC of ROC = 0.7963661207139042\n",
      "AUC of PRC = 0.7335459712665761\n",
      "min(+P, Se) = 0.6726926736441484\n",
      "Epoch 00027: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch27.test0.5286405219615085.state\n",
      "24490/24490 [==============================] - 1596s 65ms/step - loss: 0.5286 - val_loss: 0.5286\n",
      "Epoch 28/30\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5268\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13010  2069]\n",
      " [ 3815  5596]]\n",
      "accuracy = 0.7597386837005615\n",
      "precision class 0 = 0.7732540965080261\n",
      "precision class 1 = 0.7300717830657959\n",
      "recall class 0 = 0.8627893328666687\n",
      "recall class 1 = 0.594623327255249\n",
      "AUC of ROC = 0.8125026526781851\n",
      "AUC of PRC = 0.7471767940069068\n",
      "min(+P, Se) = 0.6759082217973231\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2796  458]\n",
      " [ 867 1235]]\n",
      "accuracy = 0.75261390209198\n",
      "precision class 0 = 0.7633087635040283\n",
      "precision class 1 = 0.7294743061065674\n",
      "recall class 0 = 0.8592501282691956\n",
      "recall class 1 = 0.5875356793403625\n",
      "AUC of ROC = 0.7967851321976847\n",
      "AUC of PRC = 0.7367447704458944\n",
      "min(+P, Se) = 0.669672520170859\n",
      "Epoch 00028: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch28.test0.5260214427676639.state\n",
      "24490/24490 [==============================] - 1529s 62ms/step - loss: 0.5268 - val_loss: 0.5260\n",
      "Epoch 29/30\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5273\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13301  1778]\n",
      " [ 4178  5233]]\n",
      "accuracy = 0.7567986845970154\n",
      "precision class 0 = 0.7609702944755554\n",
      "precision class 1 = 0.7463985085487366\n",
      "recall class 0 = 0.8820876479148865\n",
      "recall class 1 = 0.5560514330863953\n",
      "AUC of ROC = 0.8128895006259281\n",
      "AUC of PRC = 0.7465212220497793\n",
      "min(+P, Se) = 0.6765487195834662\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2872  382]\n",
      " [ 958 1144]]\n",
      "accuracy = 0.7498133182525635\n",
      "precision class 0 = 0.7498694658279419\n",
      "precision class 1 = 0.7496723532676697\n",
      "recall class 0 = 0.882606029510498\n",
      "recall class 1 = 0.544243574142456\n",
      "AUC of ROC = 0.7954487838140513\n",
      "AUC of PRC = 0.7356806782930547\n",
      "min(+P, Se) = 0.6726840855106888\n",
      "Epoch 00029: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch29.test0.5266129775800484.state\n",
      "24490/24490 [==============================] - 1492s 61ms/step - loss: 0.5273 - val_loss: 0.5266\n",
      "Epoch 30/30\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5277\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13156  1923]\n",
      " [ 3925  5486]]\n",
      "accuracy = 0.7612086534500122\n",
      "precision class 0 = 0.7702125310897827\n",
      "precision class 1 = 0.7404507994651794\n",
      "recall class 0 = 0.8724716305732727\n",
      "recall class 1 = 0.5829348564147949\n",
      "AUC of ROC = 0.8145415514277728\n",
      "AUC of PRC = 0.7500225252078079\n",
      "min(+P, Se) = 0.6789926681542875\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2832  422]\n",
      " [ 901 1201]]\n",
      "accuracy = 0.7529873251914978\n",
      "precision class 0 = 0.7586391568183899\n",
      "precision class 1 = 0.7399876713752747\n",
      "recall class 0 = 0.8703134655952454\n",
      "recall class 1 = 0.5713605880737305\n",
      "AUC of ROC = 0.7976424536704296\n",
      "AUC of PRC = 0.7319020554308157\n",
      "min(+P, Se) = 0.6741198858230257\n",
      "Epoch 00030: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch30.test0.5253430250155738.state\n",
      "24490/24490 [==============================] - 1514s 62ms/step - loss: 0.5277 - val_loss: 0.5253\n"
     ]
    }
   ],
   "source": [
    "!python -um mimic3models.los3days.main --data /content/los3days/ --network mimic3models/keras_models/channel_wise_lstms.py --dim 8 --depth 1 --batch_size 8 --dropout 0.3 --timestep 1.0 --epochs 5 --load_state mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch25.test0.527318338300863.state  --mode train --size_coef 4.0 --output_dir mimic3models/los3days --verbose 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sIuomgPU9QDz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeZLQRDWT40M"
   },
   "source": [
    "Load epoch 30 and continue training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zxVUIBJCPEUA",
    "outputId": "b02cc27e-15e3-4dfc-a9e8-935dd87b271b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/MIMIC_benchmark/mimic3models/los3days/main.py:7: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Using TensorFlow backend.\n",
      "Namespace(batch_norm=False, batch_size=8, beta_1=0.9, data='/content/los3days/', depth=1, dim=8, dropout=0.3, epochs=2, imputation='previous', l1=0, l2=0, load_state='mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch30.test0.5253430250155738.state', lr=0.001, mode='train', network='mimic3models/keras_models/channel_wise_lstms.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/los3days', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=1)\n",
      "==> using model mimic3models/keras_models/channel_wise_lstms.py\n",
      "==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])\n",
      "==> found 17 channels: ['Capillary refill rate', 'Diastolic blood pressure', 'Fraction inspired oxygen', 'Glascow coma scale eye opening', 'Glascow coma scale motor response', 'Glascow coma scale total', 'Glascow coma scale verbal response', 'Glucose', 'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation', 'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight', 'pH']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1364: calling reduce_any_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2613: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1379: calling reduce_all_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "==> model.final_name: k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0\n",
      "==> compiling the model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2950: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X (InputLayer)                  (None, None, 76)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 76)     0           X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "slice_1 (Slice)                 (None, None, 3)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_2 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_3 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_4 (Slice)                 (None, None, 9)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_5 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_6 (Slice)                 (None, None, 14)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_7 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_8 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_9 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_10 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_11 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_12 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_13 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_14 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_15 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_16 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_17 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 8)      256         slice_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 8)      224         slice_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, None, 8)      224         slice_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 8)      448         slice_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, None, 8)      576         slice_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, None, 8)      608         slice_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, None, 8)      576         slice_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, None, 8)      224         slice_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, None, 8)      224         slice_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, None, 8)      224         slice_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, None, 8)      224         slice_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, None, 8)      224         slice_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, None, 8)      224         slice_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, None, 8)      224         slice_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, None, 8)      224         slice_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, None, 8)      224         slice_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, None, 8)      224         slice_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 136)    0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "                                                                 bidirectional_7[0][0]            \n",
      "                                                                 bidirectional_8[0][0]            \n",
      "                                                                 bidirectional_9[0][0]            \n",
      "                                                                 bidirectional_10[0][0]           \n",
      "                                                                 bidirectional_11[0][0]           \n",
      "                                                                 bidirectional_12[0][0]           \n",
      "                                                                 bidirectional_13[0][0]           \n",
      "                                                                 bidirectional_14[0][0]           \n",
      "                                                                 bidirectional_15[0][0]           \n",
      "                                                                 bidirectional_16[0][0]           \n",
      "                                                                 bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lstm_18 (LSTM)                  (None, 32)           21632       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           lstm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            33          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,817\n",
      "Trainable params: 26,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:169: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-04-22 21:08:19.115488: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
      "2021-04-22 21:08:19.116059: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5594f9487d40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-22 21:08:19.116107: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-04-22 21:08:19.188481: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-22 21:08:19.272494: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-04-22 21:08:19.272561: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (1082c732db2c): /proc/driver/nvidia/version does not exist\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:173: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:182: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:189: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "==> training\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:958: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:680: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:945: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 24490 samples, validate on 5356 samples\n",
      "Epoch 31/32\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5272\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13446  1633]\n",
      " [ 4260  5151]]\n",
      "accuracy = 0.7593711614608765\n",
      "precision class 0 = 0.7594035863876343\n",
      "precision class 1 = 0.7592865824699402\n",
      "recall class 0 = 0.8917036652565002\n",
      "recall class 1 = 0.5473382472991943\n",
      "AUC of ROC = 0.8141215236421162\n",
      "AUC of PRC = 0.7490066732118086\n",
      "min(+P, Se) = 0.6776455588610285\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2894  360]\n",
      " [ 991 1111]]\n",
      "accuracy = 0.7477595210075378\n",
      "precision class 0 = 0.7449163198471069\n",
      "precision class 1 = 0.7552685141563416\n",
      "recall class 0 = 0.8893669247627258\n",
      "recall class 1 = 0.5285442471504211\n",
      "AUC of ROC = 0.7956253943766496\n",
      "AUC of PRC = 0.7285979207036649\n",
      "min(+P, Se) = 0.6731684110371076\n",
      "Epoch 00031: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch31.test0.5306312160940647.state\n",
      "24490/24490 [==============================] - 1663s 68ms/step - loss: 0.5271 - val_loss: 0.5306\n",
      "Epoch 32/32\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5244\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13344  1735]\n",
      " [ 4135  5276]]\n",
      "accuracy = 0.7603103518486023\n",
      "precision class 0 = 0.7634304165840149\n",
      "precision class 1 = 0.7525317072868347\n",
      "recall class 0 = 0.8849393129348755\n",
      "recall class 1 = 0.5606205463409424\n",
      "AUC of ROC = 0.8155102885367609\n",
      "AUC of PRC = 0.7508477098954077\n",
      "min(+P, Se) = 0.6777175645521198\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2864  390]\n",
      " [ 956 1146]]\n",
      "accuracy = 0.74869304895401\n",
      "precision class 0 = 0.7497382164001465\n",
      "precision class 1 = 0.74609375\n",
      "recall class 0 = 0.8801475167274475\n",
      "recall class 1 = 0.5451950430870056\n",
      "AUC of ROC = 0.7955820458403826\n",
      "AUC of PRC = 0.728196628265624\n",
      "min(+P, Se) = 0.6752258678078935\n",
      "Epoch 00032: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch32.test0.527357709372195.state\n",
      "24490/24490 [==============================] - 1606s 66ms/step - loss: 0.5244 - val_loss: 0.5274\n"
     ]
    }
   ],
   "source": [
    "!python -um mimic3models.los3days.main --data /content/los3days/ --network mimic3models/keras_models/channel_wise_lstms.py --dim 8 --depth 1 --batch_size 8 --dropout 0.3 --timestep 1.0 --epochs 2 --load_state mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch30.test0.5253430250155738.state  --mode train --size_coef 4.0 --output_dir mimic3models/los3days --verbose 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7hE6oxBqQ0cU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vquk5BdshiPN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eaCYtvzqb09l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJDImB5YaZIL"
   },
   "source": [
    "Load epoch 32 and continue training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6eRw5P0AWnNz",
    "outputId": "1c1709fe-edb4-46b4-a4bc-9201f752f94f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/MIMIC_benchmark/mimic3models/los3days/main.py:7: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Using TensorFlow backend.\n",
      "Namespace(batch_norm=False, batch_size=8, beta_1=0.9, data='/content/los3days/', depth=1, dim=8, dropout=0.3, epochs=3, imputation='previous', l1=0, l2=0, load_state='mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch32.test0.527357709372195.state', lr=0.001, mode='train', network='mimic3models/keras_models/channel_wise_lstms.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/los3days', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=1)\n",
      "==> using model mimic3models/keras_models/channel_wise_lstms.py\n",
      "==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])\n",
      "==> found 17 channels: ['Capillary refill rate', 'Diastolic blood pressure', 'Fraction inspired oxygen', 'Glascow coma scale eye opening', 'Glascow coma scale motor response', 'Glascow coma scale total', 'Glascow coma scale verbal response', 'Glucose', 'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation', 'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight', 'pH']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1364: calling reduce_any_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2613: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1379: calling reduce_all_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "==> model.final_name: k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0\n",
      "==> compiling the model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2950: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X (InputLayer)                  (None, None, 76)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 76)     0           X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "slice_1 (Slice)                 (None, None, 3)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_2 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_3 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_4 (Slice)                 (None, None, 9)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_5 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_6 (Slice)                 (None, None, 14)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_7 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_8 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_9 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_10 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_11 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_12 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_13 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_14 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_15 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_16 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_17 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 8)      256         slice_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 8)      224         slice_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, None, 8)      224         slice_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 8)      448         slice_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, None, 8)      576         slice_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, None, 8)      608         slice_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, None, 8)      576         slice_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, None, 8)      224         slice_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, None, 8)      224         slice_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, None, 8)      224         slice_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, None, 8)      224         slice_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, None, 8)      224         slice_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, None, 8)      224         slice_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, None, 8)      224         slice_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, None, 8)      224         slice_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, None, 8)      224         slice_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, None, 8)      224         slice_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 136)    0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "                                                                 bidirectional_7[0][0]            \n",
      "                                                                 bidirectional_8[0][0]            \n",
      "                                                                 bidirectional_9[0][0]            \n",
      "                                                                 bidirectional_10[0][0]           \n",
      "                                                                 bidirectional_11[0][0]           \n",
      "                                                                 bidirectional_12[0][0]           \n",
      "                                                                 bidirectional_13[0][0]           \n",
      "                                                                 bidirectional_14[0][0]           \n",
      "                                                                 bidirectional_15[0][0]           \n",
      "                                                                 bidirectional_16[0][0]           \n",
      "                                                                 bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lstm_18 (LSTM)                  (None, 32)           21632       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           lstm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            33          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,817\n",
      "Trainable params: 26,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:169: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-04-23 09:06:03.203179: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200140000 Hz\n",
      "2021-04-23 09:06:03.203626: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55885805bd40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-23 09:06:03.203675: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-04-23 09:06:03.237060: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-23 09:06:03.315964: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-04-23 09:06:03.316034: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (39faf785d96a): /proc/driver/nvidia/version does not exist\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:173: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:182: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:189: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "==> training\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:958: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:680: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:945: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 24490 samples, validate on 5356 samples\n",
      "Epoch 33/35\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5249\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13067  2012]\n",
      " [ 3788  5623]]\n",
      "accuracy = 0.7631686329841614\n",
      "precision class 0 = 0.7752595543861389\n",
      "precision class 1 = 0.7364767789840698\n",
      "recall class 0 = 0.8665693998336792\n",
      "recall class 1 = 0.5974922776222229\n",
      "AUC of ROC = 0.8162473868983817\n",
      "AUC of PRC = 0.7536624385171256\n",
      "min(+P, Se) = 0.6805865476569971\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2805  449]\n",
      " [ 876 1226]]\n",
      "accuracy = 0.75261390209198\n",
      "precision class 0 = 0.7620211839675903\n",
      "precision class 1 = 0.7319402694702148\n",
      "recall class 0 = 0.862015962600708\n",
      "recall class 1 = 0.5832540392875671\n",
      "AUC of ROC = 0.795440669669826\n",
      "AUC of PRC = 0.7296897600771587\n",
      "min(+P, Se) = 0.6693625118934349\n",
      "Epoch 00033: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch33.test0.5277186307201998.state\n",
      "24490/24490 [==============================] - 1816s 74ms/step - loss: 0.5249 - val_loss: 0.5277\n",
      "Epoch 34/35\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5255\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[13277  1802]\n",
      " [ 4055  5356]]\n",
      "accuracy = 0.7608411312103271\n",
      "precision class 0 = 0.7660396695137024\n",
      "precision class 1 = 0.7482537031173706\n",
      "recall class 0 = 0.8804960250854492\n",
      "recall class 1 = 0.569121241569519\n",
      "AUC of ROC = 0.8171610532983764\n",
      "AUC of PRC = 0.7552257853006729\n",
      "min(+P, Se) = 0.6794177026883435\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2865  389]\n",
      " [ 941 1161]]\n",
      "accuracy = 0.7516803741455078\n",
      "precision class 0 = 0.752758800983429\n",
      "precision class 1 = 0.7490322589874268\n",
      "recall class 0 = 0.8804548382759094\n",
      "recall class 1 = 0.5523310899734497\n",
      "AUC of ROC = 0.795932342949642\n",
      "AUC of PRC = 0.7329290887701623\n",
      "min(+P, Se) = 0.6717411988582302\n",
      "Epoch 00034: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch34.test0.5269261754387079.state\n",
      "24490/24490 [==============================] - 1784s 73ms/step - loss: 0.5255 - val_loss: 0.5269\n",
      "Epoch 35/35\n",
      "24488/24490 [============================>.] - ETA: 0s - loss: 0.5225\n",
      "==>predicting on train\n",
      "\tdone 24488/24490\n",
      "\n",
      "confusion matrix:\n",
      "[[12925  2154]\n",
      " [ 3641  5770]]\n",
      "accuracy = 0.7633727788925171\n",
      "precision class 0 = 0.7802124619483948\n",
      "precision class 1 = 0.7281675934791565\n",
      "recall class 0 = 0.8571523427963257\n",
      "recall class 1 = 0.6131123304367065\n",
      "AUC of ROC = 0.8170317445958775\n",
      "AUC of PRC = 0.7555775689430095\n",
      "min(+P, Se) = 0.6816491339921369\n",
      "\n",
      "==>predicting on validation\n",
      "\tdone 5352/5356\n",
      "\n",
      "confusion matrix:\n",
      "[[2776  478]\n",
      " [ 851 1251]]\n",
      "accuracy = 0.7518670558929443\n",
      "precision class 0 = 0.7653708457946777\n",
      "precision class 1 = 0.7235395908355713\n",
      "recall class 0 = 0.8531038761138916\n",
      "recall class 1 = 0.5951474905014038\n",
      "AUC of ROC = 0.7949560140282589\n",
      "AUC of PRC = 0.7320383177698238\n",
      "min(+P, Se) = 0.6712654614652712\n",
      "Epoch 00035: saving model to mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch35.test0.5277832992892376.state\n",
      "24490/24490 [==============================] - 1793s 73ms/step - loss: 0.5225 - val_loss: 0.5278\n"
     ]
    }
   ],
   "source": [
    "!python -um mimic3models.los3days.main --data /content/los3days/ --network mimic3models/keras_models/channel_wise_lstms.py --dim 8 --depth 1 --batch_size 8 --dropout 0.3 --timestep 1.0 --epochs 3 --load_state mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch32.test0.527357709372195.state  --mode train --size_coef 4.0 --output_dir mimic3models/los3days --verbose 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ELyuLFI1RAj0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bZpX6MMFiwI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "TV6ZUGj7anYh",
    "outputId": "a52148c7-5895-4ea1-e977-98e98c6c68f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_auprc</th>\n",
       "      <th>train_auroc</th>\n",
       "      <th>train_minpse</th>\n",
       "      <th>train_prec0</th>\n",
       "      <th>train_prec1</th>\n",
       "      <th>train_rec0</th>\n",
       "      <th>train_rec1</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_auprc</th>\n",
       "      <th>val_auroc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_minpse</th>\n",
       "      <th>val_prec0</th>\n",
       "      <th>val_prec1</th>\n",
       "      <th>val_rec0</th>\n",
       "      <th>val_rec1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.584072</td>\n",
       "      <td>0.735361</td>\n",
       "      <td>0.690130</td>\n",
       "      <td>0.769184</td>\n",
       "      <td>0.642227</td>\n",
       "      <td>0.742525</td>\n",
       "      <td>0.716588</td>\n",
       "      <td>0.872870</td>\n",
       "      <td>0.515036</td>\n",
       "      <td>0.735624</td>\n",
       "      <td>0.691964</td>\n",
       "      <td>0.768210</td>\n",
       "      <td>0.552702</td>\n",
       "      <td>0.645804</td>\n",
       "      <td>0.738083</td>\n",
       "      <td>0.729278</td>\n",
       "      <td>0.875538</td>\n",
       "      <td>0.519030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.567249</td>\n",
       "      <td>0.740588</td>\n",
       "      <td>0.699795</td>\n",
       "      <td>0.777149</td>\n",
       "      <td>0.646371</td>\n",
       "      <td>0.755385</td>\n",
       "      <td>0.706454</td>\n",
       "      <td>0.855826</td>\n",
       "      <td>0.555945</td>\n",
       "      <td>0.736931</td>\n",
       "      <td>0.701923</td>\n",
       "      <td>0.774702</td>\n",
       "      <td>0.550106</td>\n",
       "      <td>0.650333</td>\n",
       "      <td>0.747385</td>\n",
       "      <td>0.712969</td>\n",
       "      <td>0.856484</td>\n",
       "      <td>0.551855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.557812</td>\n",
       "      <td>0.741445</td>\n",
       "      <td>0.704341</td>\n",
       "      <td>0.781581</td>\n",
       "      <td>0.649772</td>\n",
       "      <td>0.751538</td>\n",
       "      <td>0.716739</td>\n",
       "      <td>0.866569</td>\n",
       "      <td>0.540963</td>\n",
       "      <td>0.741225</td>\n",
       "      <td>0.705522</td>\n",
       "      <td>0.777810</td>\n",
       "      <td>0.545851</td>\n",
       "      <td>0.653187</td>\n",
       "      <td>0.745273</td>\n",
       "      <td>0.731266</td>\n",
       "      <td>0.872157</td>\n",
       "      <td>0.538535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.552697</td>\n",
       "      <td>0.744508</td>\n",
       "      <td>0.708603</td>\n",
       "      <td>0.785574</td>\n",
       "      <td>0.656997</td>\n",
       "      <td>0.750796</td>\n",
       "      <td>0.728484</td>\n",
       "      <td>0.875721</td>\n",
       "      <td>0.534268</td>\n",
       "      <td>0.742905</td>\n",
       "      <td>0.711573</td>\n",
       "      <td>0.779037</td>\n",
       "      <td>0.542897</td>\n",
       "      <td>0.657508</td>\n",
       "      <td>0.745360</td>\n",
       "      <td>0.736773</td>\n",
       "      <td>0.876152</td>\n",
       "      <td>0.536632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.550841</td>\n",
       "      <td>0.746100</td>\n",
       "      <td>0.712652</td>\n",
       "      <td>0.788403</td>\n",
       "      <td>0.657884</td>\n",
       "      <td>0.760694</td>\n",
       "      <td>0.713009</td>\n",
       "      <td>0.857351</td>\n",
       "      <td>0.567846</td>\n",
       "      <td>0.748880</td>\n",
       "      <td>0.717524</td>\n",
       "      <td>0.784985</td>\n",
       "      <td>0.537181</td>\n",
       "      <td>0.660799</td>\n",
       "      <td>0.758322</td>\n",
       "      <td>0.727875</td>\n",
       "      <td>0.861094</td>\n",
       "      <td>0.575167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch      loss  train_acc  ...  val_prec1  val_rec0  val_rec1\n",
       "0      0  0.584072   0.735361  ...   0.729278  0.875538  0.519030\n",
       "1      1  0.567249   0.740588  ...   0.712969  0.856484  0.551855\n",
       "2      2  0.557812   0.741445  ...   0.731266  0.872157  0.538535\n",
       "3      3  0.552697   0.744508  ...   0.736773  0.876152  0.536632\n",
       "4      4  0.550841   0.746100  ...   0.727875  0.861094  0.575167\n",
       "\n",
       "[5 rows x 19 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Escoger epoch con mejor aucpr en validation set\n",
    "import pandas as pd\n",
    "aucpr_channelwise_lstm = pd.read_csv('mimic3models/los3days/keras_logs/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.csv', delimiter = \";\")\n",
    "aucpr_channelwise_lstm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RnYCqRgMNUW7",
    "outputId": "79242f80-d5b8-406a-83c3-70a1a40b9f3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucpr_channelwise_lstm['epoch'][aucpr_channelwise_lstm['val_auprc'].idxmax()]+1  #obs. epoch en dataframe empieza por 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yOcFpFWANUZH",
    "outputId": "0422848b-c7ce-4fbb-e464-551c8bc75548"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7367447704458944"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucpr_channelwise_lstm['val_auprc'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHRVJfwa1KDc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WrGEpZUz1UMl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsgE3s5M1Xie"
   },
   "source": [
    "Predicting on Test with epoch 28 (la mejor en aucpr sobre validation set, aucpr: 0.736):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NKShVBDf1Xig",
    "outputId": "fbcc148c-f641-43d9-ada2-751caccbef15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/MIMIC_benchmark/mimic3models/los3days/main.py:7: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Using TensorFlow backend.\n",
      "Namespace(batch_norm=False, batch_size=8, beta_1=0.9, data='/content/los3days/', depth=1, dim=8, dropout=0.3, epochs=5, imputation='previous', l1=0, l2=0, load_state='mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch28.test0.5260214427676639.state', lr=0.001, mode='test', network='mimic3models/keras_models/channel_wise_lstms.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/los3days', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)\n",
      "==> using model mimic3models/keras_models/channel_wise_lstms.py\n",
      "==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])\n",
      "==> found 17 channels: ['Capillary refill rate', 'Diastolic blood pressure', 'Fraction inspired oxygen', 'Glascow coma scale eye opening', 'Glascow coma scale motor response', 'Glascow coma scale total', 'Glascow coma scale verbal response', 'Glucose', 'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation', 'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight', 'pH']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1364: calling reduce_any_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2613: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1379: calling reduce_all_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "==> model.final_name: k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0\n",
      "==> compiling the model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2950: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X (InputLayer)                  (None, None, 76)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 76)     0           X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "slice_1 (Slice)                 (None, None, 3)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_2 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_3 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_4 (Slice)                 (None, None, 9)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_5 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_6 (Slice)                 (None, None, 14)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_7 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_8 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_9 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_10 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_11 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_12 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_13 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_14 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_15 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_16 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_17 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 8)      256         slice_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 8)      224         slice_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, None, 8)      224         slice_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 8)      448         slice_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, None, 8)      576         slice_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, None, 8)      608         slice_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, None, 8)      576         slice_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, None, 8)      224         slice_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, None, 8)      224         slice_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, None, 8)      224         slice_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, None, 8)      224         slice_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, None, 8)      224         slice_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, None, 8)      224         slice_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, None, 8)      224         slice_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, None, 8)      224         slice_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, None, 8)      224         slice_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, None, 8)      224         slice_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 136)    0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "                                                                 bidirectional_7[0][0]            \n",
      "                                                                 bidirectional_8[0][0]            \n",
      "                                                                 bidirectional_9[0][0]            \n",
      "                                                                 bidirectional_10[0][0]           \n",
      "                                                                 bidirectional_11[0][0]           \n",
      "                                                                 bidirectional_12[0][0]           \n",
      "                                                                 bidirectional_13[0][0]           \n",
      "                                                                 bidirectional_14[0][0]           \n",
      "                                                                 bidirectional_15[0][0]           \n",
      "                                                                 bidirectional_16[0][0]           \n",
      "                                                                 bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lstm_18 (LSTM)                  (None, 32)           21632       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           lstm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            33          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,817\n",
      "Trainable params: 26,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:169: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-04-23 10:40:21.814401: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200140000 Hz\n",
      "2021-04-23 10:40:21.814883: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56161c7ddd40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-04-23 10:40:21.814930: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-04-23 10:40:21.823460: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-23 10:40:21.837618: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-04-23 10:40:21.837722: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (39faf785d96a): /proc/driver/nvidia/version does not exist\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:173: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:182: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:189: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "5282/5282 [==============================] - 43s 8ms/step\n",
      "confusion matrix:\n",
      "[[2735  505]\n",
      " [ 843 1199]]\n",
      "accuracy = 0.7447936534881592\n",
      "precision class 0 = 0.7643935084342957\n",
      "precision class 1 = 0.70363849401474\n",
      "recall class 0 = 0.8441358208656311\n",
      "recall class 1 = 0.5871694684028625\n",
      "AUC of ROC = 0.7903545604043481\n",
      "AUC of PRC = 0.7193088273009822\n",
      "min(+P, Se) = 0.6557296767874633\n"
     ]
    }
   ],
   "source": [
    "!python -um mimic3models.los3days.main --data /content/los3days/ --network mimic3models/keras_models/channel_wise_lstms.py --dim 8 --depth 1 --batch_size 8 --dropout 0.3 --timestep 1.0 --epochs 5 --load_state mimic3models/los3days/keras_states/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch28.test0.5260214427676639.state --mode test --size_coef 4.0 --output_dir mimic3models/los3days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5GH5OjPt1UOe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRJRq5bg1m5a"
   },
   "source": [
    "Evaluation with epoch 28:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lrJhvcms1stY",
    "outputId": "e7c61932-6835-4a2f-f6d4-ad8c4cd2479c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the results in los3days_results_channelWise_lstm_epoch28.json ...\n",
      "{'n_iters': 10000, 'AUC of ROC': {'value': 0.7903547115512509, 'mean': 0.790298180684303, 'median': 0.7902933565476594, 'std': 0.006519500274398229, '2.5% percentile': 0.7776368054072657, '97.5% percentile': 0.803104889051896}, 'AUC of PRC': {'value': 0.7193089654741814, 'mean': 0.7193263311805393, 'median': 0.7194798695816172, 'std': 0.010782362155847441, '2.5% percentile': 0.6978825156489088, '97.5% percentile': 0.7399949245685141}, 'min(+P, Se)': {'value': 0.6557296767874633, 'mean': 0.655416454879351, 'median': 0.6555744673620296, 'std': 0.008785065384158082, '2.5% percentile': 0.6377473363774734, '97.5% percentile': 0.6722734356994602}}\n"
     ]
    }
   ],
   "source": [
    "!python -m mimic3benchmark.evaluation.evaluate_los_customized /content/gdrive/MyDrive/MIMIC_benchmark/mimic3models/los3days/test_predictions/k_channel_wise_lstms.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch28.test0.5260214427676639.state.csv --test_listfile /content/los3days/test/listfile.csv --save_file los3days_results_channelWise_lstm_epoch28.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwRISuldUsLK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTFoM61vYJ23"
   },
   "source": [
    "## Channel wise GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EzYgGbDNYI0a",
    "outputId": "4ef72bd1-3387-4b82-fcb3-45a362713035"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/MIMIC_benchmark/mimic3models/los3days/main.py:7: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Using TensorFlow backend.\n",
      "Namespace(batch_norm=False, batch_size=8, beta_1=0.9, data='/content/los3days/', depth=1, dim=8, dropout=0.3, epochs=7, imputation='previous', l1=0, l2=0, load_state='', lr=0.001, mode='train', network='mimic3models/keras_models/channel_wise_grus.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/los3days', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)\n",
      "==> using model mimic3models/keras_models/channel_wise_grus.py\n",
      "==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])\n",
      "==> found 17 channels: ['Capillary refill rate', 'Diastolic blood pressure', 'Fraction inspired oxygen', 'Glascow coma scale eye opening', 'Glascow coma scale motor response', 'Glascow coma scale total', 'Glascow coma scale verbal response', 'Glucose', 'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation', 'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight', 'pH']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1364: calling reduce_any_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2613: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1379: calling reduce_all_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "==> model.final_name: k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0\n",
      "==> compiling the model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2950: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X (InputLayer)                  (None, None, 76)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 76)     0           X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "slice_1 (Slice)                 (None, None, 3)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_2 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_3 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_4 (Slice)                 (None, None, 9)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_5 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_6 (Slice)                 (None, None, 14)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_7 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_8 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_9 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_10 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_11 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_12 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_13 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_14 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_15 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_16 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_17 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 8)      192         slice_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 8)      168         slice_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, None, 8)      168         slice_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 8)      336         slice_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, None, 8)      432         slice_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, None, 8)      456         slice_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, None, 8)      432         slice_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, None, 8)      168         slice_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, None, 8)      168         slice_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, None, 8)      168         slice_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, None, 8)      168         slice_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, None, 8)      168         slice_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, None, 8)      168         slice_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, None, 8)      168         slice_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, None, 8)      168         slice_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, None, 8)      168         slice_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, None, 8)      168         slice_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 136)    0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "                                                                 bidirectional_7[0][0]            \n",
      "                                                                 bidirectional_8[0][0]            \n",
      "                                                                 bidirectional_9[0][0]            \n",
      "                                                                 bidirectional_10[0][0]           \n",
      "                                                                 bidirectional_11[0][0]           \n",
      "                                                                 bidirectional_12[0][0]           \n",
      "                                                                 bidirectional_13[0][0]           \n",
      "                                                                 bidirectional_14[0][0]           \n",
      "                                                                 bidirectional_15[0][0]           \n",
      "                                                                 bidirectional_16[0][0]           \n",
      "                                                                 bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gru_18 (GRU)                    (None, 32)           16224       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           gru_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            33          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 20,121\n",
      "Trainable params: 20,121\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "==> training\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:958: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:680: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:945: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2378: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 24490 samples, validate on 5356 samples\n",
      "Epoch 1/7\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "2021-05-15 09:41:14.333137: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
      "2021-05-15 09:41:14.333556: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5605e792d480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-05-15 09:41:14.333599: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-05-15 09:41:14.371247: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-05-15 09:41:14.480119: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-05-15 09:41:14.480180: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a47ca3cac364): /proc/driver/nvidia/version does not exist\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:173: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:182: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:189: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13003  2076]\n",
      " [ 4364  5047]]\n",
      "accuracy = 0.7370355129241943\n",
      "precision class 0 = 0.7487188577651978\n",
      "precision class 1 = 0.7085497975349426\n",
      "recall class 0 = 0.8623250722885132\n",
      "recall class 1 = 0.5362873077392578\n",
      "AUC of ROC = 0.7676920501481839\n",
      "AUC of PRC = 0.6819341515047896\n",
      "min(+P, Se) = 0.6399277518062049\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2820  434]\n",
      " [ 977 1125]]\n",
      "accuracy = 0.736557126045227\n",
      "precision class 0 = 0.7426915764808655\n",
      "precision class 1 = 0.7216164469718933\n",
      "recall class 0 = 0.8666256666183472\n",
      "recall class 1 = 0.5352045893669128\n",
      "AUC of ROC = 0.7667170377145422\n",
      "AUC of PRC = 0.6867578704136622\n",
      "min(+P, Se) = 0.6428911079410367\n",
      "Epoch 00001: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch1.test0.5606320952193963.state\n",
      " - 1225s - loss: 0.5919 - val_loss: 0.5606\n",
      "Epoch 2/7\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13242  1837]\n",
      " [ 4598  4813]]\n",
      "accuracy = 0.7372397184371948\n",
      "precision class 0 = 0.7422645688056946\n",
      "precision class 1 = 0.7237594127655029\n",
      "recall class 0 = 0.8781749606132507\n",
      "recall class 1 = 0.5114228129386902\n",
      "AUC of ROC = 0.7800780515784439\n",
      "AUC of PRC = 0.6996332796822544\n",
      "min(+P, Se) = 0.648832271762208\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2868  386]\n",
      " [1012 1090]]\n",
      "accuracy = 0.7389843463897705\n",
      "precision class 0 = 0.7391752600669861\n",
      "precision class 1 = 0.7384823560714722\n",
      "recall class 0 = 0.8813767433166504\n",
      "recall class 1 = 0.5185537338256836\n",
      "AUC of ROC = 0.7779154339502812\n",
      "AUC of PRC = 0.7030584602915362\n",
      "min(+P, Se) = 0.6508987701040682\n",
      "Epoch 00002: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch2.test0.5481576788238486.state\n"
     ]
    }
   ],
   "source": [
    "!python -um mimic3models.los3days.main --data /content/los3days/ --network mimic3models/keras_models/channel_wise_grus.py --dim 8 --depth 1 --batch_size 8 --dropout 0.3 --timestep 1.0 --epochs 7 --mode train --size_coef 4.0 --output_dir mimic3models/los3days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lna8jHUCYJRt"
   },
   "outputs": [],
   "source": [
    "#Total 2h19min para 7 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDa45GCRjTJo"
   },
   "source": [
    "Load epoch 7 and continue training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3QyTlxSwb2Xk",
    "outputId": "ed5e3cca-6b35-449b-af84-7f80e7affba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/MIMIC_benchmark/mimic3models/los3days/main.py:7: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Using TensorFlow backend.\n",
      "Namespace(batch_norm=False, batch_size=8, beta_1=0.9, data='/content/los3days/', depth=1, dim=8, dropout=0.3, epochs=8, imputation='previous', l1=0, l2=0, load_state='mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch7.test0.5370793866746189.state', lr=0.001, mode='train', network='mimic3models/keras_models/channel_wise_grus.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/los3days', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)\n",
      "==> using model mimic3models/keras_models/channel_wise_grus.py\n",
      "==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])\n",
      "==> found 17 channels: ['Capillary refill rate', 'Diastolic blood pressure', 'Fraction inspired oxygen', 'Glascow coma scale eye opening', 'Glascow coma scale motor response', 'Glascow coma scale total', 'Glascow coma scale verbal response', 'Glucose', 'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation', 'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight', 'pH']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1364: calling reduce_any_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2613: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1379: calling reduce_all_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "==> model.final_name: k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0\n",
      "==> compiling the model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2950: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X (InputLayer)                  (None, None, 76)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 76)     0           X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "slice_1 (Slice)                 (None, None, 3)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_2 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_3 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_4 (Slice)                 (None, None, 9)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_5 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_6 (Slice)                 (None, None, 14)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_7 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_8 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_9 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_10 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_11 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_12 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_13 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_14 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_15 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_16 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_17 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 8)      192         slice_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 8)      168         slice_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, None, 8)      168         slice_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 8)      336         slice_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, None, 8)      432         slice_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, None, 8)      456         slice_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, None, 8)      432         slice_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, None, 8)      168         slice_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, None, 8)      168         slice_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, None, 8)      168         slice_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, None, 8)      168         slice_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, None, 8)      168         slice_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, None, 8)      168         slice_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, None, 8)      168         slice_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, None, 8)      168         slice_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, None, 8)      168         slice_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, None, 8)      168         slice_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 136)    0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "                                                                 bidirectional_7[0][0]            \n",
      "                                                                 bidirectional_8[0][0]            \n",
      "                                                                 bidirectional_9[0][0]            \n",
      "                                                                 bidirectional_10[0][0]           \n",
      "                                                                 bidirectional_11[0][0]           \n",
      "                                                                 bidirectional_12[0][0]           \n",
      "                                                                 bidirectional_13[0][0]           \n",
      "                                                                 bidirectional_14[0][0]           \n",
      "                                                                 bidirectional_15[0][0]           \n",
      "                                                                 bidirectional_16[0][0]           \n",
      "                                                                 bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gru_18 (GRU)                    (None, 32)           16224       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           gru_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            33          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 20,121\n",
      "Trainable params: 20,121\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:169: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-05-15 12:02:39.438583: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
      "2021-05-15 12:02:39.438866: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5579c6351480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-05-15 12:02:39.438911: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-05-15 12:02:39.442063: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-05-15 12:02:39.453971: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-05-15 12:02:39.454026: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a47ca3cac364): /proc/driver/nvidia/version does not exist\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:173: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:182: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:189: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "==> training\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:958: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:680: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:945: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 24490 samples, validate on 5356 samples\n",
      "Epoch 8/15\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13200  1879]\n",
      " [ 4313  5098]]\n",
      "accuracy = 0.7471621036529541\n",
      "precision class 0 = 0.7537258267402649\n",
      "precision class 1 = 0.7306865453720093\n",
      "recall class 0 = 0.8753896355628967\n",
      "recall class 1 = 0.5417065024375916\n",
      "AUC of ROC = 0.7956364429525343\n",
      "AUC of PRC = 0.7209996915059814\n",
      "min(+P, Se) = 0.6607161831898842\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2845  409]\n",
      " [ 960 1142]]\n",
      "accuracy = 0.744398832321167\n",
      "precision class 0 = 0.7477003931999207\n",
      "precision class 1 = 0.7362991571426392\n",
      "recall class 0 = 0.8743085265159607\n",
      "recall class 1 = 0.5432921051979065\n",
      "AUC of ROC = 0.7882769768248344\n",
      "AUC of PRC = 0.7178239295025426\n",
      "min(+P, Se) = 0.6636579572446556\n",
      "Epoch 00008: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch8.test0.5389966795344776.state\n",
      " - 1265s - loss: 0.5451 - val_loss: 0.5390\n",
      "Epoch 9/15\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13071  2008]\n",
      " [ 4171  5240]]\n",
      "accuracy = 0.7476929426193237\n",
      "precision class 0 = 0.7580907344818115\n",
      "precision class 1 = 0.7229580283164978\n",
      "recall class 0 = 0.8668347001075745\n",
      "recall class 1 = 0.5567952394485474\n",
      "AUC of ROC = 0.7982392439171477\n",
      "AUC of PRC = 0.72373683724506\n",
      "min(+P, Se) = 0.6650727871639571\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2823  431]\n",
      " [ 935 1167]]\n",
      "accuracy = 0.7449589371681213\n",
      "precision class 0 = 0.7511974573135376\n",
      "precision class 1 = 0.7302878499031067\n",
      "recall class 0 = 0.8675476312637329\n",
      "recall class 1 = 0.5551855564117432\n",
      "AUC of ROC = 0.7900666207791098\n",
      "AUC of PRC = 0.7178457465437654\n",
      "min(+P, Se) = 0.6665083135391924\n",
      "Epoch 00009: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch9.test0.5336210610619048.state\n",
      " - 1219s - loss: 0.5457 - val_loss: 0.5336\n",
      "Epoch 10/15\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13322  1757]\n",
      " [ 4367  5044]]\n",
      "accuracy = 0.7499387264251709\n",
      "precision class 0 = 0.75312340259552\n",
      "precision class 1 = 0.7416556477546692\n",
      "recall class 0 = 0.8834803104400635\n",
      "recall class 1 = 0.535968542098999\n",
      "AUC of ROC = 0.8009538986711215\n",
      "AUC of PRC = 0.7276867954519248\n",
      "min(+P, Se) = 0.6659228562320688\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2869  385]\n",
      " [ 978 1124]]\n",
      "accuracy = 0.7455190420150757\n",
      "precision class 0 = 0.7457759380340576\n",
      "precision class 1 = 0.7448641657829285\n",
      "recall class 0 = 0.8816840648651123\n",
      "recall class 1 = 0.5347288250923157\n",
      "AUC of ROC = 0.7918152554098681\n",
      "AUC of PRC = 0.7237947615707582\n",
      "min(+P, Se) = 0.6676176890156919\n",
      "Epoch 00010: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch10.test0.5325355120921331.state\n",
      " - 1217s - loss: 0.5433 - val_loss: 0.5325\n",
      "Epoch 11/15\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13400  1679]\n",
      " [ 4443  4968]]\n",
      "accuracy = 0.750020444393158\n",
      "precision class 0 = 0.7509948015213013\n",
      "precision class 1 = 0.7474048733711243\n",
      "recall class 0 = 0.8886530995368958\n",
      "recall class 1 = 0.5278928875923157\n",
      "AUC of ROC = 0.802492038019239\n",
      "AUC of PRC = 0.7292170722067389\n",
      "min(+P, Se) = 0.6671270718232044\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2902  352]\n",
      " [1000 1102]]\n",
      "accuracy = 0.7475728392601013\n",
      "precision class 0 = 0.7437211871147156\n",
      "precision class 1 = 0.7579092383384705\n",
      "recall class 0 = 0.8918254375457764\n",
      "recall class 1 = 0.5242626070976257\n",
      "AUC of ROC = 0.7912978507898059\n",
      "AUC of PRC = 0.7229963940593218\n",
      "min(+P, Se) = 0.6707897240723121\n",
      "Epoch 00011: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch11.test0.5332171932986817.state\n",
      " - 1223s - loss: 0.5426 - val_loss: 0.5332\n",
      "Epoch 12/15\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13056  2023]\n",
      " [ 4102  5309]]\n",
      "accuracy = 0.7498978972434998\n",
      "precision class 0 = 0.7609278559684753\n",
      "precision class 1 = 0.7240862250328064\n",
      "recall class 0 = 0.8658398985862732\n",
      "recall class 1 = 0.5641270875930786\n",
      "AUC of ROC = 0.8024937715310001\n",
      "AUC of PRC = 0.7269814555469538\n",
      "min(+P, Se) = 0.6669854425672086\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2833  421]\n",
      " [ 927 1175]]\n",
      "accuracy = 0.7483196258544922\n",
      "precision class 0 = 0.7534574270248413\n",
      "precision class 1 = 0.7362155318260193\n",
      "recall class 0 = 0.8706207871437073\n",
      "recall class 1 = 0.5589914321899414\n",
      "AUC of ROC = 0.7899748066786864\n",
      "AUC of PRC = 0.719880752945905\n",
      "min(+P, Se) = 0.6671415004748338\n",
      "Epoch 00012: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch12.test0.5345317074128992.state\n",
      " - 1212s - loss: 0.5416 - val_loss: 0.5345\n",
      "Epoch 13/15\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13024  2055]\n",
      " [ 4030  5381]]\n",
      "accuracy = 0.7515312433242798\n",
      "precision class 0 = 0.763691782951355\n",
      "precision class 1 = 0.7236417531967163\n",
      "recall class 0 = 0.8637177348136902\n",
      "recall class 1 = 0.5717777013778687\n",
      "AUC of ROC = 0.8049958455967838\n",
      "AUC of PRC = 0.7327204903452023\n",
      "min(+P, Se) = 0.6706682247954956\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2824  430]\n",
      " [ 905 1197]]\n",
      "accuracy = 0.7507468461990356\n",
      "precision class 0 = 0.7573075890541077\n",
      "precision class 1 = 0.7357099056243896\n",
      "recall class 0 = 0.8678549528121948\n",
      "recall class 1 = 0.5694576501846313\n",
      "AUC of ROC = 0.7934577482621111\n",
      "AUC of PRC = 0.7231252126071591\n",
      "min(+P, Se) = 0.670313986679353\n",
      "Epoch 00013: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch13.test0.5330268256338432.state\n",
      " - 1214s - loss: 0.5390 - val_loss: 0.5330\n",
      "Epoch 14/15\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13155  1924]\n",
      " [ 4147  5264]]\n",
      "accuracy = 0.7521029114723206\n",
      "precision class 0 = 0.7603167295455933\n",
      "precision class 1 = 0.7323316931724548\n",
      "recall class 0 = 0.8724053502082825\n",
      "recall class 1 = 0.5593454241752625\n",
      "AUC of ROC = 0.8064022697616448\n",
      "AUC of PRC = 0.7337093450589872\n",
      "min(+P, Se) = 0.6704195432819968\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2848  406]\n",
      " [ 936 1166]]\n",
      "accuracy = 0.7494398951530457\n",
      "precision class 0 = 0.7526426911354065\n",
      "precision class 1 = 0.741730272769928\n",
      "recall class 0 = 0.8752304911613464\n",
      "recall class 1 = 0.554709792137146\n",
      "AUC of ROC = 0.7921252741995944\n",
      "AUC of PRC = 0.7240970074731757\n",
      "min(+P, Se) = 0.6679352997145576\n",
      "Epoch 00014: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch14.test0.5306660723249979.state\n",
      " - 1226s - loss: 0.5384 - val_loss: 0.5307\n",
      "Epoch 15/15\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13238  1841]\n",
      " [ 4169  5242]]\n",
      "accuracy = 0.7545937299728394\n",
      "precision class 0 = 0.7604986429214478\n",
      "precision class 1 = 0.7400819063186646\n",
      "recall class 0 = 0.8779096603393555\n",
      "recall class 1 = 0.5570077300071716\n",
      "AUC of ROC = 0.8054377677769183\n",
      "AUC of PRC = 0.7345800869446786\n",
      "min(+P, Se) = 0.6685077004779607\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2846  408]\n",
      " [ 941 1161]]\n",
      "accuracy = 0.7481329441070557\n",
      "precision class 0 = 0.7515183687210083\n",
      "precision class 1 = 0.7399617433547974\n",
      "recall class 0 = 0.8746158480644226\n",
      "recall class 1 = 0.5523310899734497\n",
      "AUC of ROC = 0.7928205320890281\n",
      "AUC of PRC = 0.7235277020156645\n",
      "min(+P, Se) = 0.6665080875356802\n",
      "Epoch 00015: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch15.test0.5309026377071099.state\n",
      " - 1218s - loss: 0.5377 - val_loss: 0.5309\n"
     ]
    }
   ],
   "source": [
    "!python -um mimic3models.los3days.main --data /content/los3days/ --network mimic3models/keras_models/channel_wise_grus.py --dim 8 --depth 1 --batch_size 8 --dropout 0.3 --timestep 1.0 --epochs 8 --load_state mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch7.test0.5370793866746189.state  --mode train --size_coef 4.0 --output_dir mimic3models/los3days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NaO46lAoN5oP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HBouawQg6DZB",
    "outputId": "20bbfd39-f24d-4efd-d51d-524a17cd5a2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/MIMIC_benchmark/mimic3models/los3days/main.py:7: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Using TensorFlow backend.\n",
      "Namespace(batch_norm=False, batch_size=8, beta_1=0.9, data='/content/los3days/', depth=1, dim=8, dropout=0.3, epochs=5, imputation='previous', l1=0, l2=0, load_state='mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch15.test0.5309026377071099.state', lr=0.001, mode='train', network='mimic3models/keras_models/channel_wise_grus.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/los3days', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)\n",
      "==> using model mimic3models/keras_models/channel_wise_grus.py\n",
      "==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])\n",
      "==> found 17 channels: ['Capillary refill rate', 'Diastolic blood pressure', 'Fraction inspired oxygen', 'Glascow coma scale eye opening', 'Glascow coma scale motor response', 'Glascow coma scale total', 'Glascow coma scale verbal response', 'Glucose', 'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation', 'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight', 'pH']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1364: calling reduce_any_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2613: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1379: calling reduce_all_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "==> model.final_name: k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0\n",
      "==> compiling the model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2950: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X (InputLayer)                  (None, None, 76)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 76)     0           X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "slice_1 (Slice)                 (None, None, 3)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_2 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_3 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_4 (Slice)                 (None, None, 9)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_5 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_6 (Slice)                 (None, None, 14)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_7 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_8 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_9 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_10 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_11 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_12 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_13 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_14 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_15 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_16 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_17 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 8)      192         slice_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 8)      168         slice_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, None, 8)      168         slice_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 8)      336         slice_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, None, 8)      432         slice_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, None, 8)      456         slice_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, None, 8)      432         slice_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, None, 8)      168         slice_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, None, 8)      168         slice_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, None, 8)      168         slice_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, None, 8)      168         slice_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, None, 8)      168         slice_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, None, 8)      168         slice_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, None, 8)      168         slice_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, None, 8)      168         slice_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, None, 8)      168         slice_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, None, 8)      168         slice_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 136)    0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "                                                                 bidirectional_7[0][0]            \n",
      "                                                                 bidirectional_8[0][0]            \n",
      "                                                                 bidirectional_9[0][0]            \n",
      "                                                                 bidirectional_10[0][0]           \n",
      "                                                                 bidirectional_11[0][0]           \n",
      "                                                                 bidirectional_12[0][0]           \n",
      "                                                                 bidirectional_13[0][0]           \n",
      "                                                                 bidirectional_14[0][0]           \n",
      "                                                                 bidirectional_15[0][0]           \n",
      "                                                                 bidirectional_16[0][0]           \n",
      "                                                                 bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gru_18 (GRU)                    (None, 32)           16224       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           gru_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            33          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 20,121\n",
      "Trainable params: 20,121\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:169: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-05-15 15:27:15.906822: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
      "2021-05-15 15:27:15.907077: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d518657480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-05-15 15:27:15.907113: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-05-15 15:27:15.909795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-05-15 15:27:15.921574: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-05-15 15:27:15.921633: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a47ca3cac364): /proc/driver/nvidia/version does not exist\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:173: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:182: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:189: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "==> training\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:958: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:680: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:945: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 24490 samples, validate on 5356 samples\n",
      "Epoch 16/20\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13022  2057]\n",
      " [ 3913  5498]]\n",
      "accuracy = 0.7562270164489746\n",
      "precision class 0 = 0.7689400911331177\n",
      "precision class 1 = 0.7277299761772156\n",
      "recall class 0 = 0.8635851144790649\n",
      "recall class 1 = 0.5842099785804749\n",
      "AUC of ROC = 0.8083275248357447\n",
      "AUC of PRC = 0.7385261407288572\n",
      "min(+P, Se) = 0.6749548400807566\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2806  448]\n",
      " [ 900 1202]]\n",
      "accuracy = 0.7483196258544922\n",
      "precision class 0 = 0.7571505904197693\n",
      "precision class 1 = 0.7284848690032959\n",
      "recall class 0 = 0.8623232841491699\n",
      "recall class 1 = 0.5718363523483276\n",
      "AUC of ROC = 0.7916205159484601\n",
      "AUC of PRC = 0.7232945023943208\n",
      "min(+P, Se) = 0.6688867745004757\n",
      "Epoch 00016: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch16.test0.5315086785717809.state\n",
      " - 1230s - loss: 0.5373 - val_loss: 0.5315\n",
      "Epoch 17/20\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13172  1907]\n",
      " [ 4122  5289]]\n",
      "accuracy = 0.7538178563117981\n",
      "precision class 0 = 0.7616514563560486\n",
      "precision class 1 = 0.7349916696548462\n",
      "recall class 0 = 0.8735327124595642\n",
      "recall class 1 = 0.5620018839836121\n",
      "AUC of ROC = 0.8072336683443467\n",
      "AUC of PRC = 0.7354793824410748\n",
      "min(+P, Se) = 0.6702082447938802\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2847  407]\n",
      " [ 941 1161]]\n",
      "accuracy = 0.7483196258544922\n",
      "precision class 0 = 0.7515839338302612\n",
      "precision class 1 = 0.7404336929321289\n",
      "recall class 0 = 0.8749231696128845\n",
      "recall class 1 = 0.5523310899734497\n",
      "AUC of ROC = 0.7938809995689999\n",
      "AUC of PRC = 0.7250237161965202\n",
      "min(+P, Se) = 0.6698382492863939\n",
      "Epoch 00017: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch17.test0.5309052320003865.state\n",
      " - 1193s - loss: 0.5339 - val_loss: 0.5309\n",
      "Epoch 18/20\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13433  1646]\n",
      " [ 4358  5053]]\n",
      "accuracy = 0.7548387050628662\n",
      "precision class 0 = 0.75504469871521\n",
      "precision class 1 = 0.7542917132377625\n",
      "recall class 0 = 0.890841543674469\n",
      "recall class 1 = 0.5369248986244202\n",
      "AUC of ROC = 0.8096915625240098\n",
      "AUC of PRC = 0.7381194461021012\n",
      "min(+P, Se) = 0.67718627138455\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2892  362]\n",
      " [ 998 1104]]\n",
      "accuracy = 0.74607914686203\n",
      "precision class 0 = 0.7434447407722473\n",
      "precision class 1 = 0.7530695796012878\n",
      "recall class 0 = 0.888752281665802\n",
      "recall class 1 = 0.5252140760421753\n",
      "AUC of ROC = 0.7930618365042337\n",
      "AUC of PRC = 0.7265900782919206\n",
      "min(+P, Se) = 0.6726926736441484\n",
      "Epoch 00018: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch18.test0.530906707627102.state\n",
      " - 1190s - loss: 0.5326 - val_loss: 0.5309\n",
      "Epoch 19/20\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13103  1976]\n",
      " [ 3916  5495]]\n",
      "accuracy = 0.7594119906425476\n",
      "precision class 0 = 0.7699041962623596\n",
      "precision class 1 = 0.7355106472969055\n",
      "recall class 0 = 0.8689568042755127\n",
      "recall class 1 = 0.5838912129402161\n",
      "AUC of ROC = 0.8124833127471764\n",
      "AUC of PRC = 0.743236186688047\n",
      "min(+P, Se) = 0.6812579685507862\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2822  432]\n",
      " [ 905 1197]]\n",
      "accuracy = 0.7503734230995178\n",
      "precision class 0 = 0.7571773529052734\n",
      "precision class 1 = 0.7348066568374634\n",
      "recall class 0 = 0.867240309715271\n",
      "recall class 1 = 0.5694576501846313\n",
      "AUC of ROC = 0.7934822368955841\n",
      "AUC of PRC = 0.7251158085778309\n",
      "min(+P, Se) = 0.6690442225392297\n",
      "Epoch 00019: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch19.test0.5287814102037528.state\n",
      " - 1181s - loss: 0.5321 - val_loss: 0.5288\n",
      "Epoch 20/20\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13258  1821]\n",
      " [ 4166  5245]]\n",
      "accuracy = 0.7555328607559204\n",
      "precision class 0 = 0.7609044909477234\n",
      "precision class 1 = 0.7422869801521301\n",
      "recall class 0 = 0.8792360424995422\n",
      "recall class 1 = 0.5573265552520752\n",
      "AUC of ROC = 0.8109029983263367\n",
      "AUC of PRC = 0.7394718751229201\n",
      "min(+P, Se) = 0.6762299436829242\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2859  395]\n",
      " [ 954 1148]]\n",
      "accuracy = 0.7481329441070557\n",
      "precision class 0 = 0.7498033046722412\n",
      "precision class 1 = 0.7440052032470703\n",
      "recall class 0 = 0.8786109685897827\n",
      "recall class 1 = 0.5461465120315552\n",
      "AUC of ROC = 0.7947627365748196\n",
      "AUC of PRC = 0.7272804044949749\n",
      "min(+P, Se) = 0.670313986679353\n",
      "Epoch 00020: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch20.test0.529586777858898.state\n",
      " - 1187s - loss: 0.5333 - val_loss: 0.5296\n"
     ]
    }
   ],
   "source": [
    "!python -um mimic3models.los3days.main --data /content/los3days/ --network mimic3models/keras_models/channel_wise_grus.py --dim 8 --depth 1 --batch_size 8 --dropout 0.3 --timestep 1.0 --epochs 5 --load_state mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch15.test0.5309026377071099.state  --mode train --size_coef 4.0 --output_dir mimic3models/los3days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3G1_omE26Dbl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iwh-6Pd7FGJZ",
    "outputId": "134e9984-8404-4bef-b0dc-c938209085e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/MyDrive/MIMIC_benchmark/mimic3models/los3days/main.py:7: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Using TensorFlow backend.\n",
      "Namespace(batch_norm=False, batch_size=8, beta_1=0.9, data='/content/los3days/', depth=1, dim=8, dropout=0.3, epochs=5, imputation='previous', l1=0, l2=0, load_state='mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch20.test0.529586777858898.state', lr=0.001, mode='train', network='mimic3models/keras_models/channel_wise_grus.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/los3days', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)\n",
      "==> using model mimic3models/keras_models/channel_wise_grus.py\n",
      "==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])\n",
      "==> found 17 channels: ['Capillary refill rate', 'Diastolic blood pressure', 'Fraction inspired oxygen', 'Glascow coma scale eye opening', 'Glascow coma scale motor response', 'Glascow coma scale total', 'Glascow coma scale verbal response', 'Glucose', 'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation', 'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight', 'pH']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1364: calling reduce_any_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2613: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1379: calling reduce_all_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "==> model.final_name: k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0\n",
      "==> compiling the model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2950: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X (InputLayer)                  (None, None, 76)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 76)     0           X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "slice_1 (Slice)                 (None, None, 3)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_2 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_3 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_4 (Slice)                 (None, None, 9)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_5 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_6 (Slice)                 (None, None, 14)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_7 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_8 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_9 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_10 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_11 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_12 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_13 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_14 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_15 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_16 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_17 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 8)      192         slice_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 8)      168         slice_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, None, 8)      168         slice_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 8)      336         slice_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, None, 8)      432         slice_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, None, 8)      456         slice_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, None, 8)      432         slice_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, None, 8)      168         slice_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, None, 8)      168         slice_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, None, 8)      168         slice_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, None, 8)      168         slice_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, None, 8)      168         slice_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, None, 8)      168         slice_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, None, 8)      168         slice_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, None, 8)      168         slice_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, None, 8)      168         slice_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, None, 8)      168         slice_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 136)    0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "                                                                 bidirectional_7[0][0]            \n",
      "                                                                 bidirectional_8[0][0]            \n",
      "                                                                 bidirectional_9[0][0]            \n",
      "                                                                 bidirectional_10[0][0]           \n",
      "                                                                 bidirectional_11[0][0]           \n",
      "                                                                 bidirectional_12[0][0]           \n",
      "                                                                 bidirectional_13[0][0]           \n",
      "                                                                 bidirectional_14[0][0]           \n",
      "                                                                 bidirectional_15[0][0]           \n",
      "                                                                 bidirectional_16[0][0]           \n",
      "                                                                 bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gru_18 (GRU)                    (None, 32)           16224       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           gru_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            33          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 20,121\n",
      "Trainable params: 20,121\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:169: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-05-15 19:31:15.324907: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
      "2021-05-15 19:31:15.325156: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5562e3421480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-05-15 19:31:15.325192: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-05-15 19:31:15.327447: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-05-15 19:31:15.339215: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-05-15 19:31:15.339272: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a47ca3cac364): /proc/driver/nvidia/version does not exist\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:173: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:182: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:189: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "==> training\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:958: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:680: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:945: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 24490 samples, validate on 5356 samples\n",
      "Epoch 21/25\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13298  1781]\n",
      " [ 4169  5242]]\n",
      "accuracy = 0.757043719291687\n",
      "precision class 0 = 0.7613213658332825\n",
      "precision class 1 = 0.7464046478271484\n",
      "recall class 0 = 0.881888747215271\n",
      "recall class 1 = 0.5570077300071716\n",
      "AUC of ROC = 0.8118751742716639\n",
      "AUC of PRC = 0.7434126918446995\n",
      "min(+P, Se) = 0.6766549782169802\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2850  404]\n",
      " [ 965 1137]]\n",
      "accuracy = 0.744398832321167\n",
      "precision class 0 = 0.7470511198043823\n",
      "precision class 1 = 0.7378326058387756\n",
      "recall class 0 = 0.8758451342582703\n",
      "recall class 1 = 0.5409134030342102\n",
      "AUC of ROC = 0.7938869938016712\n",
      "AUC of PRC = 0.7257811709250783\n",
      "min(+P, Se) = 0.6739543726235742\n",
      "Epoch 00021: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch21.test0.5305416782103518.state\n",
      " - 1242s - loss: 0.5333 - val_loss: 0.5305\n",
      "Epoch 22/25\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13370  1709]\n",
      " [ 4175  5236]]\n",
      "accuracy = 0.7597386837005615\n",
      "precision class 0 = 0.7620404958724976\n",
      "precision class 1 = 0.7539237141609192\n",
      "recall class 0 = 0.886663556098938\n",
      "recall class 1 = 0.556370198726654\n",
      "AUC of ROC = 0.8152851645520889\n",
      "AUC of PRC = 0.7472869470494775\n",
      "min(+P, Se) = 0.6801189464740867\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2871  383]\n",
      " [ 965 1137]]\n",
      "accuracy = 0.7483196258544922\n",
      "precision class 0 = 0.7484358549118042\n",
      "precision class 1 = 0.7480263113975525\n",
      "recall class 0 = 0.8822987079620361\n",
      "recall class 1 = 0.5409134030342102\n",
      "AUC of ROC = 0.7939414535984988\n",
      "AUC of PRC = 0.7263984202553562\n",
      "min(+P, Se) = 0.6723728007608178\n",
      "Epoch 00022: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch22.test0.5286361081129228.state\n",
      " - 1185s - loss: 0.5322 - val_loss: 0.5286\n",
      "Epoch 23/25\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13148  1931]\n",
      " [ 3936  5475]]\n",
      "accuracy = 0.7604328393936157\n",
      "precision class 0 = 0.7696089744567871\n",
      "precision class 1 = 0.7392654418945312\n",
      "recall class 0 = 0.871941089630127\n",
      "recall class 1 = 0.5817660093307495\n",
      "AUC of ROC = 0.8142591193764482\n",
      "AUC of PRC = 0.7442113735399787\n",
      "min(+P, Se) = 0.6818616512591648\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2825  429]\n",
      " [ 911 1191]]\n",
      "accuracy = 0.7498133182525635\n",
      "precision class 0 = 0.756156325340271\n",
      "precision class 1 = 0.7351852059364319\n",
      "recall class 0 = 0.8681622743606567\n",
      "recall class 1 = 0.5666032433509827\n",
      "AUC of ROC = 0.7928282076308628\n",
      "AUC of PRC = 0.7262964305192435\n",
      "min(+P, Se) = 0.6680932001902045\n",
      "Epoch 00023: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch23.test0.530101595127912.state\n",
      " - 1183s - loss: 0.5309 - val_loss: 0.5301\n",
      "Epoch 24/25\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13485  1594]\n",
      " [ 4326  5085]]\n",
      "accuracy = 0.7582686543464661\n",
      "precision class 0 = 0.7571163773536682\n",
      "precision class 1 = 0.7613415122032166\n",
      "recall class 0 = 0.8942900896072388\n",
      "recall class 1 = 0.5403251647949219\n",
      "AUC of ROC = 0.8152190937948883\n",
      "AUC of PRC = 0.7473981899548696\n",
      "min(+P, Se) = 0.6835900159320234\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2887  367]\n",
      " [ 992 1110]]\n",
      "accuracy = 0.7462658882141113\n",
      "precision class 0 = 0.7442640066146851\n",
      "precision class 1 = 0.7515233755111694\n",
      "recall class 0 = 0.8872157335281372\n",
      "recall class 1 = 0.528068482875824\n",
      "AUC of ROC = 0.7924631442411213\n",
      "AUC of PRC = 0.7219184905969266\n",
      "min(+P, Se) = 0.6690442225392297\n",
      "Epoch 00024: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch24.test0.5321805021538496.state\n",
      " - 1177s - loss: 0.5296 - val_loss: 0.5322\n",
      "Epoch 25/25\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13270  1809]\n",
      " [ 4001  5410]]\n",
      "accuracy = 0.7627602815628052\n",
      "precision class 0 = 0.768339991569519\n",
      "precision class 1 = 0.7494112849235535\n",
      "recall class 0 = 0.8800318241119385\n",
      "recall class 1 = 0.5748592019081116\n",
      "AUC of ROC = 0.8169128968617088\n",
      "AUC of PRC = 0.7508363487028966\n",
      "min(+P, Se) = 0.6826054616937626\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2839  415]\n",
      " [ 941 1161]]\n",
      "accuracy = 0.7468259930610657\n",
      "precision class 0 = 0.7510582208633423\n",
      "precision class 1 = 0.7366751432418823\n",
      "recall class 0 = 0.872464656829834\n",
      "recall class 1 = 0.5523310899734497\n",
      "AUC of ROC = 0.7931578904277659\n",
      "AUC of PRC = 0.7232140557876333\n",
      "min(+P, Se) = 0.6722169362511894\n",
      "Epoch 00025: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch25.test0.5310363372463713.state\n",
      " - 1179s - loss: 0.5287 - val_loss: 0.5310\n"
     ]
    }
   ],
   "source": [
    "!python -um mimic3models.los3days.main --data /content/los3days/ --network mimic3models/keras_models/channel_wise_grus.py --dim 8 --depth 1 --batch_size 8 --dropout 0.3 --timestep 1.0 --epochs 5 --load_state mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch20.test0.529586777858898.state  --mode train --size_coef 4.0 --output_dir mimic3models/los3days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4T9HXO82Cnb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K4byogSv9u_U",
    "outputId": "7710d875-2993-4f46-88f5-c14e3b65d19f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/MIMIC_benchmark/mimic3models/los3days/main.py:7: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Using TensorFlow backend.\n",
      "Namespace(batch_norm=False, batch_size=8, beta_1=0.9, data='/content/los3days/', depth=1, dim=8, dropout=0.3, epochs=5, imputation='previous', l1=0, l2=0, load_state='mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch25.test0.5310363372463713.state', lr=0.001, mode='train', network='mimic3models/keras_models/channel_wise_grus.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/los3days', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)\n",
      "==> using model mimic3models/keras_models/channel_wise_grus.py\n",
      "==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])\n",
      "==> found 17 channels: ['Capillary refill rate', 'Diastolic blood pressure', 'Fraction inspired oxygen', 'Glascow coma scale eye opening', 'Glascow coma scale motor response', 'Glascow coma scale total', 'Glascow coma scale verbal response', 'Glucose', 'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation', 'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight', 'pH']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1364: calling reduce_any_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2613: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1379: calling reduce_all_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "==> model.final_name: k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0\n",
      "==> compiling the model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2950: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X (InputLayer)                  (None, None, 76)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 76)     0           X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "slice_1 (Slice)                 (None, None, 3)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_2 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_3 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_4 (Slice)                 (None, None, 9)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_5 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_6 (Slice)                 (None, None, 14)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_7 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_8 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_9 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_10 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_11 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_12 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_13 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_14 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_15 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_16 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_17 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 8)      192         slice_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 8)      168         slice_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, None, 8)      168         slice_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 8)      336         slice_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, None, 8)      432         slice_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, None, 8)      456         slice_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, None, 8)      432         slice_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, None, 8)      168         slice_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, None, 8)      168         slice_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, None, 8)      168         slice_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, None, 8)      168         slice_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, None, 8)      168         slice_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, None, 8)      168         slice_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, None, 8)      168         slice_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, None, 8)      168         slice_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, None, 8)      168         slice_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, None, 8)      168         slice_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 136)    0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "                                                                 bidirectional_7[0][0]            \n",
      "                                                                 bidirectional_8[0][0]            \n",
      "                                                                 bidirectional_9[0][0]            \n",
      "                                                                 bidirectional_10[0][0]           \n",
      "                                                                 bidirectional_11[0][0]           \n",
      "                                                                 bidirectional_12[0][0]           \n",
      "                                                                 bidirectional_13[0][0]           \n",
      "                                                                 bidirectional_14[0][0]           \n",
      "                                                                 bidirectional_15[0][0]           \n",
      "                                                                 bidirectional_16[0][0]           \n",
      "                                                                 bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gru_18 (GRU)                    (None, 32)           16224       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           gru_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            33          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 20,121\n",
      "Trainable params: 20,121\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:169: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-05-16 09:45:46.531420: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200145000 Hz\n",
      "2021-05-16 09:45:46.531670: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561f77897480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-05-16 09:45:46.531710: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-05-16 09:45:46.533686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-05-16 09:45:46.545097: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-05-16 09:45:46.545136: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (38c156b0a5be): /proc/driver/nvidia/version does not exist\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:173: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:182: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:189: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "==> training\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:958: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:680: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:945: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 24490 samples, validate on 5356 samples\n",
      "Epoch 26/30\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13373  1706]\n",
      " [ 4214  5197]]\n",
      "accuracy = 0.7582686543464661\n",
      "precision class 0 = 0.7603911757469177\n",
      "precision class 1 = 0.7528610825538635\n",
      "recall class 0 = 0.8868625164031982\n",
      "recall class 1 = 0.5522261261940002\n",
      "AUC of ROC = 0.81537694554368\n",
      "AUC of PRC = 0.7489771729860358\n",
      "min(+P, Se) = 0.6819630337794774\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2881  373]\n",
      " [ 968 1134]]\n",
      "accuracy = 0.7496265769004822\n",
      "precision class 0 = 0.7485061287879944\n",
      "precision class 1 = 0.752488374710083\n",
      "recall class 0 = 0.8853718638420105\n",
      "recall class 1 = 0.5394862294197083\n",
      "AUC of ROC = 0.7925435546793904\n",
      "AUC of PRC = 0.7220122541920367\n",
      "min(+P, Se) = 0.6669838249286394\n",
      "Epoch 00026: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch26.test0.5324632198931656.state\n",
      " - 1111s - loss: 0.5302 - val_loss: 0.5325\n",
      "Epoch 27/30\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13045  2034]\n",
      " [ 3828  5583]]\n",
      "accuracy = 0.7606369853019714\n",
      "precision class 0 = 0.7731286883354187\n",
      "precision class 1 = 0.7329657077789307\n",
      "recall class 0 = 0.8651103973388672\n",
      "recall class 1 = 0.5932419300079346\n",
      "AUC of ROC = 0.8177767776495426\n",
      "AUC of PRC = 0.7504410268354919\n",
      "min(+P, Se) = 0.6831704207394815\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2796  458]\n",
      " [ 881 1221]]\n",
      "accuracy = 0.75\n",
      "precision class 0 = 0.760402500629425\n",
      "precision class 1 = 0.7272185683250427\n",
      "recall class 0 = 0.8592501282691956\n",
      "recall class 1 = 0.5808753371238708\n",
      "AUC of ROC = 0.7938922570303577\n",
      "AUC of PRC = 0.7243337706416315\n",
      "min(+P, Se) = 0.6706217370669197\n",
      "Epoch 00027: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch27.test0.531069840131365.state\n",
      " - 1067s - loss: 0.5286 - val_loss: 0.5311\n",
      "Epoch 28/30\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[12991  2088]\n",
      " [ 3730  5681]]\n",
      "accuracy = 0.762433648109436\n",
      "precision class 0 = 0.7769272327423096\n",
      "precision class 1 = 0.7312395572662354\n",
      "recall class 0 = 0.8615292906761169\n",
      "recall class 1 = 0.6036552786827087\n",
      "AUC of ROC = 0.8181850971840166\n",
      "AUC of PRC = 0.7501778405713958\n",
      "min(+P, Se) = 0.6843278827776598\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2778  476]\n",
      " [ 875 1227]]\n",
      "accuracy = 0.7477595210075378\n",
      "precision class 0 = 0.7604708671569824\n",
      "precision class 1 = 0.7204932570457458\n",
      "recall class 0 = 0.8537185192108154\n",
      "recall class 1 = 0.5837298035621643\n",
      "AUC of ROC = 0.7957240799145252\n",
      "AUC of PRC = 0.7221082384875972\n",
      "min(+P, Se) = 0.6779257849666984\n",
      "Epoch 00028: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch28.test0.5288566701041842.state\n",
      " - 1069s - loss: 0.5282 - val_loss: 0.5289\n",
      "Epoch 29/30\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13022  2057]\n",
      " [ 3741  5670]]\n",
      "accuracy = 0.7632502913475037\n",
      "precision class 0 = 0.7768298983573914\n",
      "precision class 1 = 0.7337905764579773\n",
      "recall class 0 = 0.8635851144790649\n",
      "recall class 1 = 0.6024864315986633\n",
      "AUC of ROC = 0.8185121565929938\n",
      "AUC of PRC = 0.7510623820985216\n",
      "min(+P, Se) = 0.684836892997556\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2775  479]\n",
      " [ 870 1232]]\n",
      "accuracy = 0.7481329441070557\n",
      "precision class 0 = 0.7613168954849243\n",
      "precision class 1 = 0.7200467586517334\n",
      "recall class 0 = 0.8527965545654297\n",
      "recall class 1 = 0.5861084461212158\n",
      "AUC of ROC = 0.7911932441196577\n",
      "AUC of PRC = 0.7212063792303699\n",
      "min(+P, Se) = 0.6653992395437263\n",
      "Epoch 00029: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch29.test0.5323582372952967.state\n",
      " - 1057s - loss: 0.5279 - val_loss: 0.5324\n",
      "Epoch 30/30\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13321  1758]\n",
      " [ 4094  5317]]\n",
      "accuracy = 0.7610453367233276\n",
      "precision class 0 = 0.7649152874946594\n",
      "precision class 1 = 0.7515194416046143\n",
      "recall class 0 = 0.8834140300750732\n",
      "recall class 1 = 0.5649771690368652\n",
      "AUC of ROC = 0.8184617473394065\n",
      "AUC of PRC = 0.7507803226563394\n",
      "min(+P, Se) = 0.6845124282982792\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2850  404]\n",
      " [ 948 1154]]\n",
      "accuracy = 0.7475728392601013\n",
      "precision class 0 = 0.7503949403762817\n",
      "precision class 1 = 0.740693211555481\n",
      "recall class 0 = 0.8758451342582703\n",
      "recall class 1 = 0.5490009784698486\n",
      "AUC of ROC = 0.7941355351563208\n",
      "AUC of PRC = 0.7219881699548868\n",
      "min(+P, Se) = 0.6723646723646723\n",
      "Epoch 00030: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch30.test0.5312995400510678.state\n",
      " - 1063s - loss: 0.5276 - val_loss: 0.5313\n"
     ]
    }
   ],
   "source": [
    "!python -um mimic3models.los3days.main --data /content/los3days/ --network mimic3models/keras_models/channel_wise_grus.py --dim 8 --depth 1 --batch_size 8 --dropout 0.3 --timestep 1.0 --epochs 5 --load_state mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch25.test0.5310363372463713.state  --mode train --size_coef 4.0 --output_dir mimic3models/los3days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGB7ew_y6gyt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96sZLc_Q9vBO",
    "outputId": "680b8843-2bce-4e93-c65d-61a2aea3adcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/MIMIC_benchmark/mimic3models/los3days/main.py:7: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Using TensorFlow backend.\n",
      "Namespace(batch_norm=False, batch_size=8, beta_1=0.9, data='/content/los3days/', depth=1, dim=8, dropout=0.3, epochs=5, imputation='previous', l1=0, l2=0, load_state='mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch30.test0.5312995400510678.state', lr=0.001, mode='train', network='mimic3models/keras_models/channel_wise_grus.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/los3days', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)\n",
      "==> using model mimic3models/keras_models/channel_wise_grus.py\n",
      "==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])\n",
      "==> found 17 channels: ['Capillary refill rate', 'Diastolic blood pressure', 'Fraction inspired oxygen', 'Glascow coma scale eye opening', 'Glascow coma scale motor response', 'Glascow coma scale total', 'Glascow coma scale verbal response', 'Glucose', 'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation', 'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight', 'pH']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1364: calling reduce_any_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2613: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1379: calling reduce_all_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "==> model.final_name: k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0\n",
      "==> compiling the model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2950: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X (InputLayer)                  (None, None, 76)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 76)     0           X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "slice_1 (Slice)                 (None, None, 3)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_2 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_3 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_4 (Slice)                 (None, None, 9)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_5 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_6 (Slice)                 (None, None, 14)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_7 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_8 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_9 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_10 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_11 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_12 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_13 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_14 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_15 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_16 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_17 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 8)      192         slice_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 8)      168         slice_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, None, 8)      168         slice_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 8)      336         slice_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, None, 8)      432         slice_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, None, 8)      456         slice_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, None, 8)      432         slice_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, None, 8)      168         slice_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, None, 8)      168         slice_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, None, 8)      168         slice_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, None, 8)      168         slice_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, None, 8)      168         slice_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, None, 8)      168         slice_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, None, 8)      168         slice_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, None, 8)      168         slice_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, None, 8)      168         slice_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, None, 8)      168         slice_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 136)    0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "                                                                 bidirectional_7[0][0]            \n",
      "                                                                 bidirectional_8[0][0]            \n",
      "                                                                 bidirectional_9[0][0]            \n",
      "                                                                 bidirectional_10[0][0]           \n",
      "                                                                 bidirectional_11[0][0]           \n",
      "                                                                 bidirectional_12[0][0]           \n",
      "                                                                 bidirectional_13[0][0]           \n",
      "                                                                 bidirectional_14[0][0]           \n",
      "                                                                 bidirectional_15[0][0]           \n",
      "                                                                 bidirectional_16[0][0]           \n",
      "                                                                 bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gru_18 (GRU)                    (None, 32)           16224       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           gru_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            33          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 20,121\n",
      "Trainable params: 20,121\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:169: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-05-16 11:24:07.878846: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200145000 Hz\n",
      "2021-05-16 11:24:07.879101: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c67fb55480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-05-16 11:24:07.879144: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-05-16 11:24:07.881213: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-05-16 11:24:07.892948: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-05-16 11:24:07.892988: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (38c156b0a5be): /proc/driver/nvidia/version does not exist\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:173: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:182: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:189: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "==> training\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:958: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:680: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:945: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 24490 samples, validate on 5356 samples\n",
      "Epoch 31/35\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13230  1849]\n",
      " [ 3937  5474]]\n",
      "accuracy = 0.7637403011322021\n",
      "precision class 0 = 0.770664632320404\n",
      "precision class 1 = 0.7475078701972961\n",
      "recall class 0 = 0.8773791193962097\n",
      "recall class 1 = 0.581659734249115\n",
      "AUC of ROC = 0.8197818447326073\n",
      "AUC of PRC = 0.7539346651144753\n",
      "min(+P, Se) = 0.6854744447986398\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2833  421]\n",
      " [ 933 1169]]\n",
      "accuracy = 0.7471994161605835\n",
      "precision class 0 = 0.7522570490837097\n",
      "precision class 1 = 0.7352201342582703\n",
      "recall class 0 = 0.8706207871437073\n",
      "recall class 1 = 0.5561370253562927\n",
      "AUC of ROC = 0.7914455135946272\n",
      "AUC of PRC = 0.718180615095878\n",
      "min(+P, Se) = 0.670313986679353\n",
      "Epoch 00031: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch31.test0.5325900697948507.state\n",
      " - 1125s - loss: 0.5299 - val_loss: 0.5326\n",
      "Epoch 32/35\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13133  1946]\n",
      " [ 3879  5532]]\n",
      "accuracy = 0.762147843837738\n",
      "precision class 0 = 0.7719844579696655\n",
      "precision class 1 = 0.7397699952125549\n",
      "recall class 0 = 0.8709463477134705\n",
      "recall class 1 = 0.5878227353096008\n",
      "AUC of ROC = 0.8195390790947086\n",
      "AUC of PRC = 0.7512169887096022\n",
      "min(+P, Se) = 0.6862182552332377\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2822  432]\n",
      " [ 907 1195]]\n",
      "accuracy = 0.75\n",
      "precision class 0 = 0.7567712664604187\n",
      "precision class 1 = 0.734480619430542\n",
      "recall class 0 = 0.867240309715271\n",
      "recall class 1 = 0.5685061812400818\n",
      "AUC of ROC = 0.792230977375719\n",
      "AUC of PRC = 0.7226419552288591\n",
      "min(+P, Se) = 0.6720379146919432\n",
      "Epoch 00032: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch32.test0.5305816783354833.state\n",
      " - 1082s - loss: 0.5261 - val_loss: 0.5306\n",
      "Epoch 33/35\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13154  1925]\n",
      " [ 3880  5531]]\n",
      "accuracy = 0.7629644870758057\n",
      "precision class 0 = 0.772220253944397\n",
      "precision class 1 = 0.7418186664581299\n",
      "recall class 0 = 0.8723390102386475\n",
      "recall class 1 = 0.5877165198326111\n",
      "AUC of ROC = 0.8201999311260274\n",
      "AUC of PRC = 0.7534696921865639\n",
      "min(+P, Se) = 0.682233071534706\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2817  437]\n",
      " [ 928 1174]]\n",
      "accuracy = 0.7451456189155579\n",
      "precision class 0 = 0.7522029280662537\n",
      "precision class 1 = 0.7287399172782898\n",
      "recall class 0 = 0.8657037615776062\n",
      "recall class 1 = 0.558515727519989\n",
      "AUC of ROC = 0.791238712567479\n",
      "AUC of PRC = 0.719931495350179\n",
      "min(+P, Se) = 0.6717411988582302\n",
      "Epoch 00033: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch33.test0.5374131854164502.state\n",
      " - 1082s - loss: 0.5255 - val_loss: 0.5374\n",
      "Epoch 34/35\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13278  1801]\n",
      " [ 3942  5469]]\n",
      "accuracy = 0.7654961347579956\n",
      "precision class 0 = 0.7710801362991333\n",
      "precision class 1 = 0.7522696256637573\n",
      "recall class 0 = 0.8805623650550842\n",
      "recall class 1 = 0.5811284780502319\n",
      "AUC of ROC = 0.8225494772972289\n",
      "AUC of PRC = 0.7561842676135315\n",
      "min(+P, Se) = 0.688980979704601\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2841  413]\n",
      " [ 936 1166]]\n",
      "accuracy = 0.7481329441070557\n",
      "precision class 0 = 0.752184271812439\n",
      "precision class 1 = 0.738442063331604\n",
      "recall class 0 = 0.8730792999267578\n",
      "recall class 1 = 0.554709792137146\n",
      "AUC of ROC = 0.7912428061897909\n",
      "AUC of PRC = 0.7201872863970384\n",
      "min(+P, Se) = 0.6673003802281369\n",
      "Epoch 00034: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch34.test0.5358423533125365.state\n",
      " - 1076s - loss: 0.5240 - val_loss: 0.5358\n",
      "Epoch 35/35\n",
      "\n",
      "==>predicting on train\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[13431  1648]\n",
      " [ 4117  5294]]\n",
      "accuracy = 0.7645977735519409\n",
      "precision class 0 = 0.7653863430023193\n",
      "precision class 1 = 0.7626044154167175\n",
      "recall class 0 = 0.8907089233398438\n",
      "recall class 1 = 0.5625331997871399\n",
      "AUC of ROC = 0.8237917674948632\n",
      "AUC of PRC = 0.7559700907807682\n",
      "min(+P, Se) = 0.689087238338115\n",
      "\n",
      "==>predicting on validation\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[2864  390]\n",
      " [ 982 1120]]\n",
      "accuracy = 0.7438386678695679\n",
      "precision class 0 = 0.7446697950363159\n",
      "precision class 1 = 0.7417218685150146\n",
      "recall class 0 = 0.8801475167274475\n",
      "recall class 1 = 0.5328258872032166\n",
      "AUC of ROC = 0.7903670634166424\n",
      "AUC of PRC = 0.7195375088083547\n",
      "min(+P, Se) = 0.6666666666666666\n",
      "Epoch 00035: saving model to mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch35.test0.5341818687005929.state\n",
      " - 1066s - loss: 0.5250 - val_loss: 0.5342\n"
     ]
    }
   ],
   "source": [
    "!python -um mimic3models.los3days.main --data /content/los3days/ --network mimic3models/keras_models/channel_wise_grus.py --dim 8 --depth 1 --batch_size 8 --dropout 0.3 --timestep 1.0 --epochs 5 --load_state mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch30.test0.5312995400510678.state  --mode train --size_coef 4.0 --output_dir mimic3models/los3days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "muipDl1LEAMb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "flWHzNd2WD8T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "uSK_zF_qjdFT",
    "outputId": "d5c4a540-478c-4bd9-cbce-faef7f3e98b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_auprc</th>\n",
       "      <th>train_auroc</th>\n",
       "      <th>train_minpse</th>\n",
       "      <th>train_prec0</th>\n",
       "      <th>train_prec1</th>\n",
       "      <th>train_rec0</th>\n",
       "      <th>train_rec1</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_auprc</th>\n",
       "      <th>val_auroc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_minpse</th>\n",
       "      <th>val_prec0</th>\n",
       "      <th>val_prec1</th>\n",
       "      <th>val_rec0</th>\n",
       "      <th>val_rec1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.591901</td>\n",
       "      <td>0.737035</td>\n",
       "      <td>0.681934</td>\n",
       "      <td>0.767692</td>\n",
       "      <td>0.639928</td>\n",
       "      <td>0.748719</td>\n",
       "      <td>0.708550</td>\n",
       "      <td>0.862325</td>\n",
       "      <td>0.536287</td>\n",
       "      <td>0.736557</td>\n",
       "      <td>0.686758</td>\n",
       "      <td>0.766717</td>\n",
       "      <td>0.560632</td>\n",
       "      <td>0.642891</td>\n",
       "      <td>0.742692</td>\n",
       "      <td>0.721616</td>\n",
       "      <td>0.866626</td>\n",
       "      <td>0.535205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.566669</td>\n",
       "      <td>0.737240</td>\n",
       "      <td>0.699633</td>\n",
       "      <td>0.780078</td>\n",
       "      <td>0.648832</td>\n",
       "      <td>0.742265</td>\n",
       "      <td>0.723759</td>\n",
       "      <td>0.878175</td>\n",
       "      <td>0.511423</td>\n",
       "      <td>0.738984</td>\n",
       "      <td>0.703058</td>\n",
       "      <td>0.777915</td>\n",
       "      <td>0.548158</td>\n",
       "      <td>0.650899</td>\n",
       "      <td>0.739175</td>\n",
       "      <td>0.738482</td>\n",
       "      <td>0.881377</td>\n",
       "      <td>0.518554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.559690</td>\n",
       "      <td>0.742425</td>\n",
       "      <td>0.701263</td>\n",
       "      <td>0.780275</td>\n",
       "      <td>0.648284</td>\n",
       "      <td>0.744850</td>\n",
       "      <td>0.735826</td>\n",
       "      <td>0.884740</td>\n",
       "      <td>0.514398</td>\n",
       "      <td>0.739358</td>\n",
       "      <td>0.706717</td>\n",
       "      <td>0.778320</td>\n",
       "      <td>0.544774</td>\n",
       "      <td>0.657333</td>\n",
       "      <td>0.737839</td>\n",
       "      <td>0.743448</td>\n",
       "      <td>0.885679</td>\n",
       "      <td>0.512845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.554861</td>\n",
       "      <td>0.744835</td>\n",
       "      <td>0.710728</td>\n",
       "      <td>0.787162</td>\n",
       "      <td>0.653172</td>\n",
       "      <td>0.753677</td>\n",
       "      <td>0.723116</td>\n",
       "      <td>0.869885</td>\n",
       "      <td>0.544469</td>\n",
       "      <td>0.744399</td>\n",
       "      <td>0.714713</td>\n",
       "      <td>0.785214</td>\n",
       "      <td>0.541879</td>\n",
       "      <td>0.659696</td>\n",
       "      <td>0.749009</td>\n",
       "      <td>0.733291</td>\n",
       "      <td>0.871235</td>\n",
       "      <td>0.548049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.553744</td>\n",
       "      <td>0.742058</td>\n",
       "      <td>0.712816</td>\n",
       "      <td>0.790641</td>\n",
       "      <td>0.658202</td>\n",
       "      <td>0.759446</td>\n",
       "      <td>0.703446</td>\n",
       "      <td>0.850454</td>\n",
       "      <td>0.568377</td>\n",
       "      <td>0.742158</td>\n",
       "      <td>0.714833</td>\n",
       "      <td>0.786603</td>\n",
       "      <td>0.538138</td>\n",
       "      <td>0.661458</td>\n",
       "      <td>0.754415</td>\n",
       "      <td>0.715224</td>\n",
       "      <td>0.853411</td>\n",
       "      <td>0.569933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch      loss  train_acc  ...  val_prec1  val_rec0  val_rec1\n",
       "0      0  0.591901   0.737035  ...   0.721616  0.866626  0.535205\n",
       "1      1  0.566669   0.737240  ...   0.738482  0.881377  0.518554\n",
       "2      2  0.559690   0.742425  ...   0.743448  0.885679  0.512845\n",
       "3      3  0.554861   0.744835  ...   0.733291  0.871235  0.548049\n",
       "4      4  0.553744   0.742058  ...   0.715224  0.853411  0.569933\n",
       "\n",
       "[5 rows x 19 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Escoger epoch con mejor aucpr en validation set\n",
    "import pandas as pd\n",
    "aucpr_channelwise_gru = pd.read_csv('mimic3models/los3days/keras_logs/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.csv', delimiter = \";\")\n",
    "aucpr_channelwise_gru.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dzt7e1NhjdHT",
    "outputId": "56ccd86f-872f-46c2-da19-c732b2096035"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucpr_channelwise_gru['epoch'][aucpr_channelwise_gru['val_auprc'].idxmax()]+1  #obs. epoch en dataframe empieza por 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NK2fc-kcjdJU",
    "outputId": "6bf6317c-e274-48c5-c53d-619a074e6733"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7272804044949749"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucpr_channelwise_gru['val_auprc'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8upSy-cXjxwk"
   },
   "source": [
    "\n",
    "Predicting on Test with epoch 20 (la mejor en aucpr sobre validation set, aucpr: 0.727):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FWvyJ8mwjw34",
    "outputId": "6dc92767-7118-4a89-dd2f-afe2bace69f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/MIMIC_benchmark/mimic3models/los3days/main.py:7: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Using TensorFlow backend.\n",
      "Namespace(batch_norm=False, batch_size=8, beta_1=0.9, data='/content/los3days/', depth=1, dim=8, dropout=0.3, epochs=100, imputation='previous', l1=0, l2=0, load_state='mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch20.test0.529586777858898.state', lr=0.001, mode='test', network='mimic3models/keras_models/channel_wise_grus.py', normalizer_state=None, optimizer='adam', output_dir='mimic3models/los3days', prefix='', rec_dropout=0.0, save_every=1, size_coef=4.0, small_part=False, target_repl_coef=0.0, timestep=1.0, verbose=2)\n",
      "==> using model mimic3models/keras_models/channel_wise_grus.py\n",
      "==> not used params in network class: dict_keys(['batch_size', 'beta_1', 'data', 'epochs', 'imputation', 'l1', 'l2', 'load_state', 'lr', 'mode', 'network', 'normalizer_state', 'optimizer', 'output_dir', 'prefix', 'save_every', 'small_part', 'target_repl_coef', 'timestep', 'verbose'])\n",
      "==> found 17 channels: ['Capillary refill rate', 'Diastolic blood pressure', 'Fraction inspired oxygen', 'Glascow coma scale eye opening', 'Glascow coma scale motor response', 'Glascow coma scale total', 'Glascow coma scale verbal response', 'Glucose', 'Heart Rate', 'Height', 'Mean blood pressure', 'Oxygen saturation', 'Respiratory rate', 'Systolic blood pressure', 'Temperature', 'Weight', 'pH']\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1364: calling reduce_any_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2613: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1379: calling reduce_all_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "==> model.final_name: k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0\n",
      "==> compiling the model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2950: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X (InputLayer)                  (None, None, 76)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 76)     0           X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "slice_1 (Slice)                 (None, None, 3)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_2 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_3 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_4 (Slice)                 (None, None, 9)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_5 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_6 (Slice)                 (None, None, 14)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_7 (Slice)                 (None, None, 13)     0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_8 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_9 (Slice)                 (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_10 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_11 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_12 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_13 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_14 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_15 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_16 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "slice_17 (Slice)                (None, None, 2)      0           masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 8)      192         slice_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 8)      168         slice_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, None, 8)      168         slice_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 8)      336         slice_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, None, 8)      432         slice_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, None, 8)      456         slice_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, None, 8)      432         slice_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, None, 8)      168         slice_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, None, 8)      168         slice_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, None, 8)      168         slice_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, None, 8)      168         slice_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, None, 8)      168         slice_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, None, 8)      168         slice_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, None, 8)      168         slice_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, None, 8)      168         slice_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, None, 8)      168         slice_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, None, 8)      168         slice_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 136)    0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "                                                                 bidirectional_7[0][0]            \n",
      "                                                                 bidirectional_8[0][0]            \n",
      "                                                                 bidirectional_9[0][0]            \n",
      "                                                                 bidirectional_10[0][0]           \n",
      "                                                                 bidirectional_11[0][0]           \n",
      "                                                                 bidirectional_12[0][0]           \n",
      "                                                                 bidirectional_13[0][0]           \n",
      "                                                                 bidirectional_14[0][0]           \n",
      "                                                                 bidirectional_15[0][0]           \n",
      "                                                                 bidirectional_16[0][0]           \n",
      "                                                                 bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "gru_18 (GRU)                    (None, 32)           16224       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           gru_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            33          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 20,121\n",
      "Trainable params: 20,121\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:164: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:169: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-05-16 13:02:59.034297: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200145000 Hz\n",
      "2021-05-16 13:02:59.034547: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5619b4e0f480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-05-16 13:02:59.034587: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-05-16 13:02:59.036566: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-05-16 13:02:59.050043: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-05-16 13:02:59.050086: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (38c156b0a5be): /proc/driver/nvidia/version does not exist\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:173: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:182: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:189: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "5282/5282 [==============================] - 33s 6ms/step\n",
      "confusion matrix:\n",
      "[[2824  416]\n",
      " [ 914 1128]]\n",
      "accuracy = 0.7482014298439026\n",
      "precision class 0 = 0.7554842233657837\n",
      "precision class 1 = 0.7305699586868286\n",
      "recall class 0 = 0.8716049194335938\n",
      "recall class 1 = 0.5523996353149414\n",
      "AUC of ROC = 0.7891674526305608\n",
      "AUC of PRC = 0.7166281784287694\n",
      "min(+P, Se) = 0.6576885406464251\n"
     ]
    }
   ],
   "source": [
    "!python -um mimic3models.los3days.main --data /content/los3days/ --network mimic3models/keras_models/channel_wise_grus.py --dim 8 --depth 1 --batch_size 8 --dropout 0.3 --timestep 1.0 --load_state mimic3models/los3days/keras_states/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch20.test0.529586777858898.state --mode test --size_coef 4.0 --output_dir mimic3models/los3days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KpD0BZ4cj4gk"
   },
   "source": [
    "95% Confidence Interval evaluation with epoch 20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MdGlFt_UkNhp",
    "outputId": "b812c8e4-aed0-4d3b-ad5f-b7edc1c494da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the results in los3days_results_channelWise_gru_epoch20.json ...\n",
      "{'n_iters': 10000, 'AUC of ROC': {'value': 0.7891676793509147, 'mean': 0.7892349048064301, 'median': 0.7893228309218384, 'std': 0.006504602507796131, '2.5% percentile': 0.7763366481719772, '97.5% percentile': 0.8018266199334211}, 'AUC of PRC': {'value': 0.7166283490326372, 'mean': 0.7168859592473115, 'median': 0.7169850771954692, 'std': 0.010578617115684972, '2.5% percentile': 0.695805741324334, '97.5% percentile': 0.7372454640528683}, 'min(+P, Se)': {'value': 0.6576885406464251, 'mean': 0.6584358388409657, 'median': 0.658477250240256, 'std': 0.008654647055178, '2.5% percentile': 0.6414264777723497, '97.5% percentile': 0.6750837206155238}}\n"
     ]
    }
   ],
   "source": [
    "!python -m mimic3benchmark.evaluation.evaluate_los_customized /content/gdrive/MyDrive/MIMIC_benchmark/mimic3models/los3days/test_predictions/k_channel_wise_grus.n8.szc4.0.d0.3.dep1.bs8.ts1.0.epoch20.test0.529586777858898.state.csv --test_listfile /content/los3days/test/listfile.csv --save_file los3days_results_channelWise_gru_epoch20.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uNYBElWTVQcj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "aeQbdmLS0Zo7",
    "PVCFO90JVVzX",
    "YhSzKIQhV6hR"
   ],
   "name": "mimic_benchmark_prueba_modificarTareaLOS3days_addGru.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
